I"Y<hr />

<p id="toc"><strong>Table of Contents</strong></p>
<ul id="markdown-toc">
  <li><a href="#pyflink" id="markdown-toc-pyflink">PyFlink</a></li>
  <li><a href="#datastream-api" id="markdown-toc-datastream-api">DataStream API</a>    <ul>
      <li><a href="#datastream-api-맛보기" id="markdown-toc-datastream-api-맛보기">DataStream API 맛보기</a></li>
    </ul>
  </li>
  <li><a href="#참고" id="markdown-toc-참고">참고</a></li>
</ul>

<hr />

<h1 id="pyflink">PyFlink</h1>

<p><img src="/images/flink_30.png" alt="" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install apache-flink
</code></pre></div></div>

<ul>
  <li>PyFlink는 <strong>실시간 데이터 처리 파이프라인 작업을 수행하는데 필요한 고수준 API를 제공</strong></li>
  <li>크게 두 가지의 <strong>Table API, DataStream API</strong>를 제공</li>
  <li>
    <p>제공받은 API를 이용해 실시간 데이터 처리를 위한 스크립트를 <strong>파이썬</strong> 언어로 작성할 수 있음</p>
  </li>
  <li>Table API는 SQL과 유사한 형태의 강력한 관계형 쿼리를 작성하는데 필요한 기능을 제공</li>
</ul>

<h1 id="datastream-api">DataStream API</h1>

<ul>
  <li>DataStream API는 시간, 상태와 같은 스트림 처리의 핵심이 되는 개념들을 다루는데 필요한 기능을 제공</li>
  <li><strong>Filtering, Update state, Defining window, Aggregating</strong>과 같은 스트림 데이터 변환 기능을 제공</li>
</ul>

<h2 id="datastream-api-맛보기">DataStream API 맛보기</h2>

<p>DataStream API applications begin by declaring an execution environment (StreamExecutionEnvironment), the context in which a streaming program is executed. This is what you will use to set the properties of your job (e.g. default parallelism, restart strategy), create your sources and finally trigger the execution of the job.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 스트리밍 프로그램이 실행되는 실행환경
# 작업의 특성을 설정
# 소스 생성
# 작업의 실행 트리거
</span><span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="p">.</span><span class="n">get_execution_environment</span><span class="p">()</span>
<span class="n">env</span><span class="p">.</span><span class="n">set_runtime_mode</span><span class="p">(</span><span class="n">RuntimeExecutionMode</span><span class="p">.</span><span class="n">BATCH</span><span class="p">)</span>
<span class="n">env</span><span class="p">.</span><span class="n">set_parallelism</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>Once a StreamExecutionEnvironment is created, you can use it to declare your source. Sources ingest data from external systems, such as Apache Kafka, Rabbit MQ, or Apache Pulsar, into Flink Jobs.</p>

<p>To keep things simple, this walkthrough uses a source which reads data from a file.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ds = env.from_source(
    source=FileSource.for_record_stream_format(StreamFormat.text_line_format(),
                                               input_path)
                     .process_static_file_set().build(),
    watermark_strategy=WatermarkStrategy.for_monotonous_timestamps(),
    source_name="file_source"
)
</code></pre></div></div>

<h1 id="참고">참고</h1>
<ul>
  <li><a href="https://nightlies.apache.org/flink/flink-docs-master/docs/dev/python/overview/" target="_blank">Apache Flink: pyflink 공식문서</a></li>
  <li><a href="https://nightlies.apache.org/flink/flink-docs-master/api/python/" target="_blank">Apache Flink” pyflink Docs 공식문서</a></li>
</ul>

:ET