I"<hr />

<p id="toc"><strong>Table of Contents</strong></p>

<hr />

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Name node</span>

<span class="c"># 폴더 생성</span>
hdfs dfs <span class="nt">-mkdir</span> /foo

<span class="c"># 로컬의 bar.txt 데이터를 /foo 폴더로 복사</span>
<span class="c"># (dfs.datanode.data.dir에 명시된 경로에 저장됨)</span>
<span class="c"># (나의 경우 file:/opt/hadoop/data/hdfs/datanode 로 지정함)</span>
hdfs dfs <span class="nt">-put</span> ./bar.txt /foo/
</code></pre></div></div>

<p><img src="/images/hadoop_20.png" alt="" /></p>

<p><img src="/images/hadoop_21.png" alt="" /></p>

<p><img src="/images/hadoop_22.png" alt="" /></p>

<p><img src="/images/hadoop_23.png" alt="" /></p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 스파크 마스터 컨테이너에서,
</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>

<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="n">master</span><span class="p">(</span><span class="s">"spark://spark-master:7077"</span><span class="p">).</span><span class="n">appName</span><span class="p">(</span><span class="s">"hdfs_test"</span><span class="p">).</span><span class="n">getOrCreate</span><span class="p">()</span>

<span class="n">myText</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="s">"hdfs://hdfs-name-node:8020/foo/bar.txt"</span><span class="p">)</span>
<span class="n">myText</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
<span class="o">----------------------------------------------------------------------------------------------------------------</span>
<span class="o">+-------------+</span>
<span class="o">|</span>        <span class="n">value</span><span class="o">|</span>
<span class="o">+-------------+</span>
<span class="o">|</span><span class="n">Hello</span> <span class="n">Hadoop</span><span class="err">!</span><span class="o">|</span>
<span class="o">+-------------+</span>
</code></pre></div></div>

<ul>
  <li>지금 머릿속에서 헷갈리는 부분은, 나중에 스파크 어플리케이션을 실행할 때 jar 파일이 필요할 때는 어떻게 해야할까</li>
  <li>내가 알기로는 submit 하는 곳, 마스터, 워커쪽에 다 jar 파일이 있어야 한다</li>
  <li>이러한 점도 hdfs를 쓰는 이유중 하나라고 생각한다</li>
  <li>근데 나는 지금 스파크 마스터는 네임 노드도 워커 노드도 아니다</li>
  <li>=&gt; 확인 결과, 네임노드도 워커노드도 아니어도 hdfs-site.xml 에 잘 정의만 해두면, 네임노드, 워커노드와 HDFS를 함께 공유할 수 있다</li>
</ul>

<p><img src="/images/hadoop_24.png" alt="" /></p>

<ul>
  <li>그럼 이제 HDFS에 jar 파일과 데이터 잘 올려두면 스파크 어플리케이션 잘 실행할 수 있을 것 같다</li>
</ul>
:ET