I"6<hr />

<p id="toc"><strong>Table of Contents</strong></p>
<ul id="markdown-toc">
  <li><a href="#hadoop" id="markdown-toc-hadoop">Hadoop</a></li>
  <li><a href="#hdfs" id="markdown-toc-hdfs">HDFS</a>    <ul>
      <li><a href="#구글-플랫폼의-철학" id="markdown-toc-구글-플랫폼의-철학">구글 플랫폼의 철학</a></li>
      <li><a href="#하둡-특성" id="markdown-toc-하둡-특성">하둡 특성</a></li>
      <li><a href="#하둡-클러스터" id="markdown-toc-하둡-클러스터">하둡 클러스터</a></li>
      <li><a href="#하둡-블록" id="markdown-toc-하둡-블록">하둡 블록</a></li>
      <li><a href="#네임노드" id="markdown-toc-네임노드">네임노드</a></li>
      <li><a href="#데이터노드" id="markdown-toc-데이터노드">데이터노드</a></li>
    </ul>
  </li>
  <li><a href="#hive" id="markdown-toc-hive">Hive</a></li>
  <li><a href="#hbase" id="markdown-toc-hbase">HBase</a></li>
  <li><a href="#cassandra" id="markdown-toc-cassandra">Cassandra</a></li>
  <li><a href="#yarn" id="markdown-toc-yarn">Yarn</a></li>
  <li><a href="#mapreduce" id="markdown-toc-mapreduce">MapReduce</a></li>
  <li><a href="#zookeeper" id="markdown-toc-zookeeper">Zookeeper</a></li>
  <li><a href="#참고" id="markdown-toc-참고">참고</a></li>
</ul>

<hr />

<h1 id="hadoop">Hadoop</h1>

<ul>
  <li>빅데이터 처리를 위한 다양한 소프트웨어 제공</li>
  <li>하둡은 개발자 더크 커팅이 처음으로 시작</li>
  <li>구글이 발표한 분산 파일 저장을 위한 논문 GFS, 분산 데이터 처리를 위한 MapReduce 논문을 발표</li>
  <li>더그 커팅이 구글에서 발표한 논문을 구현해 하둡 프로젝트가 시작됨 -&gt; HDFS와 MapReduce가 하둡 프로젝트에 포함</li>
  <li>이 후 빅데이터 처리를 위한 다양한 소프트웨어 Hive, HBase, Cassandra, Yarn 등이 등장하여 하둡 생태계 구성</li>
</ul>

<p><img src="/images/hadoop_1.png" alt="" /></p>

<h1 id="hdfs">HDFS</h1>

<h2 id="구글-플랫폼의-철학">구글 플랫폼의 철학</h2>
<ul>
  <li>한대의 고가 장비보다 여러 대의 저가 장비가 낫다</li>
  <li>데이터는 분산 저장한다</li>
  <li>시스템(H/W)은 언제든 죽을 수 있다</li>
  <li>시스템 확장이 쉬워야 한다</li>
</ul>

<h2 id="하둡-특성">하둡 특성</h2>
<ul>
  <li>구글 플랫폼이 녹아든 빅데이터 처리 소프트웨어</li>
  <li>수천대 이상의 서버를 하나의 클러스터로 사용</li>
  <li>마스터-슬레이브 구조</li>
  <li>파일은 블록단위로 저장</li>
  <li>복제를 통한 신뢰성 보장</li>
  <li>데이터 처리의 지역성 보장</li>
</ul>

<h2 id="하둡-클러스터">하둡 클러스터</h2>

<p><img src="/images/hadoop_2.png" alt="" /></p>

<ul>
  <li>Name Node: HDFS에 대한 마스터 데몬</li>
  <li>Data Node: HDFS에 대한 슬레이브 데몬</li>
  <li>Job Tracker: 어플리케이션 관리를 위한 마스터 데몬</li>
  <li>Task Tracker: 작업 관리를 위한 슬레이브 데몬</li>
</ul>

<h2 id="하둡-블록">하둡 블록</h2>

<p><img src="/images/hadoop_3.png" alt="" /></p>

<ul>
  <li>하나의 파일을 여러 개의 Block으로 저장</li>
  <li>블럭의 기본 크기는 128MB. 설정을 통해 변경 가능</li>
  <li>128MB와 같이 블록을 크게 잡는 이유는 탐색 비용을 최소화하기 위해(Minimizing seek operation)</li>
  <li>데이터를 조각내고 복제하여 여러 서버에 분산 저장</li>
  <li>복제 저장하는 것이 용량 낭비일 수 있지만 이를 통해 얻게 되는 이점이 더 큼</li>
  <li>만약 서버 1대에 장애가 발생하면 하트비트가 끊기게 되고, 장애난 서버가 가지고 있던 블록과 같은 데이터를 가지는 서버가 다른 서버와 통신 후 데이터를 복사함으로써 복제 수 유지</li>
  <li>블록의 지역성: 데이터를 처리할 때 해당 데이터를 가지고 있는 노드한테 잡을 먼저 할당함</li>
  <li>블록 캐싱: 자주 읽는 블록을 데이터 노드의 메모리에 캐싱함으로써 읽기 성능 향상</li>
</ul>

<h2 id="네임노드">네임노드</h2>

<ul>
  <li>파일시스템에 관한 메타데이터 관리</li>
  <li>데이터노드로부터 블럭 리포트를 받음</li>
  <li>데이터 복제 유지를 위한 커맨더 역할을 수행</li>
  <li>파일시스템 이미지(fsimage) 관리 (스냅샷)</li>
  <li>파일시스템에 대한 Edit Log 관리</li>
</ul>

<h2 id="데이터노드">데이터노드</h2>

<ul>
  <li>로컬 파일 시스템에 HDFS 데이터 저장</li>
  <li>주기적으로 로컬 파일 시스템에 있는 모든 HDFS 블록들을 검사 후 정상적인 블록의 목록을 만들어 네임노드에 전송</li>
</ul>

<h1 id="hive">Hive</h1>

<h1 id="hbase">HBase</h1>

<h1 id="cassandra">Cassandra</h1>

<h1 id="yarn">Yarn</h1>

<h1 id="mapreduce">MapReduce</h1>

<h1 id="zookeeper">Zookeeper</h1>

<h1 id="참고">참고</h1>

<ul>
  <li><a href="https://hoing.io/archives/21453" target="_blank">Hoing: 하둡 프로그래밍(2) – 빅데이터 - 하둡 에코시스템</a></li>
</ul>
:ET