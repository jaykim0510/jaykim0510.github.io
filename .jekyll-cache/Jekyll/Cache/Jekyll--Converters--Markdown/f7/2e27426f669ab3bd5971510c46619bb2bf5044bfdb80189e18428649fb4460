I" <p id="toc"><strong>Table of Contents</strong></p>
<ul id="markdown-toc">
  <li><a href="#스파크-설치" id="markdown-toc-스파크-설치">스파크 설치</a>    <ul>
      <li><a href="#pyspark" id="markdown-toc-pyspark">pyspark</a>        <ul>
          <li><a href="#자바-파이썬-설치" id="markdown-toc-자바-파이썬-설치">자바, 파이썬 설치</a></li>
          <li><a href="#pyspark-설치" id="markdown-toc-pyspark-설치">pyspark 설치</a></li>
        </ul>
      </li>
      <li><a href="#spark" id="markdown-toc-spark">Spark</a></li>
    </ul>
  </li>
  <li><a href="#로컬-개발-환경" id="markdown-toc-로컬-개발-환경">로컬 개발 환경</a></li>
  <li><a href="#클러스터-환경" id="markdown-toc-클러스터-환경">클러스터 환경</a></li>
</ul>

<hr />

<h1 id="스파크-설치">스파크 설치</h1>
<p>스파크를 설치하는 과정 자체는 크게 복잡하지 않습니다. <strong>자바와 스파크만 설치</strong>하면 스파크를 사용할 수 있습니다. 자바가 필요한 이유는 스파크가 JVM 위에서 실행되기 때문입니다.</p>

<p>하지만 실무에서는 대부분의 빅데이터 소프트웨어들이 클러스터 환경에서 동작하기 때문에 제대로 활용하기 위해서는 여러 가지 준비할 것도 많고 설정해야 할 것들도 많습니다. 그래서 스파크는 <strong>개발/테스트를 위한 용도로 간단하게 사용할 때에는 단독 서버에서 동작하는 로컬 모드를, 배포를 위한 용도로 클라이언트, 클러스터 모드를 지원</strong>합니다.</p>

<p>스파크 애플리케이션 코드는 <strong>자바, 스칼라, 파이썬, R</strong>언어로 작성할 수 있습니다.</p>

<h2 id="pyspark">pyspark</h2>
<p>우선 저는 파이썬을 주언어로 사용하기 때문에 pyspark를 이용해 파이썬으로 스파크 애플리케이션 코드를 작성할 예정입니다. pyspark의 장점은 만약 개발/테스트를 위한 목적으로만 스파크를 사용할 예정이라면 스파크를 설치할 필요가 없다는 것입니다. 스파크를 사용하는데 스파크를 설치할 필요가 없다? 무슨 뜻이냐면 pyspark를 설치하기만 해도 스파크를 실행하기 위해 필요한 최소한의 파일을 함께 설치해줍니다.</p>

<p>하지만 여전히 자바는 설치해주어야 합니다.</p>

<blockquote>
  <p>To run Spark, you only require a Java runtime environment (JRE) but you may also download the Java development kit (JDK) which includes the JRE.</p>
</blockquote>

<p>저는 <strong>파이썬이 설치되어 있는 도커 이미지를 이용해 컨테이너 안에서 실습</strong>을 진행해 보았습니다.</p>

<h3 id="자바-파이썬-설치">자바, 파이썬 설치</h3>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 파이썬이 설치된 컨테이너 생성</span>
docker run <span class="nt">-it</span> python:3.8-buster
</code></pre></div></div>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># JDK 설치</span>
apt-get update
apt-get <span class="nb">install </span>openjdk-11-jdk
</code></pre></div></div>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># JAVA_HOME 변수 설정, 경로 추가</span>


<span class="nb">export </span><span class="nv">JAVA_HOME</span><span class="o">=</span>/etc/openjdk-11-jdk     <span class="c"># 본인의 자바 설치 경로</span>
<span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$JAVA_HOME</span>/bin:<span class="nv">$PATH</span>
a
<span class="nb">.</span> /etc/profile <span class="c"># bash쉘이면 source /etc/profile</span>
</code></pre></div></div>
<h3 id="pyspark-설치">pyspark 설치</h3>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># pyspark 설치</span>
pip <span class="nb">install </span>pyspark
</code></pre></div></div>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 잘 설치되었는지 확인
</span><span class="kn">import</span> <span class="nn">pyspark</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">pyspark</span><span class="p">.</span><span class="n">SparkContext</span><span class="p">(</span><span class="n">appName</span><span class="o">=</span><span class="s">"SparkContext"</span><span class="p">)</span>

<span class="n">sc</span>
<span class="o">--------------------------------</span>
<span class="n">SparkContext</span>

<span class="n">Version</span>
<span class="n">v3</span><span class="p">.</span><span class="mf">2.1</span>
<span class="n">Master</span>
<span class="n">local</span><span class="p">[</span><span class="o">*</span><span class="p">]</span>
<span class="n">AppName</span>
<span class="n">SparkContext</span>
</code></pre></div></div>

<h2 id="spark">Spark</h2>
<p>이번에는 파이썬에 국한되지 않는 조금 더 일반적인 방법으로 스파크를 설치해보겠습니다. 이번에는 리눅스 운영체제만 가지는 컨테이너 위에서 실습을 진행하도록 하겠습니다.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 우분투 컨테이너 실행</span>
docker run <span class="nt">-it</span> ubuntu:latest
</code></pre></div></div>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># JDK 설치</span>
wget https://download.oracle.com/java/17/latest/jdk-17_linux-aarch64_bin.tar.gz
<span class="nb">tar</span> <span class="nt">-xzvf</span> jdk-17_linux-aarch64_bin.tar.gz
</code></pre></div></div>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># JAVA_HOME 변수 설정, 경로 추가</span>
<span class="nb">export </span><span class="nv">JAVA_HOME</span><span class="o">=</span>/root/jdk-17.0.2     <span class="c"># 본인의 자바 설치 경로</span>
<span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$JAVA_HOME</span>/bin:<span class="nv">$PATH</span>

<span class="nb">.</span> /etc/profile
</code></pre></div></div>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 스파크 설치</span>
wget https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz
<span class="nb">tar</span> <span class="nt">-xzvf</span> spark-3.2.1-bin-hadoop3.2.tgz
</code></pre></div></div>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd </span>spark-3.2.1-bin-hadoop3.2
<span class="nb">ls</span>
<span class="nt">----------------------------------------------------------------------------------</span>
LICENSE  NOTICE  R  README.md  RELEASE  bin  conf  data  examples  jars  kubernetes  licenses  python  sbin  yarn
</code></pre></div></div>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 스파크 셸 실행</span>
./bin/spark-shell
</code></pre></div></div>

<p><img src="../images/../../images/spark_8.png" alt="" /></p>

<h1 id="로컬-개발-환경">로컬 개발 환경</h1>

<h1 id="클러스터-환경">클러스터 환경</h1>

<ul>
  <li><a href="https://stackoverflow.com/questions/61816236/does-pyspark-code-run-in-jvm-or-python-subprocess" target="_blank">Pyspark 코드는 어디서 실행되는가?</a></li>
  <li><a href="https://stackoverflow.com/questions/51728177/can-pyspark-work-without-spark" target="_blank">Pyspark만으로 스파크 애플리케이션 실행할 수 있나?</a></li>
  <li><a href="https://stackoverflow.com/questions/58479357/pyspark-from-spark-installation-vs-pyspark-python-package" target="_blank">Pyspark의 한계</a></li>
  <li><a href="https://askubuntu.com/questions/1363992/bin-sh-1-source-not-found" target="_blank">bin/sh: 1: source: not found</a></li>
  <li><a href="https://unit-15.tistory.com/114?category=521121#recentComments" target="_blank">[Linux] 우분투에 자바 설치</a></li>
</ul>
:ET