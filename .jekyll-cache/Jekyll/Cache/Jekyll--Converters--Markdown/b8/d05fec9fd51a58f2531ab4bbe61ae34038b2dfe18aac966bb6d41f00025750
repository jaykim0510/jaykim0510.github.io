I"›5<hr />

<p id="toc"><strong>Table of Contents</strong></p>
<ul id="markdown-toc">
  <li><a href="#inter-service-communication" id="markdown-toc-inter-service-communication">Inter-Service Communication</a></li>
  <li><a href="#modes-of-communication" id="markdown-toc-modes-of-communication">Modes of communication</a></li>
  <li><a href="#synchronous-approach" id="markdown-toc-synchronous-approach">Synchronous Approach</a></li>
  <li><a href="#asynchronous-approach" id="markdown-toc-asynchronous-approach">Asynchronous Approach</a>    <ul>
      <li><a href="#best-of-both-worlds" id="markdown-toc-best-of-both-worlds">Best of Both Worlds</a></li>
      <li><a href="#message-queues" id="markdown-toc-message-queues">Message Queues</a></li>
    </ul>
  </li>
  <li><a href="#protocols-for-communication" id="markdown-toc-protocols-for-communication">Protocols for communication</a>    <ul>
      <li><a href="#how-clients-and-servers-interact" id="markdown-toc-how-clients-and-servers-interact">How clients and servers interact</a></li>
      <li><a href="#http" id="markdown-toc-http">HTTP</a></li>
      <li><a href="#websocket" id="markdown-toc-websocket">WebSocket</a></li>
    </ul>
  </li>
</ul>

<hr />
<h1 id="inter-service-communication">Inter-Service Communication</h1>

<p>In this article, we will be looking at how services interact with each other. Why is this important? Well, when you have a huge system with a lot of microservices interacting with each other, their communication needs to be efficient to provide the best user experience and also to avoid any cascading effects across the system.</p>

<h1 id="modes-of-communication">Modes of communication</h1>
<p>There are primarily two modes of communication between services:</p>

<ul>
  <li>
    <p><strong>Synchronous</strong>: When a service <strong>waits</strong> for a downstream system to respond before responding back to the client with a success or failure response.</p>
  </li>
  <li>
    <p><strong>Asynchronous</strong>: This is a more of a fire and forget approach. A service will fire a call to the downstream system and wonâ€™t track it further.</p>
  </li>
</ul>

<h1 id="synchronous-approach">Synchronous Approach</h1>
<p>Letâ€™s say you are building Amazon. You have a user U1 trying to place an order. U1 will reach out to the Order Service. Order Service will now talk to the Inventory Service to find out if a sufficient quantity of the product is available. If that is the case, Inventory Service will send a success response. Otherwise, it will respond with an error, and Order Service will respond to the user saying the order could not be placed.</p>

<p>Now if the inventory response was a success, the Order Service will talk to the Payment Service to process the payment. Once the payment is successful, the Order Service will now talk to the Warehouse Service asking it to start packing and prepare for shipping the product to the user. Once Warehouse Service responds with a success, the Order Service will talk to a Notification Service to send an email to the user saying their order has been placed, with so and so payment details and sharing an ETA for the delivery of the product.</p>

<p><img src="/images/system_design_3.png" alt="" /></p>

<p>Now, this is a happy scenario. What happens when one of the calls fails? Well, it depends on which call fails. If the call to Notification Service fails, does it make sense to cancel the order? No. We shouldnâ€™t cancel an order just because the Notification Service failed. However, what if payment fails? Now we definitely need to cancel the order. But now we need to update the Inventory again to undo the change to the product quantity. What if the call to Inventory Service fails?</p>

<p>So as you can see, there are some loopholes in a purely synchronous approach.</p>

<ul>
  <li>It has very high latency as the user does not get notified until all the calls have come back with a success or failure response.</li>
  <li>The system is tightly coupled, and any failure will have cascading effects across the board.</li>
  <li>The code becomes very complex since we need to handle all the cascading error scenarios.</li>
  <li>Due to complexity, it requires extremely high maintenance.</li>
</ul>

<h1 id="asynchronous-approach">Asynchronous Approach</h1>
<p>Let us see what happens in a purely asynchronous approach.</p>

<p><img src="/images/system_design_4.png" alt="" /></p>

<p>U1 sends a call to the Order Service which makes asynchronous calls to all the downstream systems. In such a case, even if Inventory Service responds with an error code, or even if the payment fails, the order would get placed. Which is an even bigger mess! So how do we go about this?</p>

<p>Well, as we can see, some parts of this process must be mandatory, and some can be done on a best-effort basis. If the Inventory Service or Payment Service responds with an error, we cannot place the order. But if the notification does not go through or the Warehouse Service is temporarily down, we donâ€™t need to cancel our order. So we can follow a hybrid approach here; <strong>use a synchronous approach for the mandatory steps and an asynchronous approach for the rest.</strong></p>

<h2 id="best-of-both-worlds">Best of Both Worlds</h2>
<p>The Hybrid approach suggests that the mandatory tasks need to be performed in a synchronous manner and everything else can be done asynchronously.</p>

<p>So Order Service will send out a synchronous call to Inventory Service, and wait for a response. In case of success, it will call the Payment Service. If the Payment Service gives a successful response, Order Service will make parallel asynchronous calls to the Warehouse Service and Notification Service and, at the same time, respond to the user saying the order has been placed. If the Payment Service call had failed, Order Service would send an asynchronous call to the Inventory Service reverting the quantity change.</p>

<p>So this looks like a much better solution. There are still some misses here though. What if the asynchronous call to Warehouse Service failed? It would lose the details for that order. This is where we would use <strong>Message Queues</strong>.</p>

<h2 id="message-queues">Message Queues</h2>
<p>Message Queues(Kafka, RabbitMQ, ActiveMQ ë“±) are highly fault-tolerant and persist messages for some time. How a message Queue works is, it has some Publishers adding messages to it, and some Subscribers listening to it and picking up the events meant for them at their own pace. Since these queues store messages for some time, if a subscriber is temporarily down, the messages will remain in the queue and will be picked up when the subscriber is running again.</p>

<p><img src="/images/system_design_5.png" alt="" /></p>

<p>So now, when Order Service wants to make asynchronous calls to Warehouse and Notification services, it will instead put an event in the Message Queue. Warehouse Service and Notification Service, which will be listening to the queue, will pick up the events meant for them. If one of the systems is down, the messages will remain in the queue until the service is back up and ready to receive messages again. This way, none of the data gets lost.</p>

<h1 id="protocols-for-communication">Protocols for communication</h1>

<p>In this article, we will look at the protocols we can use to interact with clients.</p>

<h2 id="how-clients-and-servers-interact">How clients and servers interact</h2>

<p>In a real-world scenario, rather than talking to a specific server, the clientâ€™s request will instead be sent to a data center, where it could be picked up by any of the servers. However, irrespective of which server receives the request, the response will be the same. Based on this flow, we can draw the following conclusions about this architecture:</p>

<ul>
  <li>It is client-driven. Only on the userâ€™s button click will the client send the requests to the server, and the server will only respond to these requests.</li>
  <li>It is a simple request-response model. For every request from the client, the server will respond with some information or a simple confirmation.</li>
  <li>There are occasional requests from clients, only one request every few seconds based on the userâ€™s actions i.e. from the client-side it is a low throughput system.</li>
  <li>It is a stateless system i.e. irrespective of which server is responding, the response remains the same.</li>
</ul>

<h2 id="http">HTTP</h2>

<p>These requirements make this a perfect use case for HTTP(s) protocol. Although these days, most architectures on HTTP have moved to HTTPS, which is a more secure version of HTTP as it prevents man-in-the-middle attacks.</p>

<p>Now, when we are using HTTP, REST is usually the best API standard to follow as it is very widely used and very user friendly.</p>

<p>Let us look at an example for a REST request and response:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Request:
Method: GET
URL: https://www.twitter.com/user/{id}

Response:
Status: 200 OK
Headers: &lt;...&gt;
Body: {
    â€œuserIdâ€: 1,
    â€œEmailâ€: â€œsomeone@example.comâ€
}
</code></pre></div></div>

<p>The client makes a request to twitter.com over HTTPS to get information about a user with an id. In response, the server sends a success status code along with the userâ€™s user id and email. As you can see, REST API standard is pretty much self-documenting, which adds to its user friendliness.</p>

<p>Now let us look at an example of a chat application.</p>

<p><img src="/images/system_design_6.png" alt="" /></p>

<p>We know that HTTP is a client-driven protocol, so the server cannot initiate any contact with the client. It can only respond to the client upon receiving a request. So when U1 sends a message to U2 via chat server, U2 doesnâ€™t receive the message until it asks the server to share any pending messages. This leads to a delay when receiving messages.</p>

<p>A solution to this would be that U2 sends frequent requests to the chat server in the hopes of receiving a message. But this puts a huge load on the chat server as it will receive a huge number of requests from all its clients.</p>

<p>The best approach would be <strong>if the server could send a notification to the user every time there is a message</strong>. For this, we use a protocol called <strong>WebSocket</strong>.</p>

<p>(ì„œë²„ê°€ U2ì—ê²Œ ë³´ë‚¼ ë©”ì‹œì§€ë¥¼ ê°€ì§€ê³  ìˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³ , ëŠ¥ë™ì ìœ¼ë¡œ U2ì—ê²Œ ë³´ë‚´ì§€ ì•ŠëŠ”ë‹¤. U2ë¡œë¶€í„° requestë¥¼ ë°›ì„ë•Œê¹Œì§€ ê¸°ë‹¤ë¦°ë‹¤.)<br />
(U2ëŠ” ì–¸ì œ ìì‹ ì´ ë°›ì•„ì•¼í•  ë©”ì‹œì§€ê°€ ì„œë²„ì— ë„ì°©í–ˆëŠ”ì§€ ëª¨ë¥´ë¯€ë¡œ, ê³„ì† ì„œë²„ì— requestë¥¼ ë³´ë‚´ì•¼ í•œë‹¤.)<br />
(WebSocketì„ ì‚¬ìš©í•˜ë©´ ì„œë²„ëŠ” U2ì™€ connectionë˜ì–´ ìˆìœ¼ë©´ requestë¥¼ ë°›ì§€ ì•Šì•„ë„ ì•Œì•„ì„œ U2ì— ë©”ì‹œì§€ë¥¼ ë³´ë‚¸ë‹¤)<br />
(connectionë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´, ê°€ë§Œíˆ ìˆë‹¤ê°€, connectionë˜ê³  U2ê°€ requestë³´ë‚´ë©´ ë©”ì‹œì§€ ë³´ë‚¸ë‹¤)<br />
(WebSocketì—ë„ ë‹¨ì ì€ ìˆë‹¤. cost of maintaining a persistent connection with millions of users.)</p>

<h2 id="websocket">WebSocket</h2>
<p>A WebSocket connection is a persistent connection. It is also a bidirectional protocol, where communication can be initiated by the client or the server as long as there is an open connection. It is <strong>optimized for high-frequency communication</strong>.</p>

<p>Letâ€™s look at how our chat application would work in the case of WebSocket protocol.</p>

<p><img src="/images/system_design_7.png" alt="" /></p>

<p>First, U1 and U2 will establish HTTP connections with the chat server, which are then upgraded to a WebSocket connection. When U1 sends a message for U2 via the chat server, it will store the message along with its status, RECEIVED, letâ€™s say.</p>

<p>The chat server, if it has an open connection with U2, will then send the message to U2 and update the status to SENT. If U2 was not online and there was no open connection between U2 and the server, the messages will be saved until U2 comes online and requests the server to send all pending messages. The server will send all messages with the status RECEIVED and update the status to SENT.</p>

<p>As you can see, with this approach we have:</p>

<ul>
  <li>Reduced the latency, since the server can simply send the messages over an open connection</li>
  <li>Saved on CPU and bandwidth, as the client doesnâ€™t need to unnecessarily send requests to the server and the server is not under unnecessary load</li>
  <li>Provided better user experience</li>
</ul>

<p>Even with the benefits, there is a high cost to using WebSockets; that is the cost of maintaining a persistent connection with millions of users.</p>

<p>So how do we decide whether to use HTTP or WebSocket? Do we always go for Websocket then? Well, not really, as WebSocket is much more expensive than HTTP. We can safely say, if the communication between client and server is at a <strong>lower throughput on the client-side</strong>, HTTP is the way to go. <strong>If the communication is always client-driven</strong>, WebSocket is not needed. Also, if you are on a <strong>tight budget</strong>, HTTP may be the better choice.</p>

<p>On the other hand, if the communication from the <strong>client is at a higher throughput</strong>, WebSocket may be a better option. If the <strong>communication can be driven by both client and server</strong>, WebSocket is the way to go. Although here comes the tradeoff between cost and performance. We must decide if the optimization is really worth the huge cost of maintaining persistent connections with so many users.</p>
:ET