I"1<hr />

<p id="toc"><strong>Table of Contents</strong></p>
<ul id="markdown-toc">
  <li><a href="#대용량-데이터-처리" id="markdown-toc-대용량-데이터-처리">대용량 데이터 처리</a></li>
  <li><a href="#분산-시스템" id="markdown-toc-분산-시스템">분산 시스템</a></li>
  <li><a href="#hadoop" id="markdown-toc-hadoop">Hadoop</a></li>
</ul>

<hr />

<h1 id="대용량-데이터-처리">대용량 데이터 처리</h1>

<ul>
  <li>우리는 데이터 시대에 살고 있다</li>
  <li>
    <p>매년 모든 분야에서 데이터가 발생하고 있고, 모든 기기에서 데이터가 발생하고 있으며, 모든 생명체에서 데이터가 발생하고 있다</p>
  </li>
  <li>이러한 대용량 데이터를 처리하는데 있어 어떤 점이 어려울까</li>
  <li>모든 문제는 <strong>단일 시스템의 한계점</strong>에서 비롯된다</li>
  <li>단일 서버에 저장 -&gt; 기존 디스크의 용량이 다 차게되면 더 큰 용량을 갖는 새로운 디스크로 데이터를 옮겨야 한다</li>
  <li>단일 서버에 쓰기/읽기 -&gt; 데이터량이 많아지고, 유저가 많아지면 그에 맞는 컴퓨팅 자원(CPU, 메모리)이 필요 -&gt; 한계가 있음</li>
  <li>단일 서버에 장애가 난 경우 -&gt; 일시적으로 데이터에 접근 불가, 최악의 경우 데이터 자체를 모두 잃을 수도 있다</li>
  <li>
    <p>갑자기 트래픽량이 증가하는 경우 -&gt; 아주 일시적으로 폭발하는 트래픽량을 수용하기 위해 비싼 리소스 소모 -&gt; 자원 낭비</p>
  </li>
  <li>이를 위해 <strong>분산 시스템</strong>으로 넘어가야 한다</li>
  <li>하지만 분산 시스템에는 아무런 문제가 없는 것은 아니다</li>
  <li>분산 시스템은 위의 문제점을 해결해주지만 분산 시스템으로 인해 생기는 어려운 점도 있다</li>
</ul>

<h1 id="분산-시스템">분산 시스템</h1>

<ul>
  <li><strong>분산 시스템의 핵심은 복제 저장, 분산 저장/처리이다</strong></li>
  <li>
    <p>위의 모든 문제를 해결하고 결과적으로 <strong>Scale-Out, 분산 저장/처리, 높은 가용성</strong>과 같은 특성들을 제공해준다</p>
  </li>
  <li>분산 시스템에서 <strong>어려운 점은 시스템 일부에 생기는 하드웨어, 네트워크의 장애</strong>에서 비롯된다</li>
  <li>우선 분산 처리/저장을 할 때 최대한 네트워크 비용 자체를 줄여야 한다 (네트워크 비용은 디스크 I/O보다도 훨씬 더 큰 작업이다)</li>
  <li>일부 시스템에 장애가 발생했을 때에 대한 대비책을 만들어야 한다</li>
  <li>분산 시스템에는 높은 가용성을 위한 Replication도 있고, 분산 처리를 위한 Partition도 있다
    <ul>
      <li>Replication 간에는 동기화가 잘 되어야 한다 -&gt; <strong>합의 알고리즘</strong>(리더 선출, 데이터 동기화)을 알아야 한다</li>
      <li>Partition 간에는 최소한의 네트워크 비용이 발생하도록 해야 한다 -&gt; <strong>파티셔닝</strong>, <strong>Lazy Operation</strong>을 알아야 한다</li>
    </ul>
  </li>
</ul>

<h1 id="hadoop">Hadoop</h1>

<ul>
  <li>빅데이터 처리를 위한 다양한 소프트웨어 제공</li>
  <li>하둡은 개발자 더크 커팅이 처음으로 시작</li>
  <li>구글이 발표한 분산 파일 저장을 위한 논문 GFS, 분산 데이터 처리를 위한 MapReduce 논문을 발표</li>
  <li>더그 커팅이 구글에서 발표한 논문을 구현해 하둡 프로젝트가 시작됨 -&gt; HDFS와 MapReduce가 하둡 프로젝트에 포함</li>
  <li>이 후 빅데이터 처리를 위한 다양한 소프트웨어 Hive, HBase, Cassandra, Yarn 등이 등장하여 하둡 생태계 구성</li>
</ul>

<p><img src="/images/hadoop_1.png" alt="" /></p>

:ET