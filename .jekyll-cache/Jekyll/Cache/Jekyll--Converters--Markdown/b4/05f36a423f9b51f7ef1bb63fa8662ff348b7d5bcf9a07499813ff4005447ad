I"<hr />

<p id="toc"><strong>Table of Contents</strong></p>
<ul id="markdown-toc">
  <li><a href="#참고" id="markdown-toc-참고">참고</a></li>
</ul>

<hr />

<p>ES와 Spark 컨테이너 실행</p>

<div class="language-yml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">version</span><span class="pi">:</span> <span class="s1">'</span><span class="s">3.2'</span>

<span class="na">services</span><span class="pi">:</span>
  <span class="na">elasticsearch</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">elasticsearch:7.16.2</span>
    <span class="na">hostname</span><span class="pi">:</span> <span class="s">elasticsearch</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">9200:9200"</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">9300:9300"</span>
    <span class="na">environment</span><span class="pi">:</span>
      <span class="na">ES_JAVA_OPTS</span><span class="pi">:</span> <span class="s2">"</span><span class="s">-Xmx256m</span><span class="nv"> </span><span class="s">-Xms256m"</span>
      <span class="na">ELASTIC_PASSWORD</span><span class="pi">:</span> <span class="s">changeme</span>
      <span class="na">ELASTIC_USERNAME</span><span class="pi">:</span> <span class="s">elastic</span>
      <span class="na">discovery.type</span><span class="pi">:</span> <span class="s">single-node</span>
  
  <span class="na">spark</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">kimziont:spark</span>
    <span class="na">hostname</span><span class="pi">:</span> <span class="s">spark</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">4040:4040"</span>
    <span class="na">tty</span><span class="pi">:</span> <span class="no">true</span>
</code></pre></div></div>

<p>Spark에서 ElasticSearch를 쓰려면 커넥터가 필요한 것 같다. Elastic에서 이를 위해 elasticsearch-hadoop를 제공하는데 우선 다운을 받아야 한다.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://artifacts.elastic.co/downloads/elasticsearch-hadoop/elasticsearch-hadoop-6.4.1.zip
unzip elasticsearch-hadoop-6.4.1.zip
<span class="nb">mkdir</span> <span class="nt">-p</span> /app/spark/jars/ext/elasticsearch-hadoop
<span class="nb">mv </span>elasticsearch-hadoop-6.4.1 /app/spark/jars/ext/elasticsearch-hadoop/6.4.1
</code></pre></div></div>

<p>설치가 완료되었으면 스파크를 실행할 때 설치한 경로를 실행 인자로 주면되는 것 같다.</p>

<p>pyspark에서 사용할 때는 아래와 같다.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># pyspark 실행 커맨드</span>
pyspark <span class="nt">--driver-class-path</span><span class="o">=</span>/app/spark/jars/ext/elasticsearch-hadoop/6.4.1/dist/elasticsearch-hadoop-6.4.1.jar
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SQLContext</span>

<span class="n">sqlContext</span> <span class="o">=</span> <span class="n">SQLContext</span><span class="p">(</span><span class="n">sc</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="s">"org.elasticsearch.spark.sql"</span><span class="p">).</span><span class="n">option</span><span class="p">(</span><span class="s">"es.nodes"</span><span class="p">,</span><span class="s">"192.168.179.141:9200"</span><span class="p">).</span><span class="n">option</span><span class="p">(</span><span class="s">"es.nodes.discovery"</span><span class="p">,</span> <span class="s">"true"</span><span class="p">).</span><span class="n">load</span><span class="p">(</span><span class="s">"${INDEX}/${TYPE}"</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">registerTempTable</span><span class="p">(</span><span class="s">"tab"</span><span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="p">.</span><span class="n">sql</span><span class="p">(</span><span class="s">"SELECT distinct request FROM tab"</span><span class="p">)</span>
<span class="n">output</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p>spark-shell을 사용할 때는 아래와 같다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spark-shell --jars /app/spark/jars/ext/elasticsearch-hadoop/6.4.1/dist/elasticsearch-hadoop-6.4.1.jar
</code></pre></div></div>

<h1 id="참고">참고</h1>

<ul>
  <li>
    <p><a href="https://docs.docker.com/engine/reference/builder/#cmd" target="_blank">Docker 공식문서</a></p>
  </li>
  <li><a href="https://oboki.net/workspace/python/pyspark-elasticsearch-index-에서-dataframe-생성하기/" target="_blank">Spark와 ElasticSearch 연동하기</a></li>
  <li><a href="https://github.com/elastic/elasticsearch-hadoop" target="_blank">elasticsearch-hadoop</a></li>
</ul>
:ET