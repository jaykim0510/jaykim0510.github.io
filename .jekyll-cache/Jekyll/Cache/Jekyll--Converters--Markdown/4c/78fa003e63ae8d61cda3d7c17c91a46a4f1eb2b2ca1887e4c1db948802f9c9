I"YI<hr />

<p id="toc"><strong>Table of Contents</strong></p>
<ul id="markdown-toc">
  <li><a href="#하둡-클러스터-설정" id="markdown-toc-하둡-클러스터-설정">하둡 클러스터 설정</a></li>
  <li><a href="#하둡-설정-파일" id="markdown-toc-하둡-설정-파일">하둡 설정 파일</a></li>
  <li><a href="#메모리" id="markdown-toc-메모리">메모리</a></li>
  <li><a href="#중요한-hdfs-데몬-속성" id="markdown-toc-중요한-hdfs-데몬-속성">중요한 HDFS 데몬 속성</a></li>
  <li><a href="#도커-컴포즈" id="markdown-toc-도커-컴포즈">도커 컴포즈</a></li>
  <li><a href="#참고" id="markdown-toc-참고">참고</a></li>
</ul>

<hr />

<h1 id="하둡-클러스터-설정">하둡 클러스터 설정</h1>

<ul>
  <li>
    <p>하둡 제어 스크립트는 SSH를 이용해 전체 클러스터를 대상으로 작업을 수행하도록 개발되었다</p>
  </li>
  <li>
    <p>HDFS 파일시스템 포맷: 포맷 작업은 새로운 빈 파일시스템을 생성하는 것이다. 네임노드가 파일시스템의 모든 메타데이터를 관리하는 반면, 데이터 노드는 클러스터에 동적으로 추가되고 제거되기 때문에 초기 포맷 과정에 전혀 관여하지 않는다.</p>
  </li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hdfs namenode -format
</code></pre></div></div>

<ul>
  <li>클러스터에 있는 호스트 목록은 <code class="language-plaintext highlighter-rouge">workers</code> 파일에 저장한다. <code class="language-plaintext highlighter-rouge">workers</code> 파일에는 데이터노드와 노드 매니저가 구동될 컴퓨터를 기록한다</li>
  <li>데몬 시작</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>start-dfs.sh
</code></pre></div></div>

<ul>
  <li>리소스 매니저는 <code class="language-plaintext highlighter-rouge">start-yarn.sh</code> 스크립트가 수행된 머신에서만 실행된다</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>start-yarn.sh
</code></pre></div></div>

<h1 id="하둡-설정-파일">하둡 설정 파일</h1>

<ul>
  <li>hadoop-env.sh: 하둡을 구동하는 스크립트에서 사용되는 환경변수</li>
  <li>mapred-env.sh: 맵리듀스를 구동하는 스크립트에서 사용되는 환경변수</li>
  <li>yarn-env.sh: YARN을 구동하는 스크립트에서 사용되는 환경변수</li>
  <li>core-site.xml: HDFS, 맵리듀스, YARN에서 공통적으로 사용되는 하둡 환경 설정 구성</li>
  <li>hdfs-site.xml: 네임노드, 보조 네임노드, 데이터노드 등과 같은 HDFS를 위한 환경 설정 구성</li>
  <li>workers: 데이터노드와 노드 맴니저를 구동할 컴퓨터 목록</li>
</ul>

<p>위 파일들은 <code class="language-plaintext highlighter-rouge">./etc/hadoop</code> 에 있다</p>

<ul>
  <li>하둡은 모든 마스터와 워커 컴퓨터가 하나의 환경 설정 파일 집합을 사용할 수 있도록 설계되었다</li>
  <li>(마스터와 워커가 각각 따로 파일을 가질 필요가 없다)</li>
</ul>

<h1 id="메모리">메모리</h1>

<ul>
  <li>하둡은 각 데몬 당 1GB의 메모리를 기본으로 할당한다 (<code class="language-plaintext highlighter-rouge">hadoop-env.sh</code>의 <code class="language-plaintext highlighter-rouge">HADOOP_HEAPSIZE</code>)</li>
  <li>HDFS에서 메모리 용량을 증가시켜야 하는 경우는 보통 네임노드다 (블록에 대한 참조값을 모두 네임노드의 메모리에서 관리하기 때문)</li>
  <li>(<code class="language-plaintext highlighter-rouge">hadoop-env.sh</code>의 <code class="language-plaintext highlighter-rouge">HADOOP_NAMENODE_OPTS</code> 속성을 이용해 조절할 수 있다)</li>
  <li>(네임노드와 보조 네임노드는 동일하게 변경되어야 한다)</li>
</ul>

<h1 id="중요한-hdfs-데몬-속성">중요한 HDFS 데몬 속성</h1>

<table>
  <thead>
    <tr>
      <th style="text-align: center">속성명</th>
      <th style="text-align: center">기본값</th>
      <th style="text-align: center">설명</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">fs.defaultFS</td>
      <td style="text-align: center">file:///</td>
      <td style="text-align: center">기본 파일시스템. URI는 호스트명과 네임노드의 RPC 서버가 실행되는 포트 번호(기본값 8020)를 정의한다.</td>
    </tr>
    <tr>
      <td style="text-align: center">dfs.namenode.name.dir</td>
      <td style="text-align: center">file://${hadoop.tmp.dir}/dfs/name</td>
      <td style="text-align: center">네임노드가 영속적인 메타데이터를 지정할 디렉토리 목록을 지정한다. 네임노드는 메타데이터의 복제본을 목록에 디렉터리별로 저장한다</td>
    </tr>
    <tr>
      <td style="text-align: center">dfs.datanode.data.dir</td>
      <td style="text-align: center">file://${hadoop.tmp.dir}/dfs/data</td>
      <td style="text-align: center">데이터노드가 블록을 저장할 디렉터리의 목록. 각 븍록은 이 디렉터리중 오직 한 곳에만 저장된다.</td>
    </tr>
    <tr>
      <td style="text-align: center">dfs.namenode.checkpoint.dir</td>
      <td style="text-align: center">file://${hadoop.tmp.dir}/dfs/namesecondary</td>
      <td style="text-align: center">보조 네임노드가 체크포인트를 저장하는 디렉터리 목록. 목록에 있는 각 디렉터리에 체크포인트의 복제본을 저장한다</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>HDFS의 저장 디렉터리는 <code class="language-plaintext highlighter-rouge">hadoop.tmp.dir</code> 하위에 위치한다. (기본값은 <code class="language-plaintext highlighter-rouge">/tmp/hadoop-${user.name}</code>)</li>
  <li>hdfs-site.xml의 dfs.blocksize 속성을 이용해 HDFS 블록크기를 설정한다</li>
  <li>
    <p>HDFS는 휴지통 기능이 있어 삭제된 파일이 <code class="language-plaintext highlighter-rouge">trash</code> 디렉터리로 이동한다. <code class="language-plaintext highlighter-rouge">trash</code> 디렉터리에 보관되는 최소 기간은 <code class="language-plaintext highlighter-rouge">core-site.xml</code>의 <code class="language-plaintext highlighter-rouge">fs.trash.interval</code>로 설정한다. 기본값은 0으로 삭제하면 즉시 영구 삭제됨을 의미한다</p>
  </li>
  <li>java8 설치</li>
  <li>hadoop 3.2.4 설치</li>
  <li>JAVA_HOME, HADOOP_HOME, PATH 환경변수 설정
    <ul>
      <li><code class="language-plaintext highlighter-rouge">export JAVA_HOME=/opt/jdk</code></li>
      <li><code class="language-plaintext highlighter-rouge">export HADOOP_HOME=/opt/hadoop</code></li>
      <li><code class="language-plaintext highlighter-rouge">export PATH=${PATH}:/${JAVA_HOME}/bin:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin</code></li>
    </ul>
  </li>
  <li>노드 종류 상관 없이 공통 항목 설정후 ziontkim0510/hadoop3.2.4:1.0 이미지로 빌드
    <ul>
      <li>노드에서 저장할 데이터 디렉터리 생성
        <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> <span class="k">${</span><span class="nv">HADOOP_HOME</span><span class="k">}</span>/data/hdfs/namenode
<span class="nb">mkdir</span> <span class="nt">-p</span> <span class="k">${</span><span class="nv">HADOOP_HOME</span><span class="k">}</span>/data/hdfs/datanode
<span class="nb">mkdir</span> <span class="nt">-p</span> <span class="k">${</span><span class="nv">HADOOP_HOME</span><span class="k">}</span>/data/hdfs/secondarynode
<span class="nb">mkdir</span> <span class="nt">-p</span> <span class="k">${</span><span class="nv">HADOOP_HOME</span><span class="k">}</span>/data/yarn/nm-local-dir
<span class="nb">mkdir</span> <span class="nt">-p</span> <span class="k">${</span><span class="nv">HADOOP_HOME</span><span class="k">}</span>/data/yarn/system/rmstore
</code></pre></div>        </div>
      </li>
      <li><code class="language-plaintext highlighter-rouge">${HADOOP_HOME}/etc/hadoop/hadoop-env.sh</code> 파일
        <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">JAVA_HOME</span><span class="o">=</span>/opt/jdk

<span class="nb">export </span><span class="nv">HDFS_NAMENODE_USER</span><span class="o">=</span><span class="s2">"root"</span>
<span class="nb">export </span><span class="nv">HDFS_DATANODE_USER</span><span class="o">=</span><span class="s2">"root"</span>
<span class="nb">export </span><span class="nv">HDFS_SECONDARYNAMENODE_USER</span><span class="o">=</span><span class="s2">"root"</span>
<span class="nb">export </span><span class="nv">YARN_RESOURCEMANAGER_USER</span><span class="o">=</span><span class="s2">"root"</span>
<span class="nb">export </span><span class="nv">YARN_NODEMANAGER_USER</span><span class="o">=</span><span class="s2">"root"</span>

<span class="nb">export </span><span class="nv">HADOOP_LOG_DIR</span><span class="o">=</span>/var/log/hadoop
</code></pre></div>        </div>
      </li>
      <li><code class="language-plaintext highlighter-rouge">${HADOOP_HOME}/etc/hadoop/core-site.xml</code> 파일
        <div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span class="cp">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>

<span class="nt">&lt;configuration&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>fs.defaultFS<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>hdfs://hdfs-name-node:8020<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></div>        </div>
      </li>
      <li><code class="language-plaintext highlighter-rouge">${HADOOP_HOME}/etc/hadoop/hdfs-site.xml</code> 파일
        <div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span class="cp">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>
        
<span class="nt">&lt;configuration&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.namenode.name.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>file:/opt/hadoop/data/hdfs/namenode<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.datanode.data.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>file:/opt/hadoop/data/hdfs/datanode<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.namenode.checkpoint.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>file:/opt/hadoop/data/hdfs/secondarynode<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></div>        </div>
      </li>
      <li><code class="language-plaintext highlighter-rouge">${HADOOP_HOME}/etc/hadoop/yarn-site.xml</code> 파일
        <div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">&lt;?xml version="1.0"?&gt;</span>

<span class="nt">&lt;configuration&gt;</span>

<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>yarn.nodemanager.aux-services<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>mapreduce_shuffle<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>yarn.nodemanager.local-dirs<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>/opt/hadoop/data/yarn/nm-local-dir<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>yarn.resourcemanager.fs.state-store.uri<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>/opt/hadoop/data/yarn/system/rmstore<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>yarn.resourcemanager.hostname<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>hdfs-name-node<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>yarn.resourcemanager.address<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>hdfs-name-node:8032<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>

</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>네임노드, 세컨더리 노드 설정후 ziontkim0510/hadoop-name-3.2.4:1.0, ziontkim0510/hadoop-secondary-3.2.4:1.0 이미지로 빌드
    <ul>
      <li>HDFS 파일 시스템 포맷: 네임 노드에서 <code class="language-plaintext highlighter-rouge">hdfs namenode -format</code> 명령어 실행</li>
      <li><code class="language-plaintext highlighter-rouge">${HADOOP_HOME}/etc/hadoop/workers</code> 파일에 데이터 노드 추가
        <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># workers</span>
hdfs-data-node-1
hdfs-data-node-2
</code></pre></div>        </div>
      </li>
      <li>ssh 키 생성 후 설정: <code class="language-plaintext highlighter-rouge">ssh-keygen -t rsa</code></li>
    </ul>
  </li>
  <li>데이터 노드 설정후 ziontkim0510/hadoop-data-3.2.4:1.0 이미지로 빌드
    <ul>
      <li>네임노드에서 생성한 퍼블릭 키 복사 붙여넣기</li>
    </ul>
  </li>
</ul>

<h1 id="도커-컴포즈">도커 컴포즈</h1>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">version</span><span class="pi">:</span> <span class="s1">'</span><span class="s">3.2'</span>
<span class="na">services</span><span class="pi">:</span>
  <span class="na">hdfs-name-node</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">ziontkim0510/hadoop-name-3.2.4:1.0</span>
    <span class="na">hostname</span><span class="pi">:</span> <span class="s">hdfs-name-node</span>
    <span class="na">container_name</span><span class="pi">:</span> <span class="s">hdfs-name-node</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">9870:9870</span>
    <span class="na">command</span><span class="pi">:</span> 
      <span class="pi">-</span> <span class="s">bash</span>
      <span class="pi">-</span> <span class="s">-c</span> 
      <span class="pi">-</span> <span class="pi">|</span>
        <span class="s">/etc/init.d/ssh restart &amp;</span>
        <span class="s">./${HADOOP_HOME}/sbin/start-dfs.sh &amp;</span>
        <span class="s">./${HADOOP_HOME}/sbin/start-yarn.sh &amp;</span>
        <span class="s">sleep infinity</span>
    <span class="na">depends_on</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">hdfs-data-node-1</span>
      <span class="pi">-</span> <span class="s">hdfs-data-node-2</span>

  <span class="na">hdfs-secondary-node</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">ziontkim0510/hadoop-secondary-3.2.4:1.0</span>
    <span class="na">hostname</span><span class="pi">:</span> <span class="s">hdfs-secondary-node</span>
    <span class="na">container_name</span><span class="pi">:</span> <span class="s">hdfs-secondary-node</span>
    <span class="na">tty</span><span class="pi">:</span> <span class="no">true</span>

  <span class="na">hdfs-data-node-1</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">ziontkim0510/hadoop-data-3.2.4:1.0</span>
    <span class="na">hostname</span><span class="pi">:</span> <span class="s">hdfs-data-node-1</span>
    <span class="na">container_name</span><span class="pi">:</span> <span class="s">hdfs-data-node-1</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">9860:9864</span>
    <span class="na">command</span><span class="pi">:</span> 
      <span class="pi">-</span> <span class="s">bash</span>
      <span class="pi">-</span> <span class="s">-c</span> 
      <span class="pi">-</span> <span class="pi">|</span>
        <span class="s">/etc/init.d/ssh restart &amp;</span>
        <span class="s">sleep infinity</span>

  <span class="na">hdfs-data-node-2</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">ziontkim0510/hadoop-data-3.2.4:1.0</span>
    <span class="na">hostname</span><span class="pi">:</span> <span class="s">hdfs-data-node-2</span>
    <span class="na">container_name</span><span class="pi">:</span> <span class="s">hdfs-data-node-2</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">9861:9864</span>
    <span class="na">command</span><span class="pi">:</span> 
      <span class="pi">-</span> <span class="s">bash</span>
      <span class="pi">-</span> <span class="s">-c</span> 
      <span class="pi">-</span> <span class="pi">|</span>
        <span class="s">/etc/init.d/ssh restart &amp;</span>
        <span class="s">sleep infinity</span>
</code></pre></div></div>

<p><img src="/images/hdfs_10.png" alt="" /></p>

<h1 id="참고">참고</h1>

<ul>
  <li><a href="https://truman.tistory.com/207#recentComments" target="_blank">Truman Show, 리눅스(Linux) - 하둡(Hadoop) 설치 및 환경 설정</a></li>
  <li><a href="https://hoing.io/archives/22174#3" target="_blank">hoing, 하둡 프로그래밍(3) – 빅데이터 – 하둡 설치</a></li>
  <li><a href="https://velog.io/@hanovator/Hadoop-%EC%84%A4%EC%B9%98" target="_blank">hanovator, Hadoop 설치</a></li>
</ul>
:ET