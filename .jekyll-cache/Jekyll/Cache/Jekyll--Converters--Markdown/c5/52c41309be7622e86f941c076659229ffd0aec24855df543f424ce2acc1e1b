I"W<p id="toc"><strong>Table of Contents</strong></p>
<ul id="markdown-toc">
  <li><a href="#spark-introduction" id="markdown-toc-spark-introduction">Spark Introduction</a></li>
  <li><a href="#rdd" id="markdown-toc-rdd">RDD</a></li>
  <li><a href="#cluster-mode" id="markdown-toc-cluster-mode">Cluster Mode</a>    <ul>
      <li><a href="#shuffling" id="markdown-toc-shuffling">Shuffling</a></li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="spark-introduction">Spark Introduction</h1>
<p><strong>스파크는 클러스터 기반의 분산 처리 기능을 제공하는 오픈소스 프레임워크입니다.</strong> 쉽게 말해 대용량 데이터를 여러 컴퓨터에 나누어서 동시에 처리한다고 할 수 있습니다. 이런 방법이 스파크 이전에 없었던 것은 아닙니다. 스파크 이전에 하둡(Hadoop)이 이와 유사한 기능을 제공했었습니다. 
참고로 하둡은 더그 커팅(Doug Cutting)이라는 사람이 구글이 발표했던 두 개의 논문(<a href="https://static.googleusercontent.com/media/research.google.com/ko//archive/gfs-sosp2003.pdf"><strong>The Google File System_2003</strong></a>, <a href="https://dl.acm.org/doi/10.1145/1327452.1327492"><strong>MapReduce: simplified data processing on large clusters_2008</strong></a>)을 직접 구현해 만든 프레임워크입니다. 이처럼 구글에서는 예전부터 대용량의 데이터를 고속 분산처리 하기 위해 노력했었고, 현재 스파크는 대부분의 기업들이 사용하고 있는 소프트웨어입니다.</p>

<p>지금부터는 스파크와 하둡을 비교하며 스파크의 특징에 어떤 것이 있는지 알아보겠습니다.</p>

<table>
  <tbody>
    <tr>
      <td><strong>차이점</strong></td>
      <td><strong>하둡</strong></td>
      <td><strong>스파크</strong></td>
    </tr>
    <tr>
      <td>기반</td>
      <td>디스크 기반</td>
      <td>메모리 기반</td>
    </tr>
    <tr>
      <td>처리방식</td>
      <td>Map-Reduce</td>
      <td>RDD</td>
    </tr>
    <tr>
      <td>프로그래밍언어</td>
      <td>자바</td>
      <td>스칼라, 자바, 파이썬, R</td>
    </tr>
    <tr>
      <td>라이브러리</td>
      <td>-</td>
      <td>다양한 라이브러리(Spark streaming, MLlib, GraphX 등) 제공</td>
    </tr>
  </tbody>
</table>

<p>처리방식에 대해 조금 더 이야기 해보겠습니다. 맵리듀스(MapReduce)는 2004년 구글에서 대용량 데이터 처리를 분산환경에서 처리하기 위한 목적의 소프트웨어 프레임워크입니다. 맵리듀스는 함수형 프로그래밍에서 일반적으로 사용되는 Map과 Reduce라는 함수를 기반으로 만들어졌습니다. Map은 각각의 분산된 환경에서 독립적으로 실행되는 함수의 일종, Reduce는 분산 환경에서의 데이터를 하나로 모으는 함수라고 생각할 수 있습니다.</p>

<p><img src="../images/../../images/spark_1.png" alt="" /></p>

<p>맵리듀스는 분산된 환경에서 데이터가 처리되는데 필요한 많은 함수들을 제공해주지만, 현업에서 필요한 기능들을 모두 커버하기에는 무리가 있었습니다. 그래서 이러한 단점을 보완하기 위해 2009년 UC Berkeley 대학에서 연구를 시작해 2012년 미국 NSDI 학회에서 스파크의 핵심 개념인 <strong>RDD(Resilient Distributed Dataset)</strong> 에 대한 논문을 발표하였습니다.</p>

<h1 id="rdd">RDD</h1>
<blockquote>
  <p>RDD is a fault-tolerant collection of elements that can be operated on in parallel.<br />
다시 말하면 RDD란 스파크에서 정의한 <strong>분산 데이터 모델로서 병렬 처리가 가능한 요소</strong> 로 구성되며 데이터를 처리하는 과정에서 <strong>장애가 발생하더라도 스스로 복구할 수 있는 능력</strong> 을 가진 <strong>데이터 모델</strong> 이라는 뜻입니다. RDD는 분산 데이터에 대한 모델로서 단순히 값으로 표현되는 데이터만 가리키는 것이 아니고, 분산된 <strong>데이터를 다루는 방법까지 포함</strong> 하는 일종의 클래스와 같은 개념입니다.</p>
</blockquote>

<p>RDD에서 중요한 특징은 다음과 같습니다.</p>

<ul>
  <li>파티션(Partition)</li>
  <li>불변성</li>
  <li>게으른 연산(Lazy operation)</li>
</ul>

<h1 id="cluster-mode">Cluster Mode</h1>

<h2 id="shuffling">Shuffling</h2>
:ET