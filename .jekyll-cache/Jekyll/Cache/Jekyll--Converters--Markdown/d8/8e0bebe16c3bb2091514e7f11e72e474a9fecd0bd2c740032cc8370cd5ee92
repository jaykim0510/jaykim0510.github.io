I"<hr />
<p id="toc"><strong>Table of Contents</strong></p>
<ul id="markdown-toc">
  <li><a href="#why-connector" id="markdown-toc-why-connector">Why Connector?</a></li>
  <li><a href="#kafka-connect" id="markdown-toc-kafka-connect">Kafka Connect</a>    <ul>
      <li><a href="#kafka-connect-구성요소" id="markdown-toc-kafka-connect-구성요소">Kafka Connect 구성요소</a></li>
      <li><a href="#connect-connector" id="markdown-toc-connect-connector">Connect? Connector?</a></li>
      <li><a href="#standalone과-distributed-workers" id="markdown-toc-standalone과-distributed-workers">Standalone과 Distributed Workers</a></li>
    </ul>
  </li>
  <li><a href="#debezium" id="markdown-toc-debezium">Debezium</a></li>
  <li><a href="#참고" id="markdown-toc-참고">참고</a></li>
</ul>

<hr />

<h1 id="why-connector">Why Connector?</h1>

<p>커넥터 없이도 프로듀서 컨슈머 사용 가능</p>

<p>하지만 커넥터를 이용하면 카프카를 사용하면서 발생할 수 있는 장애에 대한 복구를 비롯한 필요한 기능들을 따로 개발할 필요없이 사용가능</p>

<p><img src="/images/kafka_56.png" alt="" /></p>

<h1 id="kafka-connect">Kafka Connect</h1>
<ul>
  <li>Kafka Connect는 다른 데이터 시스템을 Kafka와 통합하는 과정을 표준화한 프레임워크</li>
  <li>통합을 위한 Connector 개발, 배포, 관리를 단순화</li>
</ul>

<h2 id="kafka-connect-구성요소">Kafka Connect 구성요소</h2>
<ul>
  <li><strong>Connector</strong>: Task를 관리하여 데이터 스트리밍을 조정하는 jar파일</li>
  <li><strong>Task</strong>: 데이터 시스템간의 전송 방법을 구현한 구현체</li>
  <li><strong>Worker</strong>: Connector와 Task를 실행하는 프로세스</li>
  <li><strong>Converter</strong>: 데이터 포맷을 변환하는데 사용하는 구성요소</li>
  <li><strong>Trasform</strong>: 데이터를 변환하는데 사용하는 구성요소</li>
</ul>

<p><img src="/images/kafka_55.png" alt="" /></p>

<h2 id="connect-connector">Connect? Connector?</h2>
<p>커넥트는 커넥터를 실행시키기 위한 환경(프레임워크)을 제공해줌. 커넥트 위에서 커넥터 설치하고 커넥터(jar파일) 실행하면 됨</p>

<p>커넥트 이미지로 인스턴스 띄우고 거기서 각종 커넥터 다운로드 받아서 커넥터를 몽고db, mysql, s3같은데 RESTapi로 등록</p>

<h2 id="standalone과-distributed-workers">Standalone과 Distributed Workers</h2>

<p>Worker 프로세스를 한 개만 띄우는 Standalone 모드와 여러개 실행시키는 Distributed 모드가 있다.</p>

<p>보통 대부분 Distributed 모드를 사용한다.</p>

<h1 id="debezium">Debezium</h1>

<p>Debezium은 변경 데이터 캡처를 위한 오픈 소스 분산 플랫폼이다.</p>

<p>Debezium 에서 변경된 데이터 캡쳐를 위해 mysql의 경우 binlog, postgresql의 경우 replica slot(logical)을 이용하여 데이터베이스에 커밋하는 데이터를 감시하여 Kakfa, DB, ElasticSearch 등 미들웨어에 이벤트를 전달한다</p>

<h1 id="참고">참고</h1>

<ul>
  <li><a href="https://docs.confluent.io/5.0.0/installation/docker/docs/installation/connect-avro-jdbc.html" target="_blank">Confluent 공식문서: Kafka Connect Tutorial on Docker</a></li>
  <li><a href="https://hub.docker.com/r/confluentinc/cp-kafka-connect" target="_blank">Connect 도커 이미지</a></li>
  <li><a href="https://www.confluent.io/hub/mongodb/kafka-connect-mongodb" target="_blank">Confluent 공식문서: MongoDB 커넥터</a></li>
  <li><a href="https://www.mongodb.com/docs/kafka-connector/current/" target="_blank">MongoDB 공식문서: MongoDB 커넥터를 위한 Configuration</a></li>
  <li><a href="https://kudl.tistory.com/entry/CDC-debezium-설정" target="_blank">kudl: CDC - debezium 설정</a></li>
</ul>
:ET