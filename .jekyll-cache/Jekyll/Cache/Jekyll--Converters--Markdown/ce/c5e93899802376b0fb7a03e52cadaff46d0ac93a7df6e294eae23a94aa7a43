I"öm<hr />

<p id="toc"><strong>Table of Contents</strong></p>
<ul id="markdown-toc">
  <li><a href="#pyflink" id="markdown-toc-pyflink">PyFlink</a></li>
  <li><a href="#datastream-api" id="markdown-toc-datastream-api">DataStream API</a>    <ul>
      <li><a href="#datastream-api-ë§›ë³´ê¸°" id="markdown-toc-datastream-api-ë§›ë³´ê¸°">DataStream API ë§›ë³´ê¸°</a></li>
      <li><a href="#execution-mode-batchstreaming" id="markdown-toc-execution-mode-batchstreaming">Execution Mode (Batch/Streaming)</a></li>
      <li><a href="#when-canshould-i-use-batch-execution-mode" id="markdown-toc-when-canshould-i-use-batch-execution-mode">When can/should I use BATCH execution mode?</a></li>
      <li><a href="#configuring-batch-execution-mode" id="markdown-toc-configuring-batch-execution-mode">Configuring BATCH execution mode</a></li>
    </ul>
  </li>
  <li><a href="#table-api" id="markdown-toc-table-api">Table API</a></li>
  <li><a href="#ì°¸ê³ " id="markdown-toc-ì°¸ê³ ">ì°¸ê³ </a></li>
</ul>

<hr />

<h1 id="pyflink">PyFlink</h1>

<p><img src="/images/flink_30.png" alt="" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install apache-flink
</code></pre></div></div>

<ul>
  <li>PyFlinkëŠ” <strong>ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ”ë° í•„ìš”í•œ ê³ ìˆ˜ì¤€ APIë¥¼ ì œê³µ</strong></li>
  <li>í¬ê²Œ ë‘ ê°€ì§€ì˜ <strong>Table API, DataStream API</strong>ë¥¼ ì œê³µ</li>
  <li>
    <p>ì œê³µë°›ì€ APIë¥¼ ì´ìš©í•´ ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ <strong>íŒŒì´ì¬</strong> ì–¸ì–´ë¡œ ì‘ì„±í•  ìˆ˜ ìˆìŒ</p>
  </li>
  <li>Table APIëŠ” SQLê³¼ ìœ ì‚¬í•œ í˜•íƒœì˜ ê°•ë ¥í•œ ê´€ê³„í˜• ì¿¼ë¦¬ë¥¼ ì‘ì„±í•˜ëŠ”ë° í•„ìš”í•œ ê¸°ëŠ¥ì„ ì œê³µ</li>
</ul>

<h1 id="datastream-api">DataStream API</h1>

<ul>
  <li>DataStream APIëŠ” ì‹œê°„, ìƒíƒœì™€ ê°™ì€ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ì˜ í•µì‹¬ì´ ë˜ëŠ” ê°œë…ë“¤ì„ ë‹¤ë£¨ëŠ”ë° í•„ìš”í•œ ê¸°ëŠ¥ì„ ì œê³µ</li>
  <li><strong>Filtering, Update state, Defining window, Aggregating</strong>ê³¼ ê°™ì€ ìŠ¤íŠ¸ë¦¼ ë°ì´í„° ë³€í™˜ ê¸°ëŠ¥ì„ ì œê³µ</li>
</ul>

<h2 id="datastream-api-ë§›ë³´ê¸°">DataStream API ë§›ë³´ê¸°</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># DataStream API ê´€ë ¨ íŒ¨í‚¤ì§€ ì„í¬íŠ¸í•˜ê¸°
</span>
<span class="kn">from</span> <span class="nn">pyflink.common</span> <span class="kn">import</span> <span class="n">WatermarkStrategy</span><span class="p">,</span> <span class="n">Encoder</span><span class="p">,</span> <span class="n">Types</span>
<span class="kn">from</span> <span class="nn">pyflink.datastream</span> <span class="kn">import</span> <span class="n">StreamExecutionEnvironment</span><span class="p">,</span> <span class="n">RuntimeExecutionMode</span>
<span class="kn">from</span> <span class="nn">pyflink.datastream.connectors</span> <span class="kn">import</span> <span class="p">(</span><span class="n">FileSource</span><span class="p">,</span> <span class="n">StreamFormat</span><span class="p">,</span> <span class="n">FileSink</span><span class="p">,</span> <span class="n">OutputFileConfig</span><span class="p">,</span> <span class="n">RollingPolicy</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>create a StreamExecutionEnvironment</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ìŠ¤íŠ¸ë¦¬ë° í”„ë¡œê·¸ë¨ì´ ì‹¤í–‰ë˜ëŠ” ì‹¤í–‰í™˜ê²½
# ì‘ì—…ì˜ íŠ¹ì„±ì„ ì„¤ì •
# ì†ŒìŠ¤ ìƒì„±
# ì‘ì—…ì˜ ì‹¤í–‰ íŠ¸ë¦¬ê±°
</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="p">.</span><span class="n">get_execution_environment</span><span class="p">()</span>
<span class="n">env</span><span class="p">.</span><span class="n">set_runtime_mode</span><span class="p">(</span><span class="n">RuntimeExecutionMode</span><span class="p">.</span><span class="n">BATCH</span><span class="p">)</span>
<span class="n">env</span><span class="p">.</span><span class="n">set_parallelism</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>create Source DataSream</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># envë¥¼ ì´ìš©í•´ì„œ ì†ŒìŠ¤ ìƒì„±
# ì†ŒìŠ¤ëŠ” ì™¸ë¶€ì‹œìŠ¤í…œì—ì„œ ë°ì´í„° ê°€ì ¸ì˜´
</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">from_source</span><span class="p">(</span>
    <span class="n">source</span><span class="o">=</span><span class="n">FileSource</span><span class="p">.</span><span class="n">for_record_stream_format</span><span class="p">(</span><span class="n">StreamFormat</span><span class="p">.</span><span class="n">text_line_format</span><span class="p">(),</span>
                                               <span class="n">input_path</span><span class="p">)</span>
                     <span class="p">.</span><span class="n">process_static_file_set</span><span class="p">().</span><span class="n">build</span><span class="p">(),</span>
    <span class="n">watermark_strategy</span><span class="o">=</span><span class="n">WatermarkStrategy</span><span class="p">.</span><span class="n">for_monotonous_timestamps</span><span class="p">(),</span>
    <span class="n">source_name</span><span class="o">=</span><span class="s">"file_source"</span>
<span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>define the execution logic</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">:</span> <span class="n">Row</span><span class="p">(</span><span class="n">a</span> <span class="o">%</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">output_type</span><span class="o">=</span><span class="n">Types</span><span class="p">.</span><span class="n">ROW</span><span class="p">([</span><span class="n">Types</span><span class="p">.</span><span class="n">LONG</span><span class="p">(),</span> <span class="n">Types</span><span class="p">.</span><span class="n">LONG</span><span class="p">()]))</span> \
        <span class="p">.</span><span class="n">key_by</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">:</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> \
        <span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">MyMapFunction</span><span class="p">(),</span> <span class="n">output_type</span><span class="o">=</span><span class="n">Types</span><span class="p">.</span><span class="n">TUPLE</span><span class="p">([</span><span class="n">Types</span><span class="p">.</span><span class="n">LONG</span><span class="p">(),</span> <span class="n">Types</span><span class="p">.</span><span class="n">LONG</span><span class="p">()]))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ë°ì´í„° ë³€í™˜
# ì‹±í¬ì— ë°ì´í„° ì“°ê¸°
</span>
<span class="n">ds</span><span class="p">.</span><span class="n">sink_to</span><span class="p">(</span>
    <span class="n">sink</span><span class="o">=</span><span class="n">FileSink</span><span class="p">.</span><span class="n">for_row_format</span><span class="p">(</span>
        <span class="n">base_path</span><span class="o">=</span><span class="n">output_path</span><span class="p">,</span>
        <span class="n">encoder</span><span class="o">=</span><span class="n">Encoder</span><span class="p">.</span><span class="n">simple_string_encoder</span><span class="p">())</span>
    <span class="p">.</span><span class="n">with_output_file_config</span><span class="p">(</span>
        <span class="n">OutputFileConfig</span><span class="p">.</span><span class="n">builder</span><span class="p">()</span>
        <span class="p">.</span><span class="n">with_part_prefix</span><span class="p">(</span><span class="s">"prefix"</span><span class="p">)</span>
        <span class="p">.</span><span class="n">with_part_suffix</span><span class="p">(</span><span class="s">".ext"</span><span class="p">)</span>
        <span class="p">.</span><span class="n">build</span><span class="p">())</span>
    <span class="p">.</span><span class="n">with_rolling_policy</span><span class="p">(</span><span class="n">RollingPolicy</span><span class="p">.</span><span class="n">default_rolling_policy</span><span class="p">())</span>
    <span class="p">.</span><span class="n">build</span><span class="p">()</span>
<span class="p">)</span>

<span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="n">line</span><span class="p">):</span>
    <span class="k">yield</span> <span class="k">from</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">()</span>


<span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="n">flat_map</span><span class="p">(</span><span class="n">split</span><span class="p">)</span> \
       <span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">output_type</span><span class="o">=</span><span class="n">Types</span><span class="p">.</span><span class="n">TUPLE</span><span class="p">([</span><span class="n">Types</span><span class="p">.</span><span class="n">STRING</span><span class="p">(),</span> <span class="n">Types</span><span class="p">.</span><span class="n">INT</span><span class="p">()]))</span> \
       <span class="p">.</span><span class="n">key_by</span><span class="p">(</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> \
       <span class="p">.</span><span class="nb">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">i</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">j</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ìŠ¤íŠ¸ë¦¼ ì‘ì—… ì‹¤í–‰
# í”Œë§í¬ëŠ” lazy operation -&gt; MapReduceì—ì„œ Mapê³¼ ê°™ì€ ì—°ì‚°ì´ ì¼ì–´ë‚˜ëŠ” ì‹œì ì— í´ëŸ¬ìŠ¤í„°ë¡œ ì‘ì—… ì „ë‹¬
</span>
<span class="n">env</span><span class="p">.</span><span class="n">execute</span><span class="p">()</span>
</code></pre></div></div>

<p><a href="https://nightlies.apache.org/flink/flink-docs-master/docs/dev/python/datastream_tutorial/" target="_blank"><strong>ì „ì²´ ì½”ë“œ ì°¸ê³ </strong></a></p>

<h2 id="execution-mode-batchstreaming">Execution Mode (Batch/Streaming)</h2>

<p>The DataStream API supports different runtime execution modes from which you can choose depending on the requirements of your use case and the characteristics of your job.</p>

<p>There is the â€œclassicâ€ execution behavior of the DataStream API, which we call STREAMING execution mode. This should be used for unbounded jobs that require continuous incremental processing and are expected to stay online indefinitely.</p>

<p>Additionally, there is a batch-style execution mode that we call BATCH execution mode. This executes jobs in a way that is more reminiscent of batch processing frameworks such as MapReduce. This should be used for bounded jobs for which you have a known fixed input and which do not run continuously.</p>

<p>Apache Flinkâ€™s unified approach to stream and batch processing means that a DataStream application executed over bounded input will produce the same final results regardless of the configured execution mode. It is important to note what final means here: a job executing in STREAMING mode might produce incremental updates (think upserts in a database) while a BATCH job would only produce one final result at the end. The final result will be the same if interpreted correctly but the way to get there can be different.</p>

<p>By enabling BATCH execution, we allow Flink to apply additional optimizations that we can only do when we know that our input is bounded. For example, different join/aggregation strategies can be used, in addition to a different shuffle implementation that allows more efficient task scheduling and failure recovery behavior. We will go into some of the details of the execution behavior below.</p>

<h2 id="when-canshould-i-use-batch-execution-mode">When can/should I use BATCH execution mode?</h2>

<p>The BATCH execution mode can only be used for Jobs/Flink Programs that are bounded. Boundedness is a property of a data source that tells us whether all the input coming from that source is known before execution or whether new data will show up, potentially indefinitely. A job, in turn, is bounded if all its sources are bounded, and unbounded otherwise.</p>

<p>STREAMING execution mode, on the other hand, can be used for both bounded and unbounded jobs.</p>

<p>As a rule of thumb, you should be using BATCH execution mode when your program is bounded because this will be more efficient. You have to use STREAMING execution mode when your program is unbounded because only this mode is general enough to be able to deal with continuous data streams.</p>

<p>Another case where you might run a bounded job using STREAMING mode is when writing tests for code that will eventually run with unbounded sources. For testing it can be more natural to use a bounded source in those cases.</p>

<h2 id="configuring-batch-execution-mode">Configuring BATCH execution mode</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- STREAMING: The classic DataStream execution mode (default)
- BATCH: Batch-style execution on the DataStream API
- AUTOMATIC: Let the system decide based on the boundedness of the sources
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="p">.</span><span class="n">getExecutionEnvironment</span><span class="p">();</span>
<span class="n">env</span><span class="p">.</span><span class="n">setRuntimeMode</span><span class="p">(</span><span class="n">RuntimeExecutionMode</span><span class="p">.</span><span class="n">BATCH</span><span class="p">);</span>
</code></pre></div></div>

<ul>
  <li>Streaming</li>
</ul>

<p>In STREAMING execution mode, all tasks need to be online/running all the time. This allows Flink to immediately process new records through the whole pipeline, which we need for continuous and low-latency stream processing. This also means that the TaskManagers that are allotted to a job need to have enough resources to run all the tasks at the same time.</p>

<p>Network shuffles are pipelined, meaning that records are immediately sent to downstream tasks, with some buffering on the network layer. Again, this is required because when processing a continuous stream of data there are no natural points (in time) where data could be materialized between tasks (or pipelines of tasks). This contrasts with BATCH execution mode where intermediate results can be materialized, as explained below.</p>

<ul>
  <li>Batch</li>
</ul>

<p>In BATCH execution mode, the tasks of a job can be separated into stages that can be executed one after another. We can do this because the input is bounded and Flink can therefore fully process one stage of the pipeline before moving on to the next. In the above example the job would have three stages that correspond to the three tasks that are separated by the shuffle barriers.</p>

<p>Instead of sending records immediately to downstream tasks, as explained above for STREAMING mode, processing in stages requires Flink to materialize intermediate results of tasks to some non-ephemeral storage which allows downstream tasks to read them after upstream tasks have already gone off line. This will increase the latency of processing but comes with other interesting properties. For one, this allows Flink to backtrack to the latest available results when a failure happens instead of restarting the whole job. Another side effect is that BATCH jobs can execute on fewer resources (in terms of available slots at TaskManagers) because the system can execute tasks sequentially one after the other.</p>

<p>TaskManagers will keep intermediate results at least as long as downstream tasks have not consumed them. (Technically, they will be kept until the consuming pipelined regions have produced their output.) After that, they will be kept for as long as space allows in order to allow the aforementioned backtracking to earlier results in case of a failure.</p>

<h1 id="table-api">Table API</h1>

<ul>
  <li>ë°°ì¹˜, ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ë¥¼ ìœ„í•œ í•„ìš”í•œ ê¸°ëŠ¥ì„ ì œê³µ</li>
  <li>EDA, ETLê³¼ ê°™ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‰½ê²Œ ì •ì˜í•˜ê¸° ìœ„í•´ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë¨</li>
  <li>ë°ì´í„°ê°€ ìœ í•œ(Bounded), ë¬´í•œ(Unbounded)í•œ ê²½ìš°ì— ê´€ê³„ì—†ì´ ê°™ì€ ì˜ë¯¸</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pyflink.common</span> <span class="kn">import</span> <span class="n">Row</span>
<span class="kn">from</span> <span class="nn">pyflink.table</span> <span class="kn">import</span> <span class="p">(</span><span class="n">EnvironmentSettings</span><span class="p">,</span> <span class="n">TableEnvironment</span><span class="p">,</span>       
                           <span class="n">TableDescriptor</span><span class="p">,</span> <span class="n">Schema</span><span class="p">,</span>
                           <span class="n">DataTypes</span><span class="p">,</span> <span class="n">FormatDescriptor</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyflink.table.expressions</span> <span class="kn">import</span> <span class="n">lit</span><span class="p">,</span> <span class="n">col</span>
<span class="kn">from</span> <span class="nn">pyflink.table.udf</span> <span class="kn">import</span> <span class="n">udtf</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># í…Œì´ë¸” í™˜ê²½ ìƒì„±
# í”Œë§í¬ ëŸ°íƒ€ì„ê³¼ ìƒí˜¸ì‘ìš©í•˜ê¸° ìœ„í•œ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸
# ì‹¤í–‰ì„ ìœ„í•œ ì„¸íŒ…(ì¬ì‹œì‘ ì „ëµ, ë³‘ë ¬ì„± ë“±)
</span><span class="n">t_env</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="p">.</span><span class="n">create</span><span class="p">(</span><span class="n">EnvironmentSettings</span><span class="p">.</span><span class="n">in_streaming_mode</span><span class="p">())</span>
<span class="n">t_env</span><span class="p">.</span><span class="n">get_config</span><span class="p">().</span><span class="nb">set</span><span class="p">(</span><span class="s">"parallelism.default"</span><span class="p">,</span> <span class="s">"1"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># í…Œì´ë¸” ìƒì„±
</span>
<span class="n">t_env</span><span class="p">.</span><span class="n">create_temporary_table</span><span class="p">(</span>
    <span class="s">'source'</span><span class="p">,</span>
    <span class="n">TableDescriptor</span><span class="p">.</span><span class="n">for_connector</span><span class="p">(</span><span class="s">'filesystem'</span><span class="p">)</span>
        <span class="p">.</span><span class="n">schema</span><span class="p">(</span><span class="n">Schema</span><span class="p">.</span><span class="n">new_builder</span><span class="p">()</span>
                <span class="p">.</span><span class="n">column</span><span class="p">(</span><span class="s">'word'</span><span class="p">,</span> <span class="n">DataTypes</span><span class="p">.</span><span class="n">STRING</span><span class="p">())</span>
                <span class="p">.</span><span class="n">build</span><span class="p">())</span>
        <span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">'path'</span><span class="p">,</span> <span class="n">input_path</span><span class="p">)</span>
        <span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="s">'csv'</span><span class="p">)</span>
        <span class="p">.</span><span class="n">build</span><span class="p">())</span>
<span class="n">tab</span> <span class="o">=</span> <span class="n">t_env</span><span class="p">.</span><span class="n">from_path</span><span class="p">(</span><span class="s">'source'</span><span class="p">)</span>

<span class="n">t_env</span><span class="p">.</span><span class="n">create_temporary_table</span><span class="p">(</span>
    <span class="s">'sink'</span><span class="p">,</span>
    <span class="n">TableDescriptor</span><span class="p">.</span><span class="n">for_connector</span><span class="p">(</span><span class="s">'filesystem'</span><span class="p">)</span>
        <span class="p">.</span><span class="n">schema</span><span class="p">(</span><span class="n">Schema</span><span class="p">.</span><span class="n">new_builder</span><span class="p">()</span>
                <span class="p">.</span><span class="n">column</span><span class="p">(</span><span class="s">'word'</span><span class="p">,</span> <span class="n">DataTypes</span><span class="p">.</span><span class="n">STRING</span><span class="p">())</span>
                <span class="p">.</span><span class="n">column</span><span class="p">(</span><span class="s">'count'</span><span class="p">,</span> <span class="n">DataTypes</span><span class="p">.</span><span class="n">BIGINT</span><span class="p">())</span>
                <span class="p">.</span><span class="n">build</span><span class="p">())</span>
        <span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">'path'</span><span class="p">,</span> <span class="n">output_path</span><span class="p">)</span>
        <span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">FormatDescriptor</span><span class="p">.</span><span class="n">for_format</span><span class="p">(</span><span class="s">'canal-json'</span><span class="p">)</span>
                <span class="p">.</span><span class="n">build</span><span class="p">())</span>
        <span class="p">.</span><span class="n">build</span><span class="p">())</span>
</code></pre></div></div>

<p>í…Œì´ë¸”ì„ ì •ì˜í•˜ê¸° ìœ„í•´ <code class="language-plaintext highlighter-rouge">TableEnvironment.execute_sql()</code> ë©”ì„œë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆë‹¤</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">my_source_ddl</span> <span class="o">=</span> <span class="s">"""
    create table source (
        word STRING
    ) with (
        'connector' = 'filesystem',
        'format' = 'csv',
        'path' = '{}'
    )
"""</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">input_path</span><span class="p">)</span>

<span class="n">my_sink_ddl</span> <span class="o">=</span> <span class="s">"""
    create table sink (
        word STRING,
        `count` BIGINT
    ) with (
        'connector' = 'filesystem',
        'format' = 'canal-json',
        'path' = '{}'
    )
"""</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">output_path</span><span class="p">)</span>

<span class="n">t_env</span><span class="p">.</span><span class="n">execute_sql</span><span class="p">(</span><span class="n">my_source_ddl</span><span class="p">)</span>
<span class="n">t_env</span><span class="p">.</span><span class="n">execute_sql</span><span class="p">(</span><span class="n">my_sink_ddl</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">source</code>ë¼ëŠ” í…Œì´ë¸”ê³¼ <code class="language-plaintext highlighter-rouge">sink</code>ë¼ëŠ” ì´ë¦„ì˜ í…Œì´ë¸”ì„ <code class="language-plaintext highlighter-rouge">t_env</code>ì— ë“±ë¡í•œë‹¤</p>

<p>ì†ŒìŠ¤ë¥¼ ë§Œë“¤ê³ , ë³€í™˜í•˜ê³ , ì‹±í¬ì— ë°ì´í„°ë¥¼ ì“°ëŠ” ëª¨ë“  ì‘ì—…ì€ lazyí•˜ê²Œ ì‹¤í–‰ëœë‹¤. executeì™€ ê°™ì€ ë©”ì„œë“œê°€ í˜¸ì¶œë˜ì—ˆì„ ë–„ë§Œ ëª¨ë“  ì‘ì—…ì´ ì „ë‹¬ëœë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">@</span><span class="n">udtf</span><span class="p">(</span><span class="n">result_types</span><span class="o">=</span><span class="p">[</span><span class="n">DataTypes</span><span class="p">.</span><span class="n">STRING</span><span class="p">()])</span>
<span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="n">line</span><span class="p">:</span> <span class="n">Row</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">line</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">split</span><span class="p">():</span>
        <span class="k">yield</span> <span class="n">Row</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>

<span class="c1"># compute word count
</span><span class="n">tab</span><span class="p">.</span><span class="n">flat_map</span><span class="p">(</span><span class="n">split</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">'word'</span><span class="p">)</span> \
   <span class="p">.</span><span class="n">group_by</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s">'word'</span><span class="p">))</span> \
   <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s">'word'</span><span class="p">),</span> <span class="n">lit</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">count</span><span class="p">)</span> \
   <span class="p">.</span><span class="n">execute_insert</span><span class="p">(</span><span class="s">'sink'</span><span class="p">)</span> \
   <span class="p">.</span><span class="n">wait</span><span class="p">()</span>
</code></pre></div></div>

<p><a href="https://nightlies.apache.org/flink/flink-docs-master/docs/dev/python/table_api_tutorial/" target="_blank"><strong>ì „ì²´ ì½”ë“œ ì°¸ê³ </strong></a></p>

<h1 id="ì°¸ê³ ">ì°¸ê³ </h1>
<ul>
  <li><a href="https://nightlies.apache.org/flink/flink-docs-master/docs/dev/python/overview/" target="_blank">Apache Flink: pyflink ê³µì‹ë¬¸ì„œ</a></li>
  <li><a href="https://nightlies.apache.org/flink/flink-docs-master/api/python/" target="_blank">Apache Flinkâ€ pyflink Docs ê³µì‹ë¬¸ì„œ</a></li>
</ul>

:ET