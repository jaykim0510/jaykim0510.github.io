I"6<p id="toc"><strong>Table of Contents</strong></p>
<ul id="markdown-toc">
  <li><a href="#spark-introduction" id="markdown-toc-spark-introduction">Spark Introduction</a></li>
  <li><a href="#rdd" id="markdown-toc-rdd">RDD</a>    <ul>
      <li><a href="#파티션partition" id="markdown-toc-파티션partition">파티션(Partition)</a></li>
      <li><a href="#불변성immutable" id="markdown-toc-불변성immutable">불변성(Immutable)</a></li>
      <li><a href="#게으른-연산lazy-operation" id="markdown-toc-게으른-연산lazy-operation">게으른 연산(Lazy Operation)</a></li>
    </ul>
  </li>
  <li><a href="#cluster-mode" id="markdown-toc-cluster-mode">Cluster Mode</a>    <ul>
      <li><a href="#shuffling" id="markdown-toc-shuffling">Shuffling</a></li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="spark-introduction">Spark Introduction</h1>
<p><strong>스파크는 클러스터 기반의 분산 처리 기능을 제공하는 오픈소스 프레임워크입니다.</strong> 쉽게 말해 대용량 데이터를 여러 컴퓨터에 나누어서 동시에 처리한다고 할 수 있습니다. 이런 방법이 스파크 이전에 없었던 것은 아닙니다. 스파크 이전에 하둡(Hadoop)이 이와 유사한 기능을 제공했었습니다. 
참고로 하둡은 더그 커팅(Doug Cutting)이라는 사람이 구글이 발표했던 두 개의 논문(<a href="https://static.googleusercontent.com/media/research.google.com/ko//archive/gfs-sosp2003.pdf"><strong>The Google File System_2003</strong></a>, <a href="https://dl.acm.org/doi/10.1145/1327452.1327492"><strong>MapReduce: simplified data processing on large clusters_2008</strong></a>)을 직접 구현해 만든 프레임워크입니다. 이처럼 구글에서는 예전부터 대용량의 데이터를 고속 분산처리 하기 위해 노력했었고, 현재 스파크는 대부분의 기업들이 사용하고 있는 소프트웨어입니다.</p>

<p>지금부터는 스파크와 하둡을 비교하며 스파크의 특징에 어떤 것이 있는지 알아보겠습니다.</p>

<table>
  <tbody>
    <tr>
      <td><strong>차이점</strong></td>
      <td><strong>하둡</strong></td>
      <td><strong>스파크</strong></td>
    </tr>
    <tr>
      <td>기반</td>
      <td>디스크 기반</td>
      <td>메모리 기반</td>
    </tr>
    <tr>
      <td>처리방식</td>
      <td>Map-Reduce</td>
      <td>RDD</td>
    </tr>
    <tr>
      <td>프로그래밍언어</td>
      <td>자바</td>
      <td>스칼라, 자바, 파이썬, R</td>
    </tr>
    <tr>
      <td>라이브러리</td>
      <td>-</td>
      <td>다양한 라이브러리(Spark streaming, MLlib, GraphX 등) 제공</td>
    </tr>
  </tbody>
</table>

<p>처리방식에 대해 조금 더 이야기 해보겠습니다. 맵리듀스(MapReduce)는 2004년 구글에서 대용량 데이터 처리를 분산환경에서 처리하기 위한 목적의 소프트웨어 프레임워크입니다. 맵리듀스는 함수형 프로그래밍에서 일반적으로 사용되는 Map과 Reduce라는 함수를 기반으로 만들어졌습니다. Map은 각각의 분산된 환경에서 독립적으로 실행되는 함수의 일종, Reduce는 분산 환경에서의 데이터를 하나로 모으는 함수라고 생각할 수 있습니다.</p>

<p><img src="../images/../../images/spark_1.png" alt="" /></p>

<p>맵리듀스는 분산된 환경에서 데이터가 처리되는데 필요한 많은 함수들을 제공해주지만, 현업에서 필요한 기능들을 모두 커버하기에는 무리가 있었습니다. 그래서 이러한 단점을 보완하기 위해 2009년 UC Berkeley 대학에서 연구를 시작해 2012년 미국 NSDI 학회에서 스파크의 핵심 개념인 <strong>RDD(Resilient Distributed Dataset)</strong> 에 대한 논문을 발표하였습니다.</p>

<h1 id="rdd">RDD</h1>
<blockquote>
  <p>RDD is a fault-tolerant collection of elements that can be operated on in parallel.<br />
<a href="https://spark.apache.org/docs/3.2.0/rdd-programming-guide.html#resilient-distributed-datasets-rdds">(아파치 스파크 공식문서 참고)</a></p>
</blockquote>

<p>다시 말하면 RDD란 스파크에서 정의한 <strong>분산 데이터 모델로서 병렬 처리가 가능한 요소</strong> 로 구성되며 데이터를 처리하는 과정에서 <strong>장애가 발생하더라도 스스로 복구할 수 있는 능력</strong> 을 가진 <strong>데이터 모델</strong> 이라는 뜻입니다. RDD는 분산 데이터에 대한 모델로서 단순히 값으로 표현되는 데이터만 가리키는 것이 아니고, 분산된 <strong>데이터를 다루는 방법까지 포함</strong> 하는 일종의 클래스와 같은 개념입니다.</p>

<p>RDD에서 중요한 특징은 다음과 같습니다.</p>

<ul>
  <li>파티션(Partition)</li>
  <li>불변성</li>
  <li>게으른 연산(Lazy operation)</li>
  <li>
    <h2 id="파티션partition">파티션(Partition)</h2>
    <p>RDD는 분산 데이터 요소로 구성된 데이터 집합입니다. 여기서 분산 데이터 요소를 파티션이라고 합니다. 스파크는 작업을 수행할 때 바로 이 파티션 단위로 나눠서 병렬로 처리합니다. 여기서 제가 헷갈렸던 것은 파티션이 분산처리와 병렬처리 중 어떤 것을 기준으로 나뉘어진 단위인가 라는 것 이었습니다. 공식문서<a href="https://spark.apache.org/docs/3.2.0/rdd-programming-guide.html#parallelized-collections">(아파치 스파크 공식문서 참고)</a>를 살펴본 결과 파티션은 병렬 처리가 되는 기준이었습니다. 여러 서버에 분산할 때 보통 하나의 서버 당 2~4개 정도의 파티션을 설정합니다. 이 기준은 개인의 클러스터 환경에 따라 기본 설정 값이 다르며 이 값은 원하는 값으로 바꿀 수 있습니다. 구글에서 이미지를 살펴보았을 때는 다들 task당 한개의 파티션이라고 합니다.</p>
  </li>
</ul>

<p><img src="../images/../../images/spark_2.png" alt="" /></p>

<h2 id="불변성immutable">불변성(Immutable)</h2>
<p>한 개의 RDD가 여러 개의 파티션으로 나뉘고 다수의 서버에서 처리되다 보니 작업 도중 일부 파티션 처리에 장애가 발생해 파티션 처리 결과가 유실될 수 있습니다. 하지만 스파크에서 RDD는 불변성이기 때문에 생성 과정에 사용되었던 연산들을 다시 실행하여 장애를 해결할 수 있습니다. 여기서 불변성이라는 말은 RDD에서 어떤 연산을 적용해 다른 RDD가 될 때 <strong>무조건 새로 RDD를 생성합니다(RDD는 불변이다).</strong> 이러한 방식 덕분에 장애가 발생해도 기존의 RDD 데이터에 다시 연산을 적용해 장애를 해결할 수 있는 것입니다.</p>

<h2 id="게으른-연산lazy-operation">게으른 연산(Lazy Operation)</h2>

<h1 id="cluster-mode">Cluster Mode</h1>

<h2 id="shuffling">Shuffling</h2>
:ET