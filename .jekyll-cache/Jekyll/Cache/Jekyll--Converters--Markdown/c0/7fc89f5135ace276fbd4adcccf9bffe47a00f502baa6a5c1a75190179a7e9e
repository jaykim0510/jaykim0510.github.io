I"2<hr />

<p id="toc"><strong>Table of Contents</strong></p>
<ul id="markdown-toc">
  <li><a href="#도커-컴포즈로-컨테이너-띄우기" id="markdown-toc-도커-컴포즈로-컨테이너-띄우기">도커 컴포즈로 컨테이너 띄우기</a></li>
  <li><a href="#spark-client-컨테이너에서-pyspark-셸을-실행" id="markdown-toc-spark-client-컨테이너에서-pyspark-셸을-실행">spark-client 컨테이너에서 pyspark 셸을 실행</a></li>
  <li><a href="#pyspark-셸에서-몽고db와-연결" id="markdown-toc-pyspark-셸에서-몽고db와-연결">pyspark 셸에서 몽고DB와 연결</a></li>
  <li><a href="#참고" id="markdown-toc-참고">참고</a></li>
</ul>

<hr />

<h1 id="도커-컴포즈로-컨테이너-띄우기">도커 컴포즈로 컨테이너 띄우기</h1>

<div class="language-yml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">version</span><span class="pi">:</span> <span class="s1">'</span><span class="s">3.2'</span>
<span class="na">services</span><span class="pi">:</span>
    <span class="na">spark-client</span><span class="pi">:</span>
      <span class="na">image</span><span class="pi">:</span> <span class="s">kimziont/spark:1.0</span>
      <span class="na">hostname</span><span class="pi">:</span> <span class="s">spark-client</span>
      <span class="na">depends_on</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="s">spark-master</span>
      <span class="na">command</span><span class="pi">:</span> 
        <span class="pi">-</span> <span class="s">bash</span>
        <span class="pi">-</span> <span class="s">-c</span>
        <span class="pi">-</span> <span class="pi">|</span>
          <span class="s">apt -y install python-is-python3</span>
          <span class="s">sleep infinity</span>

    <span class="na">spark-master</span><span class="pi">:</span>
      <span class="na">image</span><span class="pi">:</span> <span class="s">kimziont/spark-master:1.0</span>
      <span class="na">hostname</span><span class="pi">:</span> <span class="s">spark-master</span>
      <span class="na">ports</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="s2">"</span><span class="s">4041:8080"</span>
      <span class="na">command</span><span class="pi">:</span> 
        <span class="pi">-</span> <span class="s">bash</span>
        <span class="pi">-</span> <span class="s">-c</span>
        <span class="pi">-</span> <span class="pi">|</span>
          <span class="s">./spark/sbin/start-master.sh &amp;</span>
          <span class="s">sleep infinity</span>

    <span class="na">spark-worker1</span><span class="pi">:</span>
      <span class="na">image</span><span class="pi">:</span> <span class="s">kimziont/spark-worker:1.0</span>
      <span class="na">hostname</span><span class="pi">:</span> <span class="s">worker1</span>
      <span class="na">depends_on</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="s">spark-master</span>
      <span class="na">ports</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="s2">"</span><span class="s">4042:8081"</span>
      <span class="na">command</span><span class="pi">:</span> 
        <span class="pi">-</span> <span class="s">bash</span>
        <span class="pi">-</span> <span class="s">-c</span>
        <span class="pi">-</span> <span class="pi">|</span>
          <span class="s">./spark/sbin/start-worker.sh spark://spark-master:7077 &amp;</span>
          <span class="s">sleep infinity</span>

    <span class="na">spark-worker2</span><span class="pi">:</span>
      <span class="na">image</span><span class="pi">:</span> <span class="s">kimziont/spark-worker:1.0</span>
      <span class="na">hostname</span><span class="pi">:</span> <span class="s">worker2</span>
      <span class="na">depends_on</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="s">spark-master</span>
      <span class="na">ports</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="s2">"</span><span class="s">4043:8081"</span>
      <span class="na">command</span><span class="pi">:</span> 
        <span class="pi">-</span> <span class="s">bash</span>
        <span class="pi">-</span> <span class="s">-c</span>
        <span class="pi">-</span> <span class="pi">|</span>
          <span class="s">./spark/sbin/start-worker.sh spark://spark-master:7077 &amp;</span>
          <span class="s">sleep infinity</span>
    
    <span class="na">mongodb</span><span class="pi">:</span>
      <span class="na">image</span><span class="pi">:</span> <span class="s">mongo:latest</span>
      <span class="na">hostname</span><span class="pi">:</span> <span class="s">mongodb</span>
      <span class="na">ports</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="s2">"</span><span class="s">27017:27017"</span>
      <span class="na">environment</span><span class="pi">:</span>
        <span class="na">MONGO_INITDB_ROOT_USERNAME</span><span class="pi">:</span> <span class="s">root</span>
        <span class="na">MONGO_INITDB_ROOT_PASSWORD</span><span class="pi">:</span> <span class="s">root</span>
      <span class="na">tty</span><span class="pi">:</span> <span class="no">true</span>
</code></pre></div></div>

<ul>
  <li>마스터의 UI는 디폴트로 8080포트로 보여준다, 워커는 8081포트이다</li>
  <li>워커들은 마스터의 7077포트로 연결될 수 있다</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker compose up
</code></pre></div></div>

<h1 id="spark-client-컨테이너에서-pyspark-셸을-실행">spark-client 컨테이너에서 pyspark 셸을 실행</h1>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./bin/pyspark <span class="nt">--master</span> spark://spark-master:7077 <span class="nt">--packages</span> org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 <span class="nt">--jars</span> /spark/mysql-connector-java-8.0.29.jar
</code></pre></div></div>

<h1 id="pyspark-셸에서-몽고db와-연결">pyspark 셸에서 몽고DB와 연결</h1>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from pyspark.sql import SparkSession

spark = SparkSession.builder.master('spark://spark-master:7077').config('spark.mongodb.input.uri', 'mongodb://root:root@mongodb:27017/quickstart.topicData?authSource=admin').getOrCreate()

df = spark.read.format("mongo").option("uri", "mongodb://root:root@mongodb:27017/quickstart.topicData?authSource=admin").load()

df.show()
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spark = SparkSession.builder.master('spark://spark-master:7077').config('spark.mongodb.input.uri', 'mongodb://root:root@mongodb:27017/quickstart.topicData?authSource=admin').config("spark.jars", "/spark/mysql-connector-java-8.0.29.jar").master("spark-master:7077").getOrCreate()
</code></pre></div></div>

<h1 id="참고">참고</h1>

<ul>
  <li><a href="https://www.mongodb.com/docs/manual/reference/connection-string/" target="_blank">MongoDB 공식문서: Connection String URI Format</a></li>
  <li><a href="https://www.mongodb.com/docs/manual/reference/connection-string/#mongodb-urioption-urioption.authSource" target="_blank">MongoDB 공식문서: Connection String URI Format: authSource</a></li>
  <li><a href="https://stackoverflow.com/questions/58305720/error-connecting-from-pyspark-to-mongodb-with-password" target="_blank">Error connecting from pyspark to mongodb with password</a></li>
</ul>
:ET