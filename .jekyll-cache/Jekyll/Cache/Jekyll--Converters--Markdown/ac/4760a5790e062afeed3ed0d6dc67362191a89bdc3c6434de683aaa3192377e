I"s3<hr />

<p id="toc"><strong>Table of Contents</strong></p>
<ul id="markdown-toc">
  <li><a href="#logstash의-특징" id="markdown-toc-logstash의-특징">Logstash의 특징</a></li>
  <li><a href="#logstash-설치" id="markdown-toc-logstash-설치">Logstash 설치</a></li>
  <li><a href="#logstash-구성요소" id="markdown-toc-logstash-구성요소">Logstash 구성요소</a>    <ul>
      <li><a href="#설정-파일과-실행-파일" id="markdown-toc-설정-파일과-실행-파일">설정 파일과 실행 파일</a></li>
      <li><a href="#입력" id="markdown-toc-입력">입력</a></li>
      <li><a href="#출력" id="markdown-toc-출력">출력</a></li>
      <li><a href="#필터" id="markdown-toc-필터">필터</a>        <ul>
          <li><a href="#mutate" id="markdown-toc-mutate">mutate</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#다중-파이프라인" id="markdown-toc-다중-파이프라인">다중 파이프라인</a></li>
  <li><a href="#모니터링" id="markdown-toc-모니터링">모니터링</a></li>
  <li><a href="#참고" id="markdown-toc-참고">참고</a></li>
</ul>

<hr />

<h1 id="logstash의-특징">Logstash의 특징</h1>

<ul>
  <li>플러그인 기반의 오픈소스 데이터 처리 파이프라인 도구</li>
  <li>데이터 전처리 과정을 별도의 애플리케이션 작성 없이 간단한 설정만으로 수행할 수 있다</li>
  <li>장애 대응 로직이나 성능 저하 요인을 쉽게 파악할 수 있는 모니터링 API를 제공한다</li>
  <li>성능을 튜닝할 수 있는 파라미터를 제공한다</li>
  <li>현업에서 사용하는 대부분의 데이터 소스를 지원한다</li>
  <li>자체적으로 내장되어 있는 메모리와 파일 기반의 큐(queue)를 가지고 있다</li>
  <li>(메모리는 높은 성능을, 파일 기반의 큐는 도큐먼트 유실을 최소화해준다)</li>
</ul>

<h1 id="logstash-설치">Logstash 설치</h1>

<ul>
  <li>Logstash는 Elasticsearch, Kibana와 달리 JVM을 별도로 설치해줘야 한다</li>
  <li>설치후 bin 폴더에서 스크립트를 통해 실행 시켜주면 된다</li>
  <li>Elastic은 ELK 스택의 도구들을 도커로 쉽게 시작할 수 있도록 이미지를 제공한다</li>
  <li>(전체 파이프라인을 Elastic에서 모두 관리하기 때문에 서로간의 연결성이 굉장히 뛰어나다)</li>
</ul>

<div class="language-yml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">version</span><span class="pi">:</span> <span class="s1">'</span><span class="s">3.2'</span>

<span class="na">services</span><span class="pi">:</span>

  <span class="na">elasticsearch</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">docker.elastic.co/elasticsearch/elasticsearch:${ELK_VERSION}</span>
    <span class="na">hostname</span><span class="pi">:</span> <span class="s">elasticsearch</span>
    <span class="na">container_name</span><span class="pi">:</span> <span class="s">elasticsearch</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">9200:9200"</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">9300:9300"</span>
    <span class="na">environment</span><span class="pi">:</span>
      <span class="na">ELASTIC_PASSWORD</span><span class="pi">:</span> <span class="s">changeme</span>
      <span class="na">ELASTIC_USERNAME</span><span class="pi">:</span> <span class="s">elastic</span>
      <span class="c1"># Use single node discovery in order to disable production mode and avoid bootstrap checks.</span>
      <span class="c1"># see: https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html</span>
      <span class="na">discovery.type</span><span class="pi">:</span> <span class="s">single-node</span>
    <span class="na">mem_limit</span><span class="pi">:</span> <span class="s">${MEM_LIMIT}</span>

  <span class="na">logstash</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">docker.elastic.co/logstash/logstash:${ELK_VERSION}</span>
    <span class="na">container_name</span><span class="pi">:</span> <span class="s">logstash</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">5044:5044"</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">5001:5001/tcp"</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">5001:5001/udp"</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">9600:9600"</span>
    <span class="na">mem_limit</span><span class="pi">:</span> <span class="s">${MEM_LIMIT}</span>
    <span class="na">depends_on</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">elasticsearch</span>

  <span class="na">kibana</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">docker.elastic.co/kibana/kibana:${ELK_VERSION}</span>
    <span class="na">container_name</span><span class="pi">:</span> <span class="s">kibana</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">5601:5601"</span>
    <span class="na">depends_on</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">elasticsearch</span>
</code></pre></div></div>

<h1 id="logstash-구성요소">Logstash 구성요소</h1>

<ul>
  <li>Logstash의 핵심 역할은 입력으로부터 데이터를 받아 간단한 전처리 후 출력에 전달하는 것이다</li>
  <li>이를 위해 Logstash는 입력, 필터, 출력이라는 세 가지 구성요소로 이루어진다 (입력과 출력은 필수, 필터는 옵션이다)</li>
</ul>

<div class="language-conf highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">input</span> {
    { 입력 플러그인 }
}

<span class="n">filter</span> {
    { 필터 플러그인 }
}

<span class="n">output</span> {
    { 출력 플러그인 }
}
</code></pre></div></div>

<h2 id="설정-파일과-실행-파일">설정 파일과 실행 파일</h2>

<ul>
  <li>기본 디렉터리
    <ul>
      <li><code class="language-plaintext highlighter-rouge">/usr/share/logstash</code></li>
    </ul>
  </li>
  <li>설정 파일
    <ul>
      <li><code class="language-plaintext highlighter-rouge">/usr/share/logstash/config/logstash.yml</code>
        <ul>
          <li>Logstash 프로세스에 관한 설정</li>
        </ul>
      </li>
      <li><code class="language-plaintext highlighter-rouge">/usr/share/logstash/config/pipelines.yml</code>
        <ul>
          <li>하나의 프로세스 위에서 실행되는 파이프라인에 관한 설정</li>
          <li>여러 파이프라인을 정의함으로써 다중 파이프라인을 하나의 프로세스 위에서 실행시킬 수 있다
```yml</li>
          <li>pipeline.id: main # 파이프라인의 고유한 ID
path.config: “/usr/share/logstash/pipeline/mylogstash.conf” # 파이프라인 설정 파일의 위치
pipeline.workers: # 병렬로 처리하기 위한 코어 수 (기본값: 호스트의 CPU 코어 수)
pipeline.batch.size: # 출력으로 보낼 도큐먼트의 배치 사이즈
queue.type: # 파이프라인에서 사용할 큐의 종류 (기본값: memory) persisted 타입은 이벤트 유실 최소화할 수 있음
```</li>
        </ul>
      </li>
      <li><code class="language-plaintext highlighter-rouge">/usr/share/logstash/pipeline/mylogstash.conf</code>
        <ul>
          <li>파이프라인 로직 작성</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>실행 파일
    <ul>
      <li><code class="language-plaintext highlighter-rouge">/usr/share/logstash/bin/logstash</code></li>
    </ul>
  </li>
</ul>

<h2 id="입력">입력</h2>

<ul>
  <li>소스로부터 데이터를 입력받는 단계</li>
  <li>직접 소스에 접근해 읽어들이는 경우도 있고, 서버를 열어놓고 받아들이는 경우도 있다</li>
  <li>(확장자가 꼭 위와 같을 필요는 없다. 다만 많은 사용자들이 위와 같은 확장자를 관례적으로 많이 쓰고 있을 뿐)</li>
  <li>대표적인 입력 플러그인은 file, syslog, kafka, jdbc, beats, http, redis, S3 등이 있다</li>
  <li>플러그인마다 설정 옵션이 다르므로 공식문서를 확인해보자</li>
  <li>(https://www.elastic.co/guide/en/logstash/current/input-plugins.html){:target=”_blank”}</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>input {
    file {
        path =&gt; "/opt/test/test.log"
        start_position =&gt; "beginning"
        sincedb_path =&gt; "nul"
    }
}
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- start_position: 
    - 최초 파일 발견했을 때 데이터를 처음부터(beginning) 읽을지, 실행 이후 생긴 부분부터(end) 읽을지
- sincedb_path: 
    - 파일의 어디까지 읽었는지 저장해둔다. 
    - nul로 설정하면 어디까지 읽었는지 모르게 된다. 설정 안하면 기본으로 data/plugins/inputs/file에 sincedb 파일을 생성한다
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>input {
    kafka {
        bootstrap_servers =&gt; "kafka:29092"
        topics =&gt; ["test_topic"]
    }
}
</code></pre></div></div>

<h2 id="출력">출력</h2>

<ul>
  <li>출력은 가공된 데이터를 지정한 대상으로 내보내는 단계다</li>
  <li>입력과 비슷한 방식으로 작성한다</li>
  <li>대표적인 플러그인은 elasticsearch, file, kafka, email, redis, S3 등이 있다</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>output {
	elasticsearch {
		hosts =&gt; "elasticsearch:9200"
		user =&gt; "elastic"
		index =&gt; "test"
		password =&gt; "changeme"
	}
}
</code></pre></div></div>

<h2 id="필터">필터</h2>

<ul>
  <li>입력 플러그인으로부터 받은 데이터를 정제하여 의미 있는 데이터로 정형화하는 역할</li>
  <li>필수 구성요소는 아니지만, 필터 없는 파이프라인은 의미 있는 기능을 하기 어려움</li>
  <li>대표적인 플러그인은 grok, dissect, mutate 등이 있다</li>
</ul>

<h3 id="mutate">mutate</h3>

<ul>
  <li>필드 이름 변경, 간단한 문자열 전처리와 같은 기능을 제공하는 플러그인
    <ul>
      <li>rename: 필드 이름 변경</li>
      <li>uppercase: 문자열 대문자로 변경</li>
      <li>split: 쉼표, 띄어쓰기와 같은 구분 문자를 기준으로 문자열을 배열로 나눔</li>
      <li>더 많은 옵션은 공식문서 참고: https://www.elastic.co/guide/en/logstash/current/plugins-filters-mutate.html</li>
    </ul>
  </li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>filter {
  mutate {
    rename =&gt; { "message" =&gt; "mymessage" }
  }

  dissect {
    mapping =&gt; {"mymessage" =&gt; "[%{timestamp}]%{?-&gt;}[%{id}]%{?-&gt;} [%{level}] - %{message}"}
  }

  mutate {
    lowercase =&gt; "level"
  }
}

</code></pre></div></div>

<p><img src="/images/logstash_3.png" alt="" /></p>

<h1 id="다중-파이프라인">다중 파이프라인</h1>

<ul>
  <li>하나의 로그스태시 프로세스에서 여러 개의 파이프라인을 독립적으로 실행할 수 있게 한다</li>
  <li><code class="language-plaintext highlighter-rouge">/usr/share/logstash/config</code> 의 <code class="language-plaintext highlighter-rouge">pipelines.yml</code> 파일에 여러 개의 파이프라인을 등록하면 된다
  ```sh
  # pipelines.yml 파일
    <ul>
      <li>pipeline.id: pl1
path.config: “/usr/share/logstash/pipeline/logstash_1.conf”</li>
      <li>pipeline.id: pl2
path.config: “/usr/share/logstash/pipeline/logstash_2.conf”
  ```</li>
    </ul>
  </li>
</ul>

<h1 id="모니터링">모니터링</h1>

<ul>
  <li>Kibana를 활용하면 ELK 스택을 모니터링 할 수 있다</li>
  <li>Management -&gt; Stack Monitoring -&gt; Or set up with self monitoring -&gt; Turn on monitoring</li>
</ul>

<p><img src="/images/logstash_4.png" alt="" /></p>

<h1 id="참고">참고</h1>

<ul>
  <li><a href="https://www.elastic.co/guide/en/logstash/current/index.html" target="_blank">elastic 공식문서, Logstash Reference</a></li>
  <li><a href="https://logz.io/learn/complete-guide-elk-stack/" target="_blank">logz.io, THE COMPLETE GUIDE TO THE ELK STACK</a></li>
  <li><a href="https://soyoung-new-challenge.tistory.com/99" target="_blank">[Logstash] 로그스테이시 사용법 (설정파일) + Elastic</a></li>
  <li><a href="https://www.elastic.co/kr/logstash/" target="_blank">elastic: 데이터 집계, 변환, 저장</a></li>
</ul>
:ET