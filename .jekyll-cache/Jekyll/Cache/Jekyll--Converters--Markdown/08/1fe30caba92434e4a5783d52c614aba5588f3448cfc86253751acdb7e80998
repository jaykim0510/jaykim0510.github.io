I"Ì><hr />

<p id="toc"><strong>Table of Contents</strong></p>
<ul id="markdown-toc">
  <li><a href="#rdd-dataframe-dataset" id="markdown-toc-rdd-dataframe-dataset">RDD, Dataframe, Dataset</a>    <ul>
      <li><a href="#rdd" id="markdown-toc-rdd">RDD</a></li>
      <li><a href="#dataframe" id="markdown-toc-dataframe">Dataframe</a></li>
      <li><a href="#dataset" id="markdown-toc-dataset">Dataset</a></li>
    </ul>
  </li>
  <li><a href="#dataframe-1" id="markdown-toc-dataframe-1">Dataframe</a>    <ul>
      <li><a href="#dataframe-ìƒì„±" id="markdown-toc-dataframe-ìƒì„±">Dataframe ìƒì„±</a></li>
      <li><a href="#ê¸°ë³¸-ì—°ì‚°" id="markdown-toc-ê¸°ë³¸-ì—°ì‚°">ê¸°ë³¸ ì—°ì‚°</a></li>
      <li><a href="#ì•¡ì…˜-ì—°ì‚°" id="markdown-toc-ì•¡ì…˜-ì—°ì‚°">ì•¡ì…˜ ì—°ì‚°</a></li>
      <li><a href="#ë¹„íƒ€ì…-íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜-ì—°ì‚°" id="markdown-toc-ë¹„íƒ€ì…-íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜-ì—°ì‚°">ë¹„íƒ€ì… íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ ì—°ì‚°</a></li>
      <li><a href="#í•¨ìˆ˜ê°€-ì•„ë‹Œ-sqlë¬¸" id="markdown-toc-í•¨ìˆ˜ê°€-ì•„ë‹Œ-sqlë¬¸">í•¨ìˆ˜ê°€ ì•„ë‹Œ SQLë¬¸</a></li>
    </ul>
  </li>
  <li><a href="#sparkë¥¼-ì´ìš©í•œ-dataframe-ì²˜ë¦¬-ê°œìš”" id="markdown-toc-sparkë¥¼-ì´ìš©í•œ-dataframe-ì²˜ë¦¬-ê°œìš”">Sparkë¥¼ ì´ìš©í•œ DataFrame ì²˜ë¦¬ ê°œìš”</a></li>
  <li><a href="#ì°¸ê³ " id="markdown-toc-ì°¸ê³ ">ì°¸ê³ </a></li>
</ul>

<hr />

<h1 id="rdd-dataframe-dataset">RDD, Dataframe, Dataset</h1>

<h2 id="rdd">RDD</h2>

<p><img src="../images/../../images/spark_15.jpg" alt="" /></p>

<p>Spark Coreì— RDDê°€ ìˆë‹¤ë©´ Spark SQLì—ëŠ” Dataframeê³¼ Datasetì´ ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ì˜ RDDë¥¼ ì´ìš©í•´ ìŠ¤íŒŒí¬ ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œë¥¼ ì‘ì„±í•  ë•Œì—ëŠ” RDDê°€ ê°€ì§€ê³  ìˆëŠ” ë©”ì„œë“œë‚˜ íŠ¹ì„±ì„ ì•Œì•„ì•¼ì§€ë§Œ ì½”ë“œë¥¼ ì‘ì„±í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ RDDì— ëŒ€í•œ ì´í•´ë„ê°€ ë†’ì•„ì•¼ ë¶„ì‚° í™˜ê²½ì—ì„œ ë†’ì€ ì²˜ë¦¬ ì„±ëŠ¥ì„ ì´ëŒì–´ ë‚¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.</p>

<h2 id="dataframe">Dataframe</h2>

<p><img src="../images/../../images/spark_16.jpg" alt="" /></p>

<p>ê·¸ëŸ¬ë˜ ì¤‘ Spark 1.3ë²„ì „ì—ì„œ Dataframeì´ë¼ëŠ” ìƒˆë¡œìš´ ë°ì´í„° ëª¨ë¸ì´ ê³µê°œë˜ì—ˆìŠµë‹ˆë‹¤. Dataframeì€ ê°œë°œìë“¤ì—ê²Œ ì¹œìˆ™í•œ SQLê³¼ ë¹„ìŠ·í•œ ë°©ì‹ìœ¼ë¡œ ì‘ì„±í•  ìˆ˜ ìˆë„ë¡í•˜ëŠ” APIë¥¼ ì œê³µí•´ ì§„ì… ì¥ë²½ì„ ë‚®ì·„ìœ¼ë©° ì½”ë“œì˜ ê°€ë…ì„± ë˜í•œ ë†’ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. Dataframeë„ ë§ˆì°¬ê°€ì§€ë¡œ low-levelì—ì„œëŠ” RDDë¡œ ì½”ë“œê°€ ë™ì‘í•˜ëŠ”ë° Spark SQLì€ ë‚´ë¶€ì ìœ¼ë¡œ Catalyst Optimizerë¥¼ í†µí•´ ìµœì ì˜ RDD ì½”ë“œë¡œ ë³€í™˜ë©ë‹ˆë‹¤. ë”°ë¼ì„œ ì‰¬ìš´ ì½”ë“œ ì‘ì„±ê³¼ ë†’ì€ ì„±ëŠ¥ì„ ëª¨ë‘ ì–»ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.</p>

<p>ê·¸ëŸ¬ë‚˜ Dataframeì—ë„ ì•„ì‰¬ìš´ ì ì´ ìˆì—ˆëŠ”ë°, ë°”ë¡œ RDDì—ì„œ ê°€ëŠ¥í–ˆë˜ ì»´íŒŒì¼ íƒ€ì„ ì˜¤ë¥˜ ì²´í¬ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ë‹¤ëŠ” ì ì´ì—ˆìŠµë‹ˆë‹¤.</p>

<h2 id="dataset">Dataset</h2>
<p>Spark 1.6ë²„ì „ì—ì„œ RDDì˜ ì¥ì ê³¼ Dataframeì˜ ì¥ì ì„ í•©ì¹œ ìƒˆë¡œìš´ ë°ì´í„° ëª¨ë¸ì¸ Datasetì´ ë“±ì¥í–ˆìŠµë‹ˆë‹¤.</p>

<p>ê·¸ë¦¬ê³  Spark 2.0 ì´í›„ë¶€í„°ëŠ” Dataframeì´ Dataset ì•ˆì— í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># ë°ì´í„°ì…‹ì€ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ë•Œ ë°ì´í„°ì˜ íƒ€ì…ì„ ìˆëŠ” ê·¸ëŒ€ë¡œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</span>
ë°ì´í„°ì…‹: Dataset[String], Dataset[Int]

<span class="c"># ë°ì´í„°í”„ë ˆì„ì€ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ë•Œ ë°ì´í„° íƒ€ì…ì„ ë¬´ì¡°ê±´ org.apache.spark.sql.Rowë¡œ ê°ì‹¸ì¤˜ì•¼ í•©ë‹ˆë‹¤.</span>
ë°ì´í„°í”„ë ˆì„: DataFrame <span class="o">=</span> Dataset[Row<span class="o">(</span>String<span class="o">)]</span>
</code></pre></div></div>

<p><img src="../images/../../images/spark_17.png" alt="" /></p>

<p>ì´ë ‡ê²Œ Dataframeì€ ì›ë˜ ë°ì´í„°ê°€ ê°€ì§€ê³  ìˆë˜ íƒ€ì…ì˜ íŠ¹ì„±ì€ ì‚¬ìš©í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— Dataframe APIì€ ë¹„íƒ€ì… íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ ì—°ì‚°(untyped operations)ìœ¼ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤.</p>

<table>
  <tbody>
    <tr>
      <td><strong>ë°ì´í„° ëª¨ë¸</strong></td>
      <td><strong>ì‚¬ìš© ê°€ëŠ¥í•œ ì—°ì‚°</strong></td>
    </tr>
    <tr>
      <td>Dataframe</td>
      <td>ê¸°ë³¸ ì—°ì‚°, ì•¡ì…˜ ì—°ì‚°, ë¹„íƒ€ì… íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ ì—°ì‚°</td>
    </tr>
    <tr>
      <td>Dataset</td>
      <td>ê¸°ë³¸ ì—°ì‚°, ì•¡ì…˜ ì—°ì‚°, íƒ€ì… íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ ì—°ì‚°</td>
    </tr>
  </tbody>
</table>

<p>ì €ëŠ” íŒŒì´ì¬ì„ ì£¼ì–¸ì–´ë¡œ ì‚¬ìš©í•˜ê³  ìˆìœ¼ë©° íŒŒì´ì¬ ì–¸ì–´ëŠ” Dataframe APIë§Œ ì œê³µí•˜ê¸° ë•Œë¬¸ì— ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” ì•¡ì…˜ ì—°ì‚°ê³¼ ë¹„íƒ€ì… íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ ì—°ì‚°ì— ëŒ€í•´ì„œë§Œ ë‹¤ë£¨ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.</p>

<h1 id="dataframe-1">Dataframe</h1>

<h2 id="dataframe-ìƒì„±">Dataframe ìƒì„±</h2>
<p>Dataframeì€ SparkSessionì„ ì´ìš©í•´ ìƒì„±í•©ë‹ˆë‹¤. ìƒì„± ë°©ë²•ì€ <strong>íŒŒì¼ì´ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ì™€ ê°™ì€ ìŠ¤íŒŒí¬ ì™¸ë¶€</strong>ì— ì €ì¥ëœ ë°ì´í„°ë¥¼ ì´ìš©í•  ìˆ˜ë„ ìˆê³ , <strong>ìŠ¤íŒŒí¬ ë‚´ì—ì„œì˜ RDDë‚˜ Dataframe</strong>ì„ ì´ìš©í•´ ìƒˆë¡œìš´ Dataframeì„ ìƒì„±í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.</p>

<p><strong>ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤</strong></p>

<p>íŒŒì¼ì´ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ê°™ì€ ì™¸ë¶€ ì €ì¥ì†Œì˜ ë°ì´í„°ë¥¼ ì½ì–´ì™€ì„œ Dataframeì„ ìƒì„±í•  ë•ŒëŠ” SparkSessionì˜ <code class="language-plaintext highlighter-rouge">read()</code>ë©”ì†Œë“œë¥¼ ì´ìš©í•˜ë©´ ë©ë‹ˆë‹¤. <code class="language-plaintext highlighter-rouge">read()</code>ë©”ì†Œë“œëŠ” DataFrameReader ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ì´ë¥¼ ì´ìš©í•´ ë‹¤ì–‘í•œ ìœ í˜•ì˜ ë°ì´í„°ë¥¼ ì½ê³  Dataframeì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>

<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="n">appName</span><span class="p">(</span><span class="s">"sample"</span><span class="p">).</span><span class="n">master</span><span class="p">(</span><span class="s">"local[*]"</span><span class="p">).</span><span class="n">getOrCreate</span><span class="p">()</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="s">"json"</span><span class="p">).</span><span class="n">option</span><span class="p">(</span><span class="s">"allowComments"</span><span class="p">,</span> <span class="s">"true"</span><span class="p">).</span><span class="n">load</span><span class="p">(</span><span class="s">"&lt;spark_home_dir&gt;/test.json"</span><span class="p">)</span>  
</code></pre></div></div>

<p>ì „ì²´ì ì¸ ìƒì„± ê³¼ì •ì€ í¬ê²Œ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1. Spark Sessionì˜ read() ë©”ì†Œë“œë¥¼ í˜¸ì¶œí•´ DataFrameReader ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
2. format() ë©”ì†Œë“œë¡œ ë°ì´í„°ì†ŒìŠ¤ì˜ ìœ í˜•ì„ ì§€ì •
3. option() ë©”ì†Œë“œë¡œ ë°ì´í„°ì†ŒìŠ¤ ì²˜ë¦¬ì— í•„ìš”í•œ ì˜µì…˜ì„ ì§€ì •
4. load() ë©”ì†Œë“œë¡œ ëŒ€ìƒ íŒŒì¼ì„ ì½ê³  ë°ì´í„°í”„ë ˆì„ì„ ìƒì„±
</code></pre></div></div>

<p>ë‹¤ìŒì€ DataFrameReaderê°€ ì œê³µí•˜ëŠ” ì£¼ìš” ë©”ì†Œë“œì…ë‹ˆë‹¤.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- format()
    ì½ì–´ë“¤ì´ê³ ì í•˜ëŠ” ë°ì´í„° ì†ŒìŠ¤ì˜ ìœ í˜•ì„ ë¬¸ìì—´ë¡œ ì§€ì •("kafka", "csv", "json", "parquet", "text" ë“±)
    ì´ ë°–ì—ë„ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ì†ŒìŠ¤ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í´ë˜ìŠ¤íŒ¨ìŠ¤ì— ì¶”ê°€í•´ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

- option/options()
    ë°ì´í„°ì†ŒìŠ¤ì— ì‚¬ìš©í•  ì„¤ì • ì •ë³´ë¥¼ ì§€ì •
    ë°ì´í„°ì†ŒìŠ¤ì—  ë”°ë¼ ë‹¤ë¦„

- load()
    ë°ì´í„°ì†ŒìŠ¤ë¡œë¶€í„° ì‹¤ì œ ë°ì´í„°ë¥¼ ì½ì–´ì„œ Dataframeì„ ìƒì„±

- json()
    JSON í˜•ì‹ì„ ë”°ë¥´ëŠ” ë¬¸ìì—´ë¡œ êµ¬ì„±ëœ íŒŒì¼ì´ë‚˜ RDDë¡œë¶€í„° Dataframe ìƒì„±

- parquet()
    íŒŒì¼€ì´ í˜•ì‹ì‘ë¡œ ì‘ì„±ëœ íŒŒì¼ì„ ì½ì–´ì„œ Dataframe ìƒì„±

- text()
    ì¼ë°˜ í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì‘ì„±ëœ íŒŒì¼ì„ ì½ì–´ì„œ Dataframe ìƒì„±

- csv()
    CSV íŒŒì¼ì„ ì½ì–´ Dataframe ìƒì„± 
</code></pre></div></div>

<p><strong>RDD, Dataframe</strong></p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>

<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="n">appName</span><span class="p">(</span><span class="s">"sample"</span><span class="p">).</span><span class="n">master</span><span class="p">(</span><span class="s">"local[*]"</span><span class="p">).</span><span class="n">getOrCreate</span><span class="p">()</span>

<span class="n">row1</span> <span class="o">=</span> <span class="n">Row</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">"kim"</span><span class="p">,</span> <span class="n">age</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">job</span><span class="o">=</span><span class="s">"student"</span><span class="p">)</span>
<span class="n">row2</span> <span class="o">=</span> <span class="n">Row</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">"mike"</span><span class="p">,</span> <span class="n">age</span><span class="o">=</span><span class="mi">17</span><span class="p">,</span> <span class="n">job</span><span class="o">=</span><span class="s">"student"</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">row1</span><span class="p">,</span> <span class="n">row2</span><span class="p">]</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="ê¸°ë³¸-ì—°ì‚°">ê¸°ë³¸ ì—°ì‚°</h2>
<ul>
  <li><a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/dataframe.html" target="_blank">Spark ê³µì‹ë¬¸ì„œ ì°¸ê³ </a></li>
  <li>persist()</li>
  <li>printSchema()</li>
  <li>columns</li>
  <li>dtypes</li>
  <li>createOrReplaceTempView()</li>
  <li>explain()</li>
</ul>

<h2 id="ì•¡ì…˜-ì—°ì‚°">ì•¡ì…˜ ì—°ì‚°</h2>
<ul>
  <li><a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/dataframe.html" target="_blank">Spark ê³µì‹ë¬¸ì„œ ì°¸ê³ </a></li>
  <li>show()</li>
  <li>head()</li>
  <li>take()</li>
  <li>count()</li>
  <li>describe()</li>
</ul>

<h2 id="ë¹„íƒ€ì…-íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜-ì—°ì‚°">ë¹„íƒ€ì… íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ ì—°ì‚°</h2>

<p><strong>Dataframeì—ì„œ ì œê³µí•˜ëŠ” ë¹„íƒ€ì… íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ ì—°ì‚°</strong></p>
<ul>
  <li><a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/dataframe.html" target="_blank">Spark ê³µì‹ë¬¸ì„œ ì°¸ê³ </a></li>
  <li>select()</li>
  <li>filter()</li>
  <li>agg()</li>
  <li>orderBy()</li>
  <li>groupBy()</li>
  <li>withColumn()</li>
</ul>

<p><strong>org.apache.spark.Columnì—ì„œ ì œê³µí•˜ëŠ” ë¹„íƒ€ì… íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ ì—°ì‚°</strong></p>
<ul>
  <li><a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/column.html" target="_blank">Spark ê³µì‹ë¬¸ì„œ ì°¸ê³ </a></li>
  <li>!==, ===</li>
  <li>alias()</li>
  <li>isin()</li>
  <li>when()</li>
  <li>like()</li>
</ul>

<p><strong>org.apache.spark.sql.functionsì—ì„œ ì œê³µí•˜ëŠ” ë¹„íƒ€ì… íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ ì—°ì‚°</strong></p>

<p>(ì™œ íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ì´ì§€?)</p>
<ul>
  <li><a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html" target="_blank">Spark ê³µì‹ë¬¸ì„œ ì°¸ê³ </a></li>
  <li>max(), mean(), sum()</li>
  <li>count(), countDistince()</li>
  <li>explode()</li>
  <li>when()</li>
  <li>col()</li>
  <li>lit()</li>
</ul>

<h2 id="í•¨ìˆ˜ê°€-ì•„ë‹Œ-sqlë¬¸">í•¨ìˆ˜ê°€ ì•„ë‹Œ SQLë¬¸</h2>

<ul>
  <li>createOrReplaceTempView(): Creates or replaces a local temporary view with this DataFrame.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># DataFrame ìƒì„±ì„ ìœ„í•´ì„œëŠ” SparkSessionì´ í•„ìš”í•¨
</span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>

<span class="c1"># SparkSession ìƒì„±
</span><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="n">master</span><span class="p">(</span><span class="s">"local[*]"</span><span class="p">).</span><span class="n">appName</span><span class="p">(</span><span class="s">"taxi_project"</span><span class="p">).</span><span class="n">getOrCreate</span><span class="p">()</span>

<span class="c1"># SparkSessionì„ ì´ìš©í•´ DataFrame ìƒì„±
</span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span> \
  <span class="p">.</span><span class="n">read</span> \
  <span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="s">"kafka"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">"kafka.bootstrap.servers"</span><span class="p">,</span> <span class="s">"kafka:29092"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">"subscribe"</span><span class="p">,</span> <span class="s">"test"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">"startingOffsets"</span><span class="p">,</span> <span class="s">"earliest"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">load</span><span class="p">()</span>

<span class="c1"># View ìƒì„±
</span><span class="n">df</span><span class="p">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s">"tripdata"</span><span class="p">)</span>

<span class="c1"># SQLë¬¸ì„ ì´ìš©í•´ ì¿¼ë¦¬ ì‘ì„±
</span><span class="n">query</span> <span class="o">=</span> <span class="s">"""
SELECT MONTH(value.tpep_pickup_datetime) AS month, ROUND(AVG(value.trip_distance), 3) AS average_distance
FROM tripdata
GROUP BY MONTH(value.tpep_pickup_datetime)
ORDER BY month
"""</span>

<span class="c1"># Returns a DataFrame representing the result of the given query.
</span><span class="n">table</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">sql</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>

<span class="c1"># ì•¡ì…˜ ì—°ì‚°
</span><span class="n">table</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<h1 id="sparkë¥¼-ì´ìš©í•œ-dataframe-ì²˜ë¦¬-ê°œìš”">Sparkë¥¼ ì´ìš©í•œ DataFrame ì²˜ë¦¬ ê°œìš”</h1>

<p><img src="/images/spark_40.png" alt="" /></p>

<h1 id="ì°¸ê³ ">ì°¸ê³ </h1>
<ul>
  <li><a href="http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&amp;mallGb=KOR&amp;barcode=9791158391034&amp;orderClick=LEa&amp;Kc=" target="_blank">ë¹…ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ ìŠ¤íŒŒí¬2 í”„ë¡œê·¸ë˜ë° ì±…</a></li>
  <li><a href="https://loustler.io/data_eng/spark-rdd-dataframe-and-dataset/" target="_blank">loustler, [Apache Spark] Spark RDD, Dataframe and DataSet</a></li>
  <li><a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html" target="_blank">Apache Spark ê³µì‹ë¬¸ì„œ: Spark SQL on PySpark</a></li>
  <li><a href="https://sparkbyexamples.com/pyspark-tutorial/" target="_blank">Spark by {Examples}</a></li>
</ul>
:ET