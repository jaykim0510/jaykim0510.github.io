<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Code Museum</title>
        <description>Jay Tech personal blogging theme for Jekyll</description>
        <link>http://localhost:4000/</link>
        <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
        <pubDate>Tue, 02 Aug 2022 11:00:51 +0900</pubDate>
        <lastBuildDate>Tue, 02 Aug 2022 11:00:51 +0900</lastBuildDate>
        <generator>Jekyll v4.2.1</generator>
        
            <item>
                <title>MySQL Series [Part15] IntelliJ IDE를 이용한 데이터베이스 시각화</title>
                <description>&lt;hr /&gt;
&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#참고&quot; id=&quot;markdown-toc-참고&quot;&gt;참고&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;참고&quot;&gt;참고&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.jetbrains.com/help/idea/creating-diagrams.html&quot; target=&quot;_blank&quot;&gt;IntelliJ: Database diagrams&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
                <pubDate>Fri, 29 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/mysql-series15</link>
                <guid isPermaLink="true">http://localhost:4000/mysql-series15</guid>
                
                <category>MySQL</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>MySQL Series [Part14] MySQL Optimizing SELECT Statements</title>
                <description>&lt;hr /&gt;
&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#optimization-overview&quot; id=&quot;markdown-toc-optimization-overview&quot;&gt;Optimization Overview&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#things-to-consider-for-optimization&quot; id=&quot;markdown-toc-things-to-consider-for-optimization&quot;&gt;Things to Consider for Optimization&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#optimizing-select-statements&quot; id=&quot;markdown-toc-optimizing-select-statements&quot;&gt;Optimizing SELECT Statements&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#where-clause-optimization&quot; id=&quot;markdown-toc-where-clause-optimization&quot;&gt;WHERE Clause Optimization&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#group-by-optimization&quot; id=&quot;markdown-toc-group-by-optimization&quot;&gt;GROUP BY Optimization&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#참고&quot; id=&quot;markdown-toc-참고&quot;&gt;참고&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h1 id=&quot;optimization-overview&quot;&gt;Optimization Overview&lt;/h1&gt;

&lt;p&gt;Database performance depends on several factors at the database level, such as tables, queries, and configuration settings. These software constructs result in CPU and I/O operations at the hardware level, which you must minimize and make as efficient as possible.&lt;/p&gt;

&lt;h1 id=&quot;things-to-consider-for-optimization&quot;&gt;Things to Consider for Optimization&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Are the tables structured properly? In particular, do the columns have the right data types, and does each table have the appropriate columns for the type of work? For example, applications that perform frequent updates often have many tables with few columns, while applications that analyze large amounts of data often have few tables with many columns.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Are the right indexes in place to make queries efficient?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Are you using the appropriate storage engine for each table, and taking advantage of the strengths and features of each storage engine you use? In particular, the choice of a transactional storage engine such as InnoDB or a nontransactional one such as MyISAM can be very important for performance and scalability.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Does each table use an appropriate row format? This choice also depends on the storage engine used for the table. In particular, compressed tables use less disk space and so require less disk I/O to read and write the data. Compression is available for all kinds of workloads with InnoDB tables, and for read-only MyISAM tables.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Does the application use an appropriate locking strategy? For example, by allowing shared access when possible so that database operations can run concurrently, and requesting exclusive access when appropriate so that critical operations get top priority. Again, the choice of storage engine is significant. The InnoDB storage engine handles most locking issues without involvement from you, allowing for better concurrency in the database and reducing the amount of experimentation and tuning for your code.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Are all memory areas used for caching sized correctly? That is, large enough to hold frequently accessed data, but not so large that they overload physical memory and cause paging. The main memory areas to configure are the InnoDB buffer pool and the MyISAM key cache.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;optimizing-select-statements&quot;&gt;Optimizing SELECT Statements&lt;/h1&gt;

&lt;h2 id=&quot;where-clause-optimization&quot;&gt;WHERE Clause Optimization&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Use Indexes Where Appropriate&lt;/li&gt;
  &lt;li&gt;Avoid % Wildcard in a Predicate&lt;/li&gt;
  &lt;li&gt;Avoid using a function in the predicate of a query&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;group-by-optimization&quot;&gt;GROUP BY Optimization&lt;/h2&gt;

&lt;p&gt;GROUP BY 절을 만족시키는 가장 일반적인 방법은 전체 테이블을 스캔하여 각 그룹의 모든 행이 연속되는 새 임시 테이블을 만든 다음 이 임시 테이블을 사용하여 그룹을 검색하고 집계 함수를 적용하는 것입니다&lt;/p&gt;

&lt;p&gt;In some cases, MySQL is able to do much better than that and avoid creation of temporary tables by &lt;strong&gt;using index access&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;GROUP BY에 인덱스를 사용하기 위한 가장 중요한 전제 조건은 모든 GROUP BY 열이 동일한 인덱스의 속성을 참조하고 인덱스가 해당 키를 순서대로 저장한다는 것입니다(예: BTREE 인덱스의 경우 해당되지만 해시 인덱스의 경우 해당되지 않음). 임시 테이블의 사용이 인덱스 액세스로 대체될 수 있는지 여부도 쿼리에 사용되는 인덱스의 부분, 이러한 부분에 대해 지정된 조건 및 선택한 집계 함수에 따라 달라집니다.&lt;/p&gt;

&lt;p&gt;There are two ways to execute a GROUP BY query through index access, as detailed in the following sections.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The first method applies the grouping operation together with all range predicates (if any)&lt;/li&gt;
  &lt;li&gt;The second method first performs a range scan, and then groups the resulting tuples.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;참고&quot;&gt;참고&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://dev.mysql.com/doc/refman/8.0/en/select-optimization.html&quot; target=&quot;_blank&quot;&gt;MySQL 공식문서: Optimizing SELECT Statements&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://phoenixnap.com/kb/improve-mysql-performance-tuning-optimization&quot; target=&quot;_blank&quot;&gt;MySQL Performance Tuning and Optimization Tips&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
                <pubDate>Fri, 29 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/mysql-series14</link>
                <guid isPermaLink="true">http://localhost:4000/mysql-series14</guid>
                
                <category>MySQL</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Coding Test Series [Part21]: 파이썬 문법</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#in-python-and-operation-will-not-return-a-boolean-value&quot; id=&quot;markdown-toc-in-python-and-operation-will-not-return-a-boolean-value&quot;&gt;In python, ‘and’ operation will not return a boolean value&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;in-python-and-operation-will-not-return-a-boolean-value&quot;&gt;In python, ‘and’ operation will not return a boolean value&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;If it’s true, it will return the last true value, remember is the value, not True. Otherwise, it will return the first false value.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;'ban' and 'car' -&amp;gt; 'car'
0 and 'car' -&amp;gt; 0
'ban' and False -&amp;gt; False
'ban' or False -&amp;gt; 'ban'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
                <pubDate>Fri, 29 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/python-things</link>
                <guid isPermaLink="true">http://localhost:4000/python-things</guid>
                
                <category>Coding_Test</category>
                
                
                <category>CS</category>
                
            </item>
        
            <item>
                <title>Data Engineering Series [Part22]: 시스템 디자인(3) Consistent Hashing</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#why-hashing&quot; id=&quot;markdown-toc-why-hashing&quot;&gt;Why hashing?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#consistent-hashing&quot; id=&quot;markdown-toc-consistent-hashing&quot;&gt;Consistent Hashing&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#where-is-it-used&quot; id=&quot;markdown-toc-where-is-it-used&quot;&gt;Where is it Used&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;why-hashing&quot;&gt;Why hashing?&lt;/h1&gt;

&lt;p&gt;Hash is basically a function that takes a value and converts it into another value of a specific format. Hash functions that are commonly used are MD5, SHA1, SHA256, etc.&lt;/p&gt;

&lt;p&gt;Suppose you build a distributed cache, where the data is distributed over various nodes, sometimes spanning multiple data centers. When we want to store the data for a user, we need to decide which node will cache this data. And when we want to retrieve this cached value, we must query the same node. So let us use a simple hash function for this again.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hash(user) = Sum(ASCII value of all characters in name) % 5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Where 5 is the number of nodes. This way, the hashes generated for users will be as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_8.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Since hash(Alice) is 0, Alice’s data will be stored in node 0. Similarly, Bob’s data will be stored in node 1 and Eve’s in 4. Now when you need to look up the information for Alice, you will use the same hash function to determine which node to query. Since hash(Alice) equals 0, you will query node 0 and fetch the information.&lt;/p&gt;

&lt;p&gt;But there is a problem with this solution. This model is not scalable. If the traffic increases and you want to add a new node, the formula to calculate the hash will get updated to&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hash(user) = Sum(ASCII value of all characters in name) % 6
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And similarly hash(Alice) will get updated to 2. So now you will search for Alice’s information in node 2, but the information is actually stored in node 0 so you won’t find it.&lt;/p&gt;

&lt;p&gt;To fix this, you will need to rehash all the data every time a node is added or removed, and once rehashed, you need to move the data to their respective new nodes, which could be across different data centers. This is not a very good solution as it uses up a lot of CPU resources and bandwidth.&lt;/p&gt;

&lt;p&gt;This is where Consistent Hashing comes in.&lt;/p&gt;

&lt;h1 id=&quot;consistent-hashing&quot;&gt;Consistent Hashing&lt;/h1&gt;

&lt;p&gt;Consistent Hashing tries to optimize the system in such a way that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;You don’t need to move around all the data while adding or removing nodes.&lt;/li&gt;
  &lt;li&gt;There will be minimal movement of data as if a node is removed, the data from that node will be supported by another node. Similarly, when a node is added, some data will be mapped to it as you don’t want it to sit idle.&lt;/li&gt;
  &lt;li&gt;You can have a nearly even distribution of data across all machines.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The idea is &lt;strong&gt;removing the number of nodes in the system out of the equation&lt;/strong&gt; while calculating the hash. Now hashes for data and nodes will all be independently calculated and adding or removing nodes won’t change these hashes.&lt;/p&gt;

&lt;p&gt;Now instead of assigning the data to these nodes in a sequential manner, we will plot these nodes, or their hashes, on the number line, and each node will be responsible for the range between its position and the position of the first node to its right.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_9.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;When the data comes in for storage, we will calculate its hash to determine its place on the number line. Based on which node’s range it falls in, we will map the data to that node.&lt;/p&gt;

&lt;p&gt;If you want to remove a node from this system, the range of the previous machine on the number line will be extended, and all the data from the removed node will be mapped to the previous node in the number line. This resolves the issue of data transfer as only the data from one machine will need to be mapped to another machine.&lt;/p&gt;

&lt;p&gt;But there is still a problem with this system. &lt;strong&gt;After removing a node, the ranges of certain machines might not be balanced.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;An ideal solution to this would be &lt;strong&gt;assigning data between various nodes.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The idea is to assign the same machine to multiple hashes and map each of these hashes on the number line.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_10.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This can be achieved by either using multiple hash functions or by assigning multiple identifiers to the same node, and then calculating the hashes for all of the instanced. Then, We can map them on the number line, or what we can now refer to as a consistent hashing ring, essentially representing the same node on the ring multiple times.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_11.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now the data handled by a removed node will be distributed across the ring. So when a node needs to be removed, all its identifiers will be removed and the data will be mapped to the nodes falling to the right of each identifier, as shown in the following diagram, making the distribution much more even.&lt;/p&gt;

&lt;p&gt;(노드가 삭제되도, 그 노드에 저장되어 있던 데이터가 여러 해시 함수에 의해 분리된 인스턴스에 흩어져서 저장되어 있었으므로, 다른 노드로 이동할 때도 각 인스턴스의 오른쪽 인스턴스로 저장되므로 여러 노드에 분산 저장되게 된다. -&amp;gt; 데이터가 훨씬 even해진다.)&lt;/p&gt;

&lt;p&gt;The reason why it gets even is because each identifier of machine is hashed separately, with the hash function, it is very likely that they would be arranged in a random fashion like Blue_4 - Red_1 - Blue_2 - Green_3 - Red_4 - Orange_1, which makes sure that when one machine is removed, it’s data us spread across multiple other machines.&lt;/p&gt;

&lt;p&gt;Similarly, when a new node is added, its identifiers will also be mapped across the ring, picking up data from various nodes, maintaining even distribution across the ring.&lt;/p&gt;

&lt;h1 id=&quot;where-is-it-used&quot;&gt;Where is it Used&lt;/h1&gt;

&lt;p&gt;Now we just saw how we could use consistent hashing while building a caching system. There are a lot of systems out there that use consistent hashing for improving their performance. For example, Cassandra, a distributed NoSQL Columnar DB that deals with huge traffic uses consistent hashing to distribute its data. Amazon’s Dynamo DB is another such example. It is a managed distributed DB which uses consistent hashing for distributing its data. Similarly, Couchbase is another NoSQL DB (a document DB) which uses consistent hashing to distribute its data across various instances.&lt;/p&gt;
</description>
                <pubDate>Tue, 26 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/data-engineering-series22</link>
                <guid isPermaLink="true">http://localhost:4000/data-engineering-series22</guid>
                
                <category>Data_Engineering</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Data Engineering Series [Part21]: 시스템 디자인(2) Inter-Service Communication</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#inter-service-communication&quot; id=&quot;markdown-toc-inter-service-communication&quot;&gt;Inter-Service Communication&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#modes-of-communication&quot; id=&quot;markdown-toc-modes-of-communication&quot;&gt;Modes of communication&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#synchronous-approach&quot; id=&quot;markdown-toc-synchronous-approach&quot;&gt;Synchronous Approach&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#asynchronous-approach&quot; id=&quot;markdown-toc-asynchronous-approach&quot;&gt;Asynchronous Approach&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#best-of-both-worlds&quot; id=&quot;markdown-toc-best-of-both-worlds&quot;&gt;Best of Both Worlds&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#message-queues&quot; id=&quot;markdown-toc-message-queues&quot;&gt;Message Queues&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#protocols-for-communication&quot; id=&quot;markdown-toc-protocols-for-communication&quot;&gt;Protocols for communication&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#how-clients-and-servers-interact&quot; id=&quot;markdown-toc-how-clients-and-servers-interact&quot;&gt;How clients and servers interact&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#http&quot; id=&quot;markdown-toc-http&quot;&gt;HTTP&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#websocket&quot; id=&quot;markdown-toc-websocket&quot;&gt;WebSocket&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h1 id=&quot;inter-service-communication&quot;&gt;Inter-Service Communication&lt;/h1&gt;

&lt;p&gt;In this article, we will be looking at how services interact with each other. Why is this important? Well, when you have a huge system with a lot of microservices interacting with each other, their communication needs to be efficient to provide the best user experience and also to avoid any cascading effects across the system.&lt;/p&gt;

&lt;h1 id=&quot;modes-of-communication&quot;&gt;Modes of communication&lt;/h1&gt;
&lt;p&gt;There are primarily two modes of communication between services:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Synchronous&lt;/strong&gt;: When a service &lt;strong&gt;waits&lt;/strong&gt; for a downstream system to respond before responding back to the client with a success or failure response.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Asynchronous&lt;/strong&gt;: This is a more of a fire and forget approach. A service will fire a call to the downstream system and won’t track it further.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;synchronous-approach&quot;&gt;Synchronous Approach&lt;/h1&gt;
&lt;p&gt;Let’s say you are building Amazon. You have a user U1 trying to place an order. U1 will reach out to the Order Service. Order Service will now talk to the Inventory Service to find out if a sufficient quantity of the product is available. If that is the case, Inventory Service will send a success response. Otherwise, it will respond with an error, and Order Service will respond to the user saying the order could not be placed.&lt;/p&gt;

&lt;p&gt;Now if the inventory response was a success, the Order Service will talk to the Payment Service to process the payment. Once the payment is successful, the Order Service will now talk to the Warehouse Service asking it to start packing and prepare for shipping the product to the user. Once Warehouse Service responds with a success, the Order Service will talk to a Notification Service to send an email to the user saying their order has been placed, with so and so payment details and sharing an ETA for the delivery of the product.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now, this is a happy scenario. What happens when one of the calls fails? Well, it depends on which call fails. If the call to Notification Service fails, does it make sense to cancel the order? No. We shouldn’t cancel an order just because the Notification Service failed. However, what if payment fails? Now we definitely need to cancel the order. But now we need to update the Inventory again to undo the change to the product quantity. What if the call to Inventory Service fails?&lt;/p&gt;

&lt;p&gt;So as you can see, there are some loopholes in a purely synchronous approach.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It has very high latency as the user does not get notified until all the calls have come back with a success or failure response.&lt;/li&gt;
  &lt;li&gt;The system is tightly coupled, and any failure will have cascading effects across the board.&lt;/li&gt;
  &lt;li&gt;The code becomes very complex since we need to handle all the cascading error scenarios.&lt;/li&gt;
  &lt;li&gt;Due to complexity, it requires extremely high maintenance.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;asynchronous-approach&quot;&gt;Asynchronous Approach&lt;/h1&gt;
&lt;p&gt;Let us see what happens in a purely asynchronous approach.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;U1 sends a call to the Order Service which makes asynchronous calls to all the downstream systems. In such a case, even if Inventory Service responds with an error code, or even if the payment fails, the order would get placed. Which is an even bigger mess! So how do we go about this?&lt;/p&gt;

&lt;p&gt;Well, as we can see, some parts of this process must be mandatory, and some can be done on a best-effort basis. If the Inventory Service or Payment Service responds with an error, we cannot place the order. But if the notification does not go through or the Warehouse Service is temporarily down, we don’t need to cancel our order. So we can follow a hybrid approach here; &lt;strong&gt;use a synchronous approach for the mandatory steps and an asynchronous approach for the rest.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;best-of-both-worlds&quot;&gt;Best of Both Worlds&lt;/h2&gt;
&lt;p&gt;The Hybrid approach suggests that the mandatory tasks need to be performed in a synchronous manner and everything else can be done asynchronously.&lt;/p&gt;

&lt;p&gt;So Order Service will send out a synchronous call to Inventory Service, and wait for a response. In case of success, it will call the Payment Service. If the Payment Service gives a successful response, Order Service will make parallel asynchronous calls to the Warehouse Service and Notification Service and, at the same time, respond to the user saying the order has been placed. If the Payment Service call had failed, Order Service would send an asynchronous call to the Inventory Service reverting the quantity change.&lt;/p&gt;

&lt;p&gt;So this looks like a much better solution. There are still some misses here though. What if the asynchronous call to Warehouse Service failed? It would lose the details for that order. This is where we would use &lt;strong&gt;Message Queues&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;message-queues&quot;&gt;Message Queues&lt;/h2&gt;
&lt;p&gt;Message Queues(Kafka, RabbitMQ, ActiveMQ 등) are highly fault-tolerant and persist messages for some time. How a message Queue works is, it has some Publishers adding messages to it, and some Subscribers listening to it and picking up the events meant for them at their own pace. Since these queues store messages for some time, if a subscriber is temporarily down, the messages will remain in the queue and will be picked up when the subscriber is running again.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So now, when Order Service wants to make asynchronous calls to Warehouse and Notification services, it will instead put an event in the Message Queue. Warehouse Service and Notification Service, which will be listening to the queue, will pick up the events meant for them. If one of the systems is down, the messages will remain in the queue until the service is back up and ready to receive messages again. This way, none of the data gets lost.&lt;/p&gt;

&lt;h1 id=&quot;protocols-for-communication&quot;&gt;Protocols for communication&lt;/h1&gt;

&lt;p&gt;In this article, we will look at the protocols we can use to interact with clients.&lt;/p&gt;

&lt;h2 id=&quot;how-clients-and-servers-interact&quot;&gt;How clients and servers interact&lt;/h2&gt;

&lt;p&gt;In a real-world scenario, rather than talking to a specific server, the client’s request will instead be sent to a data center, where it could be picked up by any of the servers. However, irrespective of which server receives the request, the response will be the same. Based on this flow, we can draw the following conclusions about this architecture:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It is client-driven. Only on the user’s button click will the client send the requests to the server, and the server will only respond to these requests.&lt;/li&gt;
  &lt;li&gt;It is a simple request-response model. For every request from the client, the server will respond with some information or a simple confirmation.&lt;/li&gt;
  &lt;li&gt;There are occasional requests from clients, only one request every few seconds based on the user’s actions i.e. from the client-side it is a low throughput system.&lt;/li&gt;
  &lt;li&gt;It is a stateless system i.e. irrespective of which server is responding, the response remains the same.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;http&quot;&gt;HTTP&lt;/h2&gt;

&lt;p&gt;These requirements make this a perfect use case for HTTP(s) protocol. Although these days, most architectures on HTTP have moved to HTTPS, which is a more secure version of HTTP as it prevents man-in-the-middle attacks.&lt;/p&gt;

&lt;p&gt;Now, when we are using HTTP, REST is usually the best API standard to follow as it is very widely used and very user friendly.&lt;/p&gt;

&lt;p&gt;Let us look at an example for a REST request and response:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Request:
Method: GET
URL: https://www.twitter.com/user/{id}

Response:
Status: 200 OK
Headers: &amp;lt;...&amp;gt;
Body: {
    “userId”: 1,
    “Email”: “someone@example.com”
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The client makes a request to twitter.com over HTTPS to get information about a user with an id. In response, the server sends a success status code along with the user’s user id and email. As you can see, REST API standard is pretty much self-documenting, which adds to its user friendliness.&lt;/p&gt;

&lt;p&gt;Now let us look at an example of a chat application.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We know that HTTP is a client-driven protocol, so the server cannot initiate any contact with the client. It can only respond to the client upon receiving a request. So when U1 sends a message to U2 via chat server, U2 doesn’t receive the message until it asks the server to share any pending messages. This leads to a delay when receiving messages.&lt;/p&gt;

&lt;p&gt;A solution to this would be that U2 sends frequent requests to the chat server in the hopes of receiving a message. But this puts a huge load on the chat server as it will receive a huge number of requests from all its clients.&lt;/p&gt;

&lt;p&gt;The best approach would be &lt;strong&gt;if the server could send a notification to the user every time there is a message&lt;/strong&gt;. For this, we use a protocol called &lt;strong&gt;WebSocket&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;(서버가 U2에게 보낼 메시지를 가지고 있음에도 불구하고, 능동적으로 U2에게 보내지 않는다. U2로부터 request를 받을때까지 기다린다.)&lt;br /&gt;
(U2는 언제 자신이 받아야할 메시지가 서버에 도착했는지 모르므로, 계속 서버에 request를 보내야 한다.)&lt;br /&gt;
(WebSocket을 사용하면 서버는 U2와 connection되어 있으면 request를 받지 않아도 알아서 U2에 메시지를 보낸다)&lt;br /&gt;
(connection되어 있지 않으면, 가만히 있다가, connection되고 U2가 request보내면 메시지 보낸다)&lt;br /&gt;
(WebSocket에도 단점은 있다. cost of maintaining a persistent connection with millions of users.)&lt;/p&gt;

&lt;h2 id=&quot;websocket&quot;&gt;WebSocket&lt;/h2&gt;
&lt;p&gt;A WebSocket connection is a persistent connection. It is also a bidirectional protocol, where communication can be initiated by the client or the server as long as there is an open connection. It is &lt;strong&gt;optimized for high-frequency communication&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Let’s look at how our chat application would work in the case of WebSocket protocol.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;First, U1 and U2 will establish HTTP connections with the chat server, which are then upgraded to a WebSocket connection. When U1 sends a message for U2 via the chat server, it will store the message along with its status, RECEIVED, let’s say.&lt;/p&gt;

&lt;p&gt;The chat server, if it has an open connection with U2, will then send the message to U2 and update the status to SENT. If U2 was not online and there was no open connection between U2 and the server, the messages will be saved until U2 comes online and requests the server to send all pending messages. The server will send all messages with the status RECEIVED and update the status to SENT.&lt;/p&gt;

&lt;p&gt;As you can see, with this approach we have:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Reduced the latency, since the server can simply send the messages over an open connection&lt;/li&gt;
  &lt;li&gt;Saved on CPU and bandwidth, as the client doesn’t need to unnecessarily send requests to the server and the server is not under unnecessary load&lt;/li&gt;
  &lt;li&gt;Provided better user experience&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Even with the benefits, there is a high cost to using WebSockets; that is the cost of maintaining a persistent connection with millions of users.&lt;/p&gt;

&lt;p&gt;So how do we decide whether to use HTTP or WebSocket? Do we always go for Websocket then? Well, not really, as WebSocket is much more expensive than HTTP. We can safely say, if the communication between client and server is at a &lt;strong&gt;lower throughput on the client-side&lt;/strong&gt;, HTTP is the way to go. &lt;strong&gt;If the communication is always client-driven&lt;/strong&gt;, WebSocket is not needed. Also, if you are on a &lt;strong&gt;tight budget&lt;/strong&gt;, HTTP may be the better choice.&lt;/p&gt;

&lt;p&gt;On the other hand, if the communication from the &lt;strong&gt;client is at a higher throughput&lt;/strong&gt;, WebSocket may be a better option. If the &lt;strong&gt;communication can be driven by both client and server&lt;/strong&gt;, WebSocket is the way to go. Although here comes the tradeoff between cost and performance. We must decide if the optimization is really worth the huge cost of maintaining persistent connections with so many users.&lt;/p&gt;
</description>
                <pubDate>Tue, 26 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/data-engineering-series21</link>
                <guid isPermaLink="true">http://localhost:4000/data-engineering-series21</guid>
                
                <category>Data_Engineering</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Data Engineering Series [Part20]: 시스템 디자인(1) Intro + Architecture</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#intro&quot; id=&quot;markdown-toc-intro&quot;&gt;Intro&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#what-will-be-covered&quot; id=&quot;markdown-toc-what-will-be-covered&quot;&gt;What will be covered?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#high-level-system-design&quot; id=&quot;markdown-toc-high-level-system-design&quot;&gt;High Level System Design&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#low-level-system-design-code-quality&quot; id=&quot;markdown-toc-low-level-system-design-code-quality&quot;&gt;Low Level System Design (Code Quality)&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#application-architecture&quot; id=&quot;markdown-toc-application-architecture&quot;&gt;Application Architecture&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#monolithic-architecture&quot; id=&quot;markdown-toc-monolithic-architecture&quot;&gt;Monolithic Architecture&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#microservice-architecture&quot; id=&quot;markdown-toc-microservice-architecture&quot;&gt;Microservice Architecture&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot; id=&quot;markdown-toc-conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h1 id=&quot;intro&quot;&gt;Intro&lt;/h1&gt;

&lt;h2 id=&quot;what-will-be-covered&quot;&gt;What will be covered?&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Introduction to System Design: Start with an introduction of the course, explanations on high level and low level design, interviewer’s expectations, and how to approach these kind in an interview.&lt;/li&gt;
  &lt;li&gt;System Design Basics: Build a strong foundation of System Design fundamentals that are useful in understanding the dynamics of highly scalable systems.&lt;/li&gt;
  &lt;li&gt;System Design Case Studies: Cover the 11 most frequently asked interview questions with a detailed walkthrough.&lt;/li&gt;
  &lt;li&gt;Problem Solving: Apply your understanding of the preceding chapters with the help of some practice problems and quizzes.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;high-level-system-design&quot;&gt;High Level System Design&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Overall architecture&lt;/strong&gt;: How the system can be built such that it takes care of scalability, latency, and other performance requirements&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Components and services&lt;/strong&gt;: Any system is a collection of various services and other components interacting with each other. In this part of high level design, we need to decide how the system will be broken down, what will the microservices be, and their scope.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Interaction between the systems&lt;/strong&gt;: How will the systems interact with each other? What protocols will you use? Will it be synchronous or asynchronous? You need to make these decisions based on the requirements.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Databases&lt;/strong&gt;: What databases will you need? What kind of data do you need to store? SQL or NoSQL, what will be the database schema? Depending on how much detail the interviewer wants you to go into, you may have to make these decisions as well.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;low-level-system-design-code-quality&quot;&gt;Low Level System Design (Code Quality)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: If you’re trying to build a web server, define your APIs clearly. For example, if you decide to make REST APIs, ensure they follow REST standards. Similarly, if you are building a library, define the APIs in a very clean manner as publicly accessible functions such that the client can easily integrate them&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Test Code&lt;/strong&gt;: This means we should have a working code with some basic test cases that are passing for the logic we have written.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Modular&lt;/strong&gt;: how easy it is to add new features without interfering with existing code.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;application-architecture&quot;&gt;Application Architecture&lt;/h1&gt;

&lt;h2 id=&quot;monolithic-architecture&quot;&gt;Monolithic Architecture&lt;/h2&gt;

&lt;p&gt;Back when the internet was just starting to gain popularity, websites used to serve mostly static content. There wasn’t a lot of user interaction like we see now. The applications were much less complex, and so was their architecture. A single application used to take care of the entire user journey, everything from UI rendering to backend business logic to fetching the data from DBs or File Systems. This was the world of Web 1.0.&lt;/p&gt;

&lt;p&gt;Then came Web 2.0 with social networks, e-commerce, and online gaming and things became a lot more interactive. By this time everything was still maintained in a single huge codebase. If you consider an e-commerce system, back then everything from UI to business logic for payments, carts, orders, etc. was maintained in a single codebase. This is known as Monolithic Architecture.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The problem with this approach was that the code was very complex, difficult to maintain, and hard to iterate and improve. On top of that, multiple people were working on the same codebase; it was a recipe for disaster.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Disadvantage of Monolithic Architecture&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;One of the most common problems with monoliths is that you are &lt;strong&gt;bound to a single technology stack&lt;/strong&gt;. Suppose you have a monolith built on Java with Spring framework. Now you need to add some Machine Learning logic, and you want to use Python for it. That is nearly impossible in monolithic architecture. You either need to figure out a way to do this with Java, or you need a standalone application that handles your machine learning logic, which defeats the purpose of a monolithic app.&lt;/li&gt;
  &lt;li&gt;Another problem would be that it is very &lt;strong&gt;easy to break&lt;/strong&gt; things in such an architecture. That is because, when you have such a huge codebase, it is nearly impossible for everyone to know everything about how the entire system works. If you change some logic in the shared code, you might end up breaking someone else’s feature. Sure you can have test cases, but even those are not enough sometimes.&lt;/li&gt;
  &lt;li&gt;Another major issue is scalability. It is very &lt;strong&gt;tricky to scale a monolithic application&lt;/strong&gt;. Let us look at the example of an e-commerce application. In case of a Black Friday sale, you might need to scale your payments and cart modules, but Warehouse and Notification modules can continue to work at the same pace. This cannot be done in a monolithic app. Since it is the same codebase, you will need to deploy the entire system again and again. This means the capacity meant for the Warehouse module might be sitting idle or that the Payment and Cart modules may choke the rest of the system.&lt;/li&gt;
  &lt;li&gt;Deployments are also a very tedious process here. Since the code is huge, it takes &lt;strong&gt;much longer to build&lt;/strong&gt;, package, and deploy the code. That said, if you update the code for Warehousing, even the Payments module must be redeployed since everything is packaged together.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;microservice-architecture&quot;&gt;Microservice Architecture&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The idea is to break down the application into logical components such that these components become services of their own. Normally this is also how the teams would be structured, so each team would work on the services that handle their features. These services will now be communicating with each other via a set of API calls like REST APIs or Remote Procedure Calls.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Benefits of Microservice Architecture&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We are not bound to a single technology stack anymore. Different services can use different languages or databases as needed.&lt;/li&gt;
  &lt;li&gt;Each system does one thing and does it well, without worrying about breaking another set of features.&lt;/li&gt;
  &lt;li&gt;Engineers will be working on and maintaining a smaller codebase.&lt;/li&gt;
  &lt;li&gt;Iterating, deploying, and testing becomes a lot easier.&lt;/li&gt;
  &lt;li&gt;Unlike in monolith, we can now independently scale up Cart and Payments Services, and the rest of the services can continue working as they are. This ensures optimized use of resources and makes auto-scaling a lot easier.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantage of Microservice Architecture&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Latency
    &lt;ul&gt;
      &lt;li&gt;One of the key reasons is latency. Function calls are faster than API calls, so it makes sense that monoliths will have lower latency. Usually, this latency is not high enough to be noticed by the user, but if you are working on something that needs a response in a few microseconds then you should definitely think about using monolithic architecture.&lt;/li&gt;
      &lt;li&gt;With network calls comes the possibility of network failures and slightly increases the complexity of error handling and retries.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Backward Compatibility
    &lt;ul&gt;
      &lt;li&gt;If a service needs a new mandatory parameter and the other services have not made the change accordingly, certain flows will break.&lt;/li&gt;
      &lt;li&gt;In monolith it will be caught in the development phase since the compiler will throw an error. To solve this we need some good automated test cases.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Logging
    &lt;ul&gt;
      &lt;li&gt;If you need to trace logs for a user in monoliths, it is easy to do so as they are all in the same place. But in microservices, for each request from the user there will be multiple service calls.&lt;/li&gt;
      &lt;li&gt;In the below example, consider a single request from the user to the order service. The order service is talking to Inventory, Payment, Warehouse, and Notification Services, and thus there will be logs in each of these services. So tracing exactly what happened becomes very difficult as we need to check logs in each system.&lt;/li&gt;
      &lt;li&gt;A better approach would be to store all the logs in a central place where they can be queried. This is a cost since you either need to build a Log Aggregation System or buy a third-party system’s license.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;In conclusion, if you are a small business working with a small team and have a limited set of features, monolith might be a better approach for you. However, if you are working on a huge product with hundreds of microservices, the maintenance cost of microservices will be worthwhile.&lt;/p&gt;

&lt;p&gt;Also, usually, when you think about HLD(High Level Design) interviews, chances are you will be developing an overall architecture for a complex system that might be difficult to design in a monolithic manner. So thinking in terms of microservices will be a good idea.&lt;/p&gt;
</description>
                <pubDate>Tue, 26 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/data-engineering-series20</link>
                <guid isPermaLink="true">http://localhost:4000/data-engineering-series20</guid>
                
                <category>Data_Engineering</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Data Engineering Series [Part19]: 로그 구조 스토리지</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;
</description>
                <pubDate>Mon, 25 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/data-engineering-series19</link>
                <guid isPermaLink="true">http://localhost:4000/data-engineering-series19</guid>
                
                <category>Data_Engineering</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Data Engineering Series [Part18]: APIs</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#event-driven-api&quot; id=&quot;markdown-toc-event-driven-api&quot;&gt;Event Driven API&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#web-api&quot; id=&quot;markdown-toc-web-api&quot;&gt;Web API&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;event-driven-api&quot;&gt;Event Driven API&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Webhooks&lt;/li&gt;
  &lt;li&gt;Websockets&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;web-api&quot;&gt;Web API&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;REST&lt;/li&gt;
  &lt;li&gt;RPC&lt;/li&gt;
  &lt;li&gt;GraphQL&lt;/li&gt;
&lt;/ul&gt;
</description>
                <pubDate>Sun, 24 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/data-engineering-series18</link>
                <guid isPermaLink="true">http://localhost:4000/data-engineering-series18</guid>
                
                <category>Data_Engineering</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Data Engineering Series [Part17]: 분산 시스템(Distributed Systems)의 핵심</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#장애-대응fault-tolerance&quot; id=&quot;markdown-toc-장애-대응fault-tolerance&quot;&gt;장애 대응(Fault Tolerance)&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#장애-감지와-회복&quot; id=&quot;markdown-toc-장애-감지와-회복&quot;&gt;장애 감지와 회복&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#리더와-팔로워&quot; id=&quot;markdown-toc-리더와-팔로워&quot;&gt;리더와 팔로워&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#복제&quot; id=&quot;markdown-toc-복제&quot;&gt;복제&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#일관성-보장&quot; id=&quot;markdown-toc-일관성-보장&quot;&gt;일관성 보장&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#합의-알고리즘&quot; id=&quot;markdown-toc-합의-알고리즘&quot;&gt;합의 알고리즘&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#분산-처리distributed-computing&quot; id=&quot;markdown-toc-분산-처리distributed-computing&quot;&gt;분산 처리(Distributed Computing)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#시스템-확장scale-out&quot; id=&quot;markdown-toc-시스템-확장scale-out&quot;&gt;시스템 확장(Scale-out)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#참고&quot; id=&quot;markdown-toc-참고&quot;&gt;참고&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;distributed system은 fault tolerance 하기 위해 여러 서버에 replication. replication할 때 유의할 점이 consistency (어떤 서버가 선택되어도 클라이언트에게 일관된 결과를 돌려 주는가). consistency를 제공하기 위한 것이 합의 알고리즘?&lt;/p&gt;

&lt;h1 id=&quot;장애-대응fault-tolerance&quot;&gt;장애 대응(Fault Tolerance)&lt;/h1&gt;

&lt;h2 id=&quot;장애-감지와-회복&quot;&gt;장애 감지와 회복&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Heartbeats and Ping&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;리더와-팔로워&quot;&gt;리더와 팔로워&lt;/h2&gt;

&lt;p&gt;동기화는 비용이 많이 들 수 있다. 동기화 오버헤드를 줄이기 위해 일부 알고리즘에는 분산 알고리즘의 단계를 수행 및 조정하는 리더 프로세스가 있다. 일반적으로 분산 시스템의 프로세스는 균일하고 모든 프로세스가 리더 역할을 맡을 수 있다. 장애가 발생하면 어떤 프로세스라도 리더 선출 과정을 시작할 수 있고 선출된 프로세스는 이전 리더의 작업을 이어서 수행한다.&lt;/p&gt;

&lt;p&gt;이상적으로는 한 번에 하나의 리더만 존재하고, 여러 리더가 선출되고 서로 존재를 모르는 상황(split brain 현상)은 절대로 발생하지 않아야 한다. 하지만 많은 리더 선출 알고리즘이 이 조건을 위반한다. 이 문제를 해결하기 위해서는 클러스터 구성원 과반수의 동의가 필요하다. 멀티 팍소스와 래프트를 비롯한 여러 합의 알고리즘은 리더 프로세스가 조율을 담당한다.&lt;/p&gt;

&lt;p&gt;선출 작업은 결정론적이어야 한다. 정확히 하나의 리더를 선출하고 모든 참가자가 결과를 인정해야 한다. 선출된 새로운 리더는 모든 구성원에게 자신의 존재를 알려야 한다.&lt;/p&gt;

&lt;p&gt;리더 프로세스가 있는 시스템의 가장 큰 문제는 리더가 병목 지점이 될 수 있다는 점이다. 이 문제를 해결하기 위해 많은 시스템이 데이터를 독립적인 파티션으로 나누고 각 파티션별로 리더를 선출한다. 스패너(Spanner)가 이 방식을 사용한다.&lt;/p&gt;

&lt;p&gt;선출 작업은 비용이 높은 작업이지만 자주 수행되지 않기 때문에 시스템 성능에 큰 영향을 주지 않는다.&lt;/p&gt;

&lt;p&gt;리더의 정체는 프로세스가 모르는 사이에 바뀔 수 있다. 따라서 각 프로세스가 개별적으로 알고 있는 리더에 대한 정보가 유효한지 확인해야 한다. 이 문제는 리더 선출 알고리즘과 장애 감지 알고리즘을 같이 사용해 해결할 수 있다. 예를 들어 안정적인 리더 선출 알고리즘은 안정적인 프로세스에 리더의 기회를 주고 타임아웃 기반의 장애 감지 알고리즘을 사용해 해당 프로세스에 장애가 발생하지 않고 접근이 가능한 동안 계속해서 리더 역할을 유지할 수 있도록 보장한다.&lt;/p&gt;

&lt;p&gt;리더에 의존하는 대부분의 알고리즘은 여러 리더가 존재하는 것을 허용하고 리더 사이의 충돌을 최대한 빠르게 해결한다.&lt;/p&gt;

&lt;h2 id=&quot;복제&quot;&gt;복제&lt;/h2&gt;

&lt;p&gt;In a distributed system data is stored is over different computers in a network. Therefore, we need to make sure that data is readily available for the users. Availability of the data is an important factor often accomplished by data replication. Replication is the practice of keeping several copies of data in different places.&lt;/p&gt;

&lt;p&gt;Why do we require replication?&lt;br /&gt;
The first and foremost thing is that it makes our system more stable because of node replication. It is good to have replicas of a node in a network due to following reasons:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If a node stops working, the distributed network will still work fine due to its replicas which will be there. Thus it increases the fault tolerance of the system.&lt;/li&gt;
  &lt;li&gt;It also helps in load sharing where loads on a server are shared among different replicas.&lt;/li&gt;
  &lt;li&gt;It enhances the availability of the data. If the replicas are created and data is stored near to the consumers, it would be easier and faster to fetch data.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Types of Replication&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Active Replication&lt;/li&gt;
  &lt;li&gt;Passive Replication&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Active Replication&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The request of the client goes to all the replicas.&lt;/li&gt;
  &lt;li&gt;It is to be made sure that every replica receives the client request in the same order else the system will get inconsistent.&lt;/li&gt;
  &lt;li&gt;There is no need for coordination because each copy processes the same request in the same sequence.&lt;/li&gt;
  &lt;li&gt;All replicas respond to the client’s request.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It is really simple. The codes in active replication are the same throughout.&lt;/li&gt;
  &lt;li&gt;It is transparent.&lt;/li&gt;
  &lt;li&gt;Even if a node fails, it will be easily handled by replicas of that node.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It increases resource consumption. The greater the number of replicas, the greater the memory needed.&lt;/li&gt;
  &lt;li&gt;It increases the time complexity. If some change is done on one replica it should also be done in all others.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Passive Replication&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The client request goes to the primary replica, also called the main replica.&lt;/li&gt;
  &lt;li&gt;There are more replicas that act as backup for the primary replica.&lt;/li&gt;
  &lt;li&gt;Primary replica informs all other backup replicas about any modification done.&lt;/li&gt;
  &lt;li&gt;The response is returned to the client by a primary replica.&lt;/li&gt;
  &lt;li&gt;Periodically primary replica sends some signal to backup replicas to let them know that it is working perfectly fine.&lt;/li&gt;
  &lt;li&gt;In case of failure of a primary replica, a backup replica becomes the primary replica.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The resource consumption is less as backup servers only come into play when the primary server fails.&lt;/li&gt;
  &lt;li&gt;The time complexity of this is also less as there’s no need for updating in all the nodes replicas, unlike active replication.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If some failure occurs, the response time is delayed.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;일관성-보장&quot;&gt;일관성 보장&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;CAP Theorem&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Eventual Consistency&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Eventual consistency is a consistency model that enables the data store to be highly available. It is also known as optimistic replication &amp;amp; is key to distributed systems. So, how exactly does it work? Let’s Understand this with the help of a use case.&lt;/p&gt;

&lt;p&gt;Real World Use Case :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Think of a popular microblogging site deployed across the world in different geographical regions like Asia, America, and Europe. Moreover, each geographical region has multiple data center zones: North, East, West, and South.&lt;/li&gt;
  &lt;li&gt;Furthermore, each zone has multiple clusters which have multiple server nodes running. So, we have many datastore nodes spread across the world that micro-blogging site uses for persisting data. Since there are so many nodes running, there is no single point of failure.&lt;/li&gt;
  &lt;li&gt;The data store service is highly available. Even if a few nodes go down persistence service is still up. Let’s say a celebrity makes a post on the website that everybody starts liking around the world.&lt;/li&gt;
  &lt;li&gt;At a point in time, a user in Japan likes a post which increases the “Like” count of the post from say 100 to 101. At the same point in time, a user in America, in a different geographical zone, clicks on the post, and he sees “Like” count as 100, not 101.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Reason for the above Use case :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Simply, because the new updated value of the Post “Like” counter needs some time to move from Japan to America and update server nodes running there. Though the value of the counter at that point in time was 101, the user in America sees old inconsistent values.&lt;/li&gt;
  &lt;li&gt;But when he refreshes his web page after a few seconds “Like” counter value shows as 101. So, data was initially inconsistent but eventually got consistent across server nodes deployed around the world. This is what eventual consistency is.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Strong Consistency&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Strong Consistency simply means the data must be strongly consistent at all times. All the server nodes across the world should contain the same value as an entity at any point in time. And the only way to implement this behavior is by locking down the nodes when being updated.&lt;/p&gt;

&lt;p&gt;Real World Use Case :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Let’s continue the same Eventual Consistency example from the previous lesson. To ensure Strong Consistency in the system, when a user in Japan likes posts, all nodes across different geographical zones must be locked down to prevent any concurrent updates.&lt;/li&gt;
  &lt;li&gt;This means at one point in time, only one user can update the post “Like” counter value. So, once a user in Japan updates the “Like” counter from 100 to 101. The value gets replicated globally across all nodes. Once all nodes reach consensus, locks get lifted. Now, other users can Like posts.&lt;/li&gt;
  &lt;li&gt;If the nodes take a while to reach a consensus, they must wait until then. Well, this is surely not desired in the case of social applications. But think of a stock market application where the users are seeing different prices of the same stock at one point in time and updating it concurrently. This would create chaos. Therefore, to avoid this confusion we need our systems to be Strongly Consistent.&lt;/li&gt;
  &lt;li&gt;The nodes must be locked down for updates. Queuing all requests is one good way of making a system Strongly Consistent. The strong Consistency model hits the capability of the system to be Highly Available &amp;amp; perform concurrent updates. This is how strongly consistent ACID transactions are implemented.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;ACID Transaction Support&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Distributed systems like NoSQL databases which scale horizontally on the fly don’t support ACID transactions globally &amp;amp; this is due to their design. The whole reason for the development of NoSQL tech is the ability to be Highly Available and Scalable. If we must lock down nodes every time, it becomes just like SQL. So, NoSQL databases don’t support ACID transactions and those that claim to, have terms and conditions applied to them. Generally, transaction support is limited to a geographic zone or an entity hierarchy. Developers of tech make sure that all the Strongly consistent entity nodes reside in the same geographic zone to make ACID transactions possible.&lt;/p&gt;

&lt;p&gt;Conclusion: For transactional things go for MySQL because it provides a lock-in feature and supports ACID transactions.&lt;/p&gt;

&lt;h2 id=&quot;합의-알고리즘&quot;&gt;합의 알고리즘&lt;/h2&gt;

&lt;p&gt;Consensus is a general agreement on a decision made by the majority of those involved. For example, the problem may be as simple as friends trying to decide which restaurant has multiple options to choose from or complex as decisions on distributed systems.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Need of consensus in a distributed system&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In a distributed system, nodes are distributed across the network. Some of these nodes might get failed(crash fault) or starts behaving abnormally (Byzantine Fault). In such a scenario, it becomes difficult to come to a common decision. More concisely,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;There are n processes, m of which may be faulty.&lt;/li&gt;
  &lt;li&gt;The task is to make all the Nonfaulty processes agree on some value(s) even in the presence of the faulty processes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So we can remove these problems by given below solutions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Consensus Without Any Fault&lt;/li&gt;
  &lt;li&gt;Consensus With at most m Crash Faults&lt;/li&gt;
  &lt;li&gt;Consensus With at most m Byzantine Faults&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;멀티 팍소스&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;래프트&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;분산-처리distributed-computing&quot;&gt;분산 처리(Distributed Computing)&lt;/h1&gt;

&lt;h1 id=&quot;시스템-확장scale-out&quot;&gt;시스템 확장(Scale-out)&lt;/h1&gt;

&lt;h1 id=&quot;참고&quot;&gt;참고&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.geeksforgeeks.org/consensus-problem-of-distributed-systems/?ref=gcse&quot;&gt;GeeksforGeeks: Consensus Problem of Distributed Systems&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
                <pubDate>Sat, 23 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/data-engineering-series17</link>
                <guid isPermaLink="true">http://localhost:4000/data-engineering-series17</guid>
                
                <category>Data_Engineering</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Data Engineering Series [Part16]: 분산 시스템(Distributed Systems)에서의 네트워크와 운영체제</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#운영체제-관점&quot; id=&quot;markdown-toc-운영체제-관점&quot;&gt;운영체제 관점&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#네트워크-inter-process-communication&quot; id=&quot;markdown-toc-네트워크-inter-process-communication&quot;&gt;네트워크: Inter Process Communication&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#remote-procedure-callrpc&quot; id=&quot;markdown-toc-remote-procedure-callrpc&quot;&gt;Remote Procedure Call(RPC)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#message-based-communication&quot; id=&quot;markdown-toc-message-based-communication&quot;&gt;Message based Communication&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#sockets&quot; id=&quot;markdown-toc-sockets&quot;&gt;Sockets&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#참고&quot; id=&quot;markdown-toc-참고&quot;&gt;참고&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;운영체제-관점&quot;&gt;운영체제 관점&lt;/h1&gt;

&lt;h1 id=&quot;네트워크-inter-process-communication&quot;&gt;네트워크: Inter Process Communication&lt;/h1&gt;

&lt;p&gt;Inter-process communication (IPC) is set of interfaces, which is usually programmed in order for the programs to communicate between series of processes. This allows running programs concurrently in an Operating System.&lt;/p&gt;

&lt;p&gt;Interprocess communication is at the heart of all distributed systems. It makes no sense to study distributed systems without carefully examining the ways that processes on different machines can exchange information. Communication in distributed systems is always based on low-level message passing as offered by the underlying network. Expressing communication through message passing is harder than using primitives based on shared memory, as available for nondistrib- uted platforms. Modem distributed systems often consist of thousands or even millions of processes scattered across a network with unreliable communication such as the Internet. Unless the primitive communication facilities of computer networks are replaced by something else, development of large-scale distributed applications is extremely difficult.&lt;/p&gt;

&lt;p&gt;In this chapter, we start by discussing the rules that communicating processes must adhere to, known as protocols, and concentrate on structuring those proto- cols in the form of layers. We then look at three widely-used models for commu- nication: Remote Procedure Call (RPC), Message-Oriented Middleware (MOM), and data streaming. We also discuss the general problem of sending data to multi- ple receivers, called multicasting.&lt;/p&gt;

&lt;p&gt;Our first model for communication in distributed systems is the remote proce- dure call (RPC). An RPC aims at hiding most of the intricacies of message pass- ing, and is ideal for client-server applications.&lt;/p&gt;

&lt;p&gt;In many distributed applications, communication does not follow the rather strict pattern of client-server interaction. In those cases, it turns out that thinking in terms of messages is more appropriate. However, the low-level communication facilities of computer networks are in many ways not suitable due to their lack of distribution transparency.&lt;/p&gt;

&lt;p&gt;An alternative is to use a high-level message-queuing model, in which communication proceeds much the same as in electronic maiI systems. Message-oriented middleware (MOM) is a subject important enough to warrant a section of its own.&lt;/p&gt;

&lt;p&gt;With the advent of multimedia distributed systems, it became apparent that
many systems were lacking support for communication of continuous media, such as audio and video. What is needed is the notion of a stream that can support the continuous flow of messages, subject to various timing constraints. Streams are discussed in a separate section.&lt;/p&gt;

&lt;p&gt;Finally, since our understanding of setting up multicast facilities has im- proved, novel and elegant solutions for data dissemination have emerged. We pay separate attention to this subject in the last section of this chapter.&lt;/p&gt;

&lt;h2 id=&quot;remote-procedure-callrpc&quot;&gt;Remote Procedure Call(RPC)&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/dist_5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Remote Procedure Call (RPC) is a communication technology that is used by one program to make a request to another program for utilizing its service on a network without even knowing the network’s details. A function call or a subroutine call are other terms for a procedure call.&lt;/p&gt;

&lt;p&gt;It is based on the client-server concept. The client is the program that makes the request, and the server is the program that gives the service. An RPC, like a local procedure call, is based on the synchronous operation that requires the requesting application to be stopped until the remote process returns its results. Multiple RPCs can be executed concurrently by utilizing lightweight processes or threads that share the same address space.&lt;/p&gt;

&lt;p&gt;Remote Procedure Call program as often as possible utilizes the Interface Definition Language (IDL), a determination language for describing a computer program component’s Application Programming Interface (API). In this circumstance, IDL acts as an interface between machines at either end of the connection, which may be running different operating systems and programming languages.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Elements of RPC&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/rpc_1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Client&lt;/strong&gt;: The client process initiates RPC. The client makes a standard call, which triggers a correlated procedure in the client stub.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Client Stub&lt;/strong&gt;: Stubs are used by RPC to achieve semantic transparency. The client calls the client stub. Client stub does the following tasks:
    &lt;ul&gt;
      &lt;li&gt;The first task performed by client stub is when it receives a request from a client, it packs(marshalls) the parameters and required specifications of remote/target procedure in a message.&lt;/li&gt;
      &lt;li&gt;The second task performed by the client stub is upon receiving the result values after execution, it unpacks (unmarshalled) those results and sends them to the Client.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;RPC Runtime&lt;/strong&gt;: The RPC runtime is in charge of message transmission between client and server via the network. Retransmission, acknowledgment, routing, and encryption are all tasks performed by it. On the client-side, it receives the result values in a message from the server-side, and then it further sends it to the client stub whereas, on the server-side, RPC Runtime got the same message from the server stub when then it forwards to the client machine. It also accepts and forwards client machine call request messages to the server stub.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Server Stub&lt;/strong&gt;: Server stub does the following tasks:
    &lt;ul&gt;
      &lt;li&gt;The first task performed by server stub is that it unpacks(unmarshalled) the call request message which is received from the local RPC Runtime and makes a regular call to invoke the required procedure in the server.&lt;/li&gt;
      &lt;li&gt;The second task performed by server stub is that when it receives the server’s procedure execution result, it packs it into a message and asks the local RPC Runtime to transmit it to the client stub where it is unpacked.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Server&lt;/strong&gt;: After receiving a call request from the client machine, the server stub passes it to the server. The execution of the required procedure is made by the server and finally, it returns the result to the server stub so that it can be passed to the client machine using the local RPC Runtime.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Working Procedure for RPC Model&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The process arguments are placed in a precise location by the caller when the procedure needs to be called.&lt;/li&gt;
  &lt;li&gt;Control at that point passed to the body of the method, which is having a series of instructions.&lt;/li&gt;
  &lt;li&gt;The procedure body is run in a recently created execution environment that has duplicates of the calling instruction’s arguments.&lt;/li&gt;
  &lt;li&gt;At the end, after the completion of the operation, the calling point gets back the control, which returns a result.
    &lt;ul&gt;
      &lt;li&gt;The call to a procedure is possible only for those procedures that are not within the caller’s address space because both processes (caller and callee) have distinct address space and the access is restricted to the caller’s environment’s data and variables from the remote procedure.&lt;/li&gt;
      &lt;li&gt;The caller and callee processes in the RPC communicate to exchange information via the message-passing scheme.&lt;/li&gt;
      &lt;li&gt;The first task from the server-side is to extract the procedure’s parameters when a request message arrives, then the result, send a reply message, and finally wait for the next call message.&lt;/li&gt;
      &lt;li&gt;Only one process is enabled at a certain point in time.&lt;/li&gt;
      &lt;li&gt;The caller is not always required to be blocked.&lt;/li&gt;
      &lt;li&gt;The asynchronous mechanism could be employed in the RPC that permits the client to work even if the server has not responded yet.&lt;/li&gt;
      &lt;li&gt;In order to handle incoming requests, the server might create a thread that frees the server for handling consequent requests.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/dist_4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Advantages of Remote Procedure Calls&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The technique of using procedure calls in RPC permits high-level languages to provide communication between clients and servers.&lt;/li&gt;
  &lt;li&gt;This method is like a local procedure call but with the difference that the called procedure is executed on another process and a different computer.&lt;/li&gt;
  &lt;li&gt;The thread-oriented model is also supported by RPC in addition to the process model.&lt;/li&gt;
  &lt;li&gt;The RPC mechanism is employed to conceal the core message passing method.&lt;/li&gt;
  &lt;li&gt;The amount of time and effort required to rewrite and develop the code is minimal.&lt;/li&gt;
  &lt;li&gt;The distributed and local environments can both benefit from remote procedure calls.&lt;/li&gt;
  &lt;li&gt;To increase performance, it omits several of the protocol layers.&lt;/li&gt;
  &lt;li&gt;Abstraction is provided via RPC.  To exemplify, the user is not known about the nature of message-passing in network communication.&lt;/li&gt;
  &lt;li&gt;RPC empowers the utilization of applications in a distributed environment.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages of Remote Procedure Calls&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In Remote Procedure Calls parameters are only passed by values as pointer values are not allowed.&lt;/li&gt;
  &lt;li&gt;It involves a communication system with another machine and another process, so this mechanism is extremely prone to failure.&lt;/li&gt;
  &lt;li&gt;The RPC concept can be implemented in a variety of ways, hence there is no standard.&lt;/li&gt;
  &lt;li&gt;Due to the interaction-based nature, there is no flexibility for hardware architecture in RPC.&lt;/li&gt;
  &lt;li&gt;Due to a remote procedure call, the process’s cost has increased.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;message-based-communication&quot;&gt;Message based Communication&lt;/h2&gt;

&lt;p&gt;In the development of models and technologies, message abstraction is a necessary aspect that enables distributed computing. Distributed system is defined as a system in which components reside at networked communication and synchronise its functions only by movement of messages. In this, message recognizes any discrete data that is moved from one entity to another. It includes any kind of data representation having restriction of size and time, whereas it invokes a remote procedure or a sequence of object instance or a common message. This is the reason that “message-based communication model” can be beneficial to refer various model for inter-process communication, which is based on the data streaming abstraction.&lt;/p&gt;

&lt;p&gt;Various distributed programming model use this type of communication despite of the abstraction which is shown to developers for programming the co-ordination of shared components. Below are some major distributed programming models that uses “message-based communication model”&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Message Passing
    &lt;ul&gt;
      &lt;li&gt;In this model, the concept of message as the major abstraction of model is introduced. The units which inter-change the data and information that is explicitly encode, in the form of message. According to then model, the schema and content of message changes or varies. Message Passing Interface and OpenMP are major example of this type of model.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Remote Procedure Call
    &lt;ul&gt;
      &lt;li&gt;This model explores the keys of procedure call beyond the restrictions of a single process, thus pointing the execution of program in remote processes. In this, primary client-server is implied. A remote process maintains a server component, thus enabling client processes to invoke the approaches and returns the output of the execution. Messages, created by the Remote Procedure Call (RPC) implementation, retrieve the information of the procedure itself and that procedure is to execute having necessary arguments and also returns the values. The use of messages regarding this referred as marshal-ling of the arguments and return values.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sockets&quot;&gt;Sockets&lt;/h2&gt;

&lt;p&gt;This method is mostly used to communicate over a network between a client and a server. It allows for a standard connection which is computer and OS independent.&lt;/p&gt;

&lt;h1 id=&quot;참고&quot;&gt;참고&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.geeksforgeeks.org/interprocess-communication-in-distributed-systems/?ref=gcse&quot; target=&quot;_blank&quot;&gt;GeeksforGeeks: Interprocess Communication in Distributed Systems&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;amp;blogId=horajjan&amp;amp;logNo=220956169499&quot; target=&quot;_blank&quot;&gt;조원호의 행복공간: [네트워크] IPC와 RPC의 차이점&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
                <pubDate>Fri, 22 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/data-engineering-series16</link>
                <guid isPermaLink="true">http://localhost:4000/data-engineering-series16</guid>
                
                <category>Data_Engineering</category>
                
                
                <category>DE</category>
                
            </item>
        
    </channel>
</rss>