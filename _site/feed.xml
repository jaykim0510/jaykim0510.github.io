<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Code Museum</title>
        <description>Jay Tech personal blogging theme for Jekyll</description>
        <link>http://localhost:4000/</link>
        <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
        <pubDate>Tue, 02 Aug 2022 13:19:59 +0900</pubDate>
        <lastBuildDate>Tue, 02 Aug 2022 13:19:59 +0900</lastBuildDate>
        <generator>Jekyll v4.2.1</generator>
        
            <item>
                <title>MySQL Series [Part15] IntelliJ IDE를 이용한 데이터베이스 시각화</title>
                <description>&lt;hr /&gt;
&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#참고&quot; id=&quot;markdown-toc-참고&quot;&gt;참고&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;참고&quot;&gt;참고&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.jetbrains.com/help/idea/creating-diagrams.html&quot; target=&quot;_blank&quot;&gt;IntelliJ: Database diagrams&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
                <pubDate>Fri, 29 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/mysql-series15</link>
                <guid isPermaLink="true">http://localhost:4000/mysql-series15</guid>
                
                <category>MySQL</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>MySQL Series [Part14] MySQL Optimizing SELECT Statements</title>
                <description>&lt;hr /&gt;
&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#optimization-overview&quot; id=&quot;markdown-toc-optimization-overview&quot;&gt;Optimization Overview&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#things-to-consider-for-optimization&quot; id=&quot;markdown-toc-things-to-consider-for-optimization&quot;&gt;Things to Consider for Optimization&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#optimizing-select-statements&quot; id=&quot;markdown-toc-optimizing-select-statements&quot;&gt;Optimizing SELECT Statements&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#where-clause-optimization&quot; id=&quot;markdown-toc-where-clause-optimization&quot;&gt;WHERE Clause Optimization&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#group-by-optimization&quot; id=&quot;markdown-toc-group-by-optimization&quot;&gt;GROUP BY Optimization&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#참고&quot; id=&quot;markdown-toc-참고&quot;&gt;참고&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h1 id=&quot;optimization-overview&quot;&gt;Optimization Overview&lt;/h1&gt;

&lt;p&gt;Database performance depends on several factors at the database level, such as tables, queries, and configuration settings. These software constructs result in CPU and I/O operations at the hardware level, which you must minimize and make as efficient as possible.&lt;/p&gt;

&lt;h1 id=&quot;things-to-consider-for-optimization&quot;&gt;Things to Consider for Optimization&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Are the tables structured properly? In particular, do the columns have the right data types, and does each table have the appropriate columns for the type of work? For example, applications that perform frequent updates often have many tables with few columns, while applications that analyze large amounts of data often have few tables with many columns.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Are the right indexes in place to make queries efficient?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Are you using the appropriate storage engine for each table, and taking advantage of the strengths and features of each storage engine you use? In particular, the choice of a transactional storage engine such as InnoDB or a nontransactional one such as MyISAM can be very important for performance and scalability.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Does each table use an appropriate row format? This choice also depends on the storage engine used for the table. In particular, compressed tables use less disk space and so require less disk I/O to read and write the data. Compression is available for all kinds of workloads with InnoDB tables, and for read-only MyISAM tables.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Does the application use an appropriate locking strategy? For example, by allowing shared access when possible so that database operations can run concurrently, and requesting exclusive access when appropriate so that critical operations get top priority. Again, the choice of storage engine is significant. The InnoDB storage engine handles most locking issues without involvement from you, allowing for better concurrency in the database and reducing the amount of experimentation and tuning for your code.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Are all memory areas used for caching sized correctly? That is, large enough to hold frequently accessed data, but not so large that they overload physical memory and cause paging. The main memory areas to configure are the InnoDB buffer pool and the MyISAM key cache.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;optimizing-select-statements&quot;&gt;Optimizing SELECT Statements&lt;/h1&gt;

&lt;h2 id=&quot;where-clause-optimization&quot;&gt;WHERE Clause Optimization&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Use Indexes Where Appropriate&lt;/li&gt;
  &lt;li&gt;Avoid % Wildcard in a Predicate&lt;/li&gt;
  &lt;li&gt;Avoid using a function in the predicate of a query&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;group-by-optimization&quot;&gt;GROUP BY Optimization&lt;/h2&gt;

&lt;p&gt;GROUP BY 절을 만족시키는 가장 일반적인 방법은 전체 테이블을 스캔하여 각 그룹의 모든 행이 연속되는 새 임시 테이블을 만든 다음 이 임시 테이블을 사용하여 그룹을 검색하고 집계 함수를 적용하는 것입니다&lt;/p&gt;

&lt;p&gt;In some cases, MySQL is able to do much better than that and avoid creation of temporary tables by &lt;strong&gt;using index access&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;GROUP BY에 인덱스를 사용하기 위한 가장 중요한 전제 조건은 모든 GROUP BY 열이 동일한 인덱스의 속성을 참조하고 인덱스가 해당 키를 순서대로 저장한다는 것입니다(예: BTREE 인덱스의 경우 해당되지만 해시 인덱스의 경우 해당되지 않음). 임시 테이블의 사용이 인덱스 액세스로 대체될 수 있는지 여부도 쿼리에 사용되는 인덱스의 부분, 이러한 부분에 대해 지정된 조건 및 선택한 집계 함수에 따라 달라집니다.&lt;/p&gt;

&lt;p&gt;There are two ways to execute a GROUP BY query through index access, as detailed in the following sections.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The first method applies the grouping operation together with all range predicates (if any)&lt;/li&gt;
  &lt;li&gt;The second method first performs a range scan, and then groups the resulting tuples.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;참고&quot;&gt;참고&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://dev.mysql.com/doc/refman/8.0/en/select-optimization.html&quot; target=&quot;_blank&quot;&gt;MySQL 공식문서: Optimizing SELECT Statements&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://phoenixnap.com/kb/improve-mysql-performance-tuning-optimization&quot; target=&quot;_blank&quot;&gt;MySQL Performance Tuning and Optimization Tips&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
                <pubDate>Fri, 29 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/mysql-series14</link>
                <guid isPermaLink="true">http://localhost:4000/mysql-series14</guid>
                
                <category>MySQL</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Coding Test Series [Part21]: 파이썬 문법</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#in-python-and-operation-will-not-return-a-boolean-value&quot; id=&quot;markdown-toc-in-python-and-operation-will-not-return-a-boolean-value&quot;&gt;In python, ‘and’ operation will not return a boolean value&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;in-python-and-operation-will-not-return-a-boolean-value&quot;&gt;In python, ‘and’ operation will not return a boolean value&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;If it’s true, it will return the last true value, remember is the value, not True. Otherwise, it will return the first false value.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;'ban' and 'car' -&amp;gt; 'car'
0 and 'car' -&amp;gt; 0
'ban' and False -&amp;gt; False
'ban' or False -&amp;gt; 'ban'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
                <pubDate>Fri, 29 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/python-things</link>
                <guid isPermaLink="true">http://localhost:4000/python-things</guid>
                
                <category>Coding_Test</category>
                
                
                <category>CS</category>
                
            </item>
        
            <item>
                <title>Data Engineering Series [Part24]: 시스템 디자인(4) Database</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#factors&quot; id=&quot;markdown-toc-factors&quot;&gt;Factors&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#caching-solution&quot; id=&quot;markdown-toc-caching-solution&quot;&gt;Caching Solution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#file-storage-solution&quot; id=&quot;markdown-toc-file-storage-solution&quot;&gt;File Storage Solution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#storage-solutions-offering-text-search-capability&quot; id=&quot;markdown-toc-storage-solutions-offering-text-search-capability&quot;&gt;Storage Solutions Offering Text Search Capability&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#time-series-database&quot; id=&quot;markdown-toc-time-series-database&quot;&gt;Time Series Database&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#data-warehousing-storage-solution&quot; id=&quot;markdown-toc-data-warehousing-storage-solution&quot;&gt;Data Warehousing Storage Solution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#rdbms-vs-nosql&quot; id=&quot;markdown-toc-rdbms-vs-nosql&quot;&gt;RDBMS vs NoSQL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;Databases will not impact your functional requirements. Whichever database you use, you can still achieve your functional requirements somehow, but at the cost of huge performance degradation. So when we say requirement, we usually mean non-functional requirements.&lt;/p&gt;

&lt;h1 id=&quot;factors&quot;&gt;Factors&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Structure of the data&lt;/li&gt;
  &lt;li&gt;Query pattern&lt;/li&gt;
  &lt;li&gt;Amount or scale that you need to handle&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These are the factors we need to consider when selecting which database to use. Now let us look at various types of storage solutions and some use cases where they will be suitable.&lt;/p&gt;

&lt;h1 id=&quot;caching-solution&quot;&gt;Caching Solution&lt;/h1&gt;
&lt;p&gt;If you are calling your database very frequently or making a remote call to independent services with high latency, you might want to cache some data locally at your end. Some of the most commonly used caching solutions are Memcached, Hazelcast, and Redis. You could also use some other solutions; this is not an exhaustive list. In the following articles, we will usually use Redis as it is one of the most widely used and stable solutions.&lt;/p&gt;

&lt;h1 id=&quot;file-storage-solution&quot;&gt;File Storage Solution&lt;/h1&gt;

&lt;p&gt;Assume you are working on something like Netflix and you need a data store for images, videos, etc. Now, in this case, a database is not very useful to us as we are storing files rather than information. &lt;strong&gt;Databases are meant to store information that can be queried&lt;/strong&gt;, whereas files you do not need to query. You just deliver them as they are.&lt;/p&gt;

&lt;p&gt;This is when we use something called Blob (Binary Large Object) storage. Amazon S3 is an example of blob storage. Usually, blob storage is used in combination with a Content delivery network or a CDN. A CDN is a network of servers around the world that delivers content in different geographical locations with reduced latency. If the server you are getting content from is closer to your geographic location, the content will take less time (reduced latency) to be delivered from the server to you.&lt;/p&gt;

&lt;h1 id=&quot;storage-solutions-offering-text-search-capability&quot;&gt;Storage Solutions Offering Text Search Capability&lt;/h1&gt;

&lt;p&gt;Let’s again take the Netflix example. Suppose you want to build a search functionality where the user can search by movie, genre, actor, actress, director, etc. Here you use a search engine like Solr or Elasticsearch which can support fuzzy search.&lt;/p&gt;

&lt;p&gt;To understand fuzzy search, let us take an example of an Uber user searching for airprot. If you notice this is a typo, what the user means to search is airport. But if, because of this typo, we don’t provide any search results, it will be a very poor user experience. So we search for terms similar to airport in the database. This is known as fuzzy search.&lt;/p&gt;

&lt;p&gt;Now a key point here is that these search engines are not databases. Databases provide a guarantee that once stored, our data will not be lost unless we delete it; search engines offer no such guarantee. This is why we should never use search engines like Elasticsearch as our primary data source. We can load the data to them from our primary database to reduce search latency and provide fuzzy and relevance-based text search.&lt;/p&gt;

&lt;h1 id=&quot;time-series-database&quot;&gt;Time Series Database&lt;/h1&gt;

&lt;p&gt;Suppose we are trying to build a metric tracking system. We will need something called a time-series database. Time-series databases are, in a way, an extension of relational databases, but unlike a standard relational DB, time-series databases will never be randomly updated. It will be &lt;strong&gt;updated sequentially in an append-only format&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Also, it will have more bulk reads for a certain time range as opposed to random reads. For example, how many people watched a video in the last 1 week, 10 days, 1 month, 1 year, and so on. Some examples of time series databases are OpenTSDB and InfluxDB.&lt;/p&gt;

&lt;h1 id=&quot;data-warehousing-storage-solution&quot;&gt;Data Warehousing Storage Solution&lt;/h1&gt;

&lt;p&gt;Sometimes we need a large database to dump all of the data available to us, to perform analytics. Eg. a company like Uber will store all of their data so they can perform analytics to identify where Uber is not used very much, where are the hotspots, what are the peak hours, etc. These systems are not used for regular transactions but offline reporting. Hadoop is a very commonly used Data warehouse.&lt;/p&gt;

&lt;h1 id=&quot;rdbms-vs-nosql&quot;&gt;RDBMS vs NoSQL&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_14.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If you need ACID properties, then you need to use a relational DBMS. Some examples are MySQL, Oracle, and Postgres. But what if you don’t need ACID? Well, you can still use RDBMS, or you can use a Non-relational database.&lt;/p&gt;

&lt;p&gt;Let’s consider an example. Suppose you are trying to build a catalog for something like Amazon, where you want to store information about different products that have various attributes. These attributes will normally not be the same for different products. In such a case, our data cannot be represented as a table. This means we need to use a NoSQL database.&lt;/p&gt;

&lt;p&gt;Also, we don’t just need to store this data but also &lt;strong&gt;query on this data&lt;/strong&gt;. Here comes the factor of query pattern. Which type of database we use here will be decided based on what type of data we store and what types of queries will be run on it. If we have vast data - not just volume but also a vast variety of attributes - and we need to run a vast variety of queries, we need to use something called a Document DB. Couchbase and MongoDB are some commonly used document databases. (Elasticsearch is special cases of document DB)&lt;/p&gt;

&lt;p&gt;But what if &lt;strong&gt;you don’t have a vast variety of attributes&lt;/strong&gt; i.e. very &lt;strong&gt;limited variety of queries&lt;/strong&gt;, but the &lt;strong&gt;size of the database increases very rapidly&lt;/strong&gt;? For example, data collected by Uber for their drivers’ location pings. Now the number of Uber drivers will keep increasing day by day, and therefore so will the data collected every day. This results in an ever-increasing amount of data. In such cases, we use &lt;strong&gt;Columnar DBs like Cassandra or HBase&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Using Cassandra is lighter to deploy, whereas HBase is built on top of Hadoop; we would need to first set up Hadoop and then setup HBase on top of it. This makes the setup of HBase a little lengthy, but performance-wise both are pretty much the same.&lt;/p&gt;

&lt;p&gt;Let us assume we have stored Uber’s ride-related data in a Cassandra with driver id as a partition key. Now when we want to fetch a ride for a particular driver on a particular date, Cassandra can find it easily enough. But if we want to find a customer’s ride on a particular date, Cassandra will have to fan out this query to all the partitions since customer id is not a partition key. So what is the point of using Cassandra if it is not going to scale well!&lt;/p&gt;

&lt;p&gt;Well, there is a simple enough fix. We can replicate the same data to another table or column family with a different partition key. Now when we receive the query for customer id and date, we can simply direct it to the table where the partition key is customer id. This is what we mean by a limited variety of queries but a huge scale. Cassandra (and HBase) can scale massively as long as the queries are of similar types.&lt;/p&gt;

&lt;p&gt;If the queries are more diverse, then we will have to replicate again and again for each partition key, which we can, but only to a certain limit. If we cannot control the types of queries, then something like MongoDB might be the way to go. But if we just need a huge scale for a few types of queries, the Cassandra is the perfect solution.&lt;/p&gt;

&lt;p&gt;Now let’s shake things up a bit!&lt;/p&gt;

&lt;p&gt;Let’s consider the Amazon example again. If for a product we have only one item in stock but multiple users are trying to buy it, it should only be sold to one user, which means we need ACID here. So we should choose a Relational DB like MySQL.&lt;/p&gt;

&lt;p&gt;But the orders-related data for Amazon will be ever-increasing and will have a variety of attributes. That means we should use a Columnar NoSQL database like Cassandra. So which one to go for? We decide to go with a combination of both. We can store the data of orders that are not yet delivered in a MySQL database, and once the order is completed, we can move it to Cassandra to be permanently stored.&lt;/p&gt;

&lt;p&gt;But again, our requirements might be a little more complex. Suppose you want to build a reporting system for how many people bought a particular item. Now, on Amazon, products are sold by various users of different brands and different variations. So the report can not target a single product, rather, it should target a subset of products, which can be in either Cassandra or MySQL.&lt;/p&gt;

&lt;p&gt;Such a requirement is an example of a situation where our best choice would be a document DB like Mongo DB. So we decide to keep a subset of this orders data in Mongo DB that tells us which users bought how much quantity of a certain product, at what time, on what date, etc. So suppose you want to check how many people bought sugar in the last month. You can get order ids from Mongo DB and use this order id to pick up the rest of the data from Cassandra or MySQL.&lt;/p&gt;

&lt;p&gt;That should be it for Storage Solutions in System Design!&lt;/p&gt;
</description>
                <pubDate>Tue, 26 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/data-engineering-series24</link>
                <guid isPermaLink="true">http://localhost:4000/data-engineering-series24</guid>
                
                <category>Data_Engineering</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Data Engineering Series [Part23]: 시스템 디자인(4) Caching</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#what-is-a-cache&quot; id=&quot;markdown-toc-what-is-a-cache&quot;&gt;What is a Cache?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#when-to-cache&quot; id=&quot;markdown-toc-when-to-cache&quot;&gt;When to Cache?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#how-does-caching-work&quot; id=&quot;markdown-toc-how-does-caching-work&quot;&gt;How Does Caching Work?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#when-not-to-cache&quot; id=&quot;markdown-toc-when-not-to-cache&quot;&gt;When Not to Cache?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#cache-eviction-strategies&quot; id=&quot;markdown-toc-cache-eviction-strategies&quot;&gt;Cache Eviction Strategies&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#time-based&quot; id=&quot;markdown-toc-time-based&quot;&gt;Time Based&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#size-based&quot; id=&quot;markdown-toc-size-based&quot;&gt;Size Based&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#metrics&quot; id=&quot;markdown-toc-metrics&quot;&gt;Metrics&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#caching-products&quot; id=&quot;markdown-toc-caching-products&quot;&gt;Caching Products&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;what-is-a-cache&quot;&gt;What is a Cache?&lt;/h1&gt;
&lt;p&gt;A cache is high-speed data access and storage layer that helps us fetch data that we had previously retrieved or computed.&lt;/p&gt;

&lt;p&gt;If we need frequent or repeated access to certain information that we have already queried from a service or a database, then instead of repeatedly querying the service, it’s better to cache that information for subsequent use, for it to be readily available.&lt;/p&gt;

&lt;p&gt;For Example, for Twitter users, we can cache all the information that is needed to load the homepage of a user (like followers, tweets, etc.). Caching will help avoid repeatedly querying the same service, caused by the refreshing of the browser by the user or other similar use cases. In this case, caching helps to reduce latency and improve resource utilization of servers.&lt;/p&gt;

&lt;h1 id=&quot;when-to-cache&quot;&gt;When to Cache?&lt;/h1&gt;
&lt;p&gt;A cache is primarily used in the following scenarios:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;When the data involves a lot of computation, then to reduce latency and CPU utilization, it’s good to cache the pre-calculated information for fast retrieval later on.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;To reduce frequent database or network (API) calls, it’s beneficial to cache the previously fetched data for fast retrieval. This helps reduce latency as well as bandwidth requirements.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;how-does-caching-work&quot;&gt;How Does Caching Work?&lt;/h1&gt;

&lt;p&gt;A cache is primarily used to store the most recently or frequently used data, in the hope that it will soon be fetched again. Caches are typically faster than databases and services when it comes to re-accessing this stored information. What makes them so fast is the fact that caches store data in SSDs and mostly RAMs which reduces the lookup time. However, this does not mean that we should cache everything.&lt;/p&gt;

&lt;h1 id=&quot;when-not-to-cache&quot;&gt;When Not to Cache?&lt;/h1&gt;
&lt;p&gt;There are some scenarios where the negative aspects of caching outweigh its benefits:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;High Consistency requirements: When we fetch the previously stored data from the cache, there is a possibility of stale data being displayed to the user. For example, for a social media app, then some stale data is probably fine. However, for a stock price display app, then the cache must be in sync with the primary data source.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Write heavy / Read Once: When write operations (updates to data) are more frequent than read operations (data retrieval). For example, caching the data of an analytics system would only increase the hardware maintenance cost.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Low repetition: When the action of retrieval of the same information is not frequently repeated by the user. For example, the cost calculated by the trip cost estimation module of a cab booking app between the exact two points need not be cached.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;cache-eviction-strategies&quot;&gt;Cache Eviction Strategies&lt;/h1&gt;
&lt;p&gt;We need to regularly expel data from the cache to limit the size of the cache and to maintain its speed while ensuring that the entries are up to date.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_12.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;time-based&quot;&gt;Time Based&lt;/h2&gt;

&lt;p&gt;We keep an entry in the cache for some amount of time. In this strategy, we set a TTL (Time To Live). We will evict the entry from the cache after a certain pre-determined time has elapsed. The time which an entry stays in the cache before being evicted is called TTL.&lt;/p&gt;

&lt;h2 id=&quot;size-based&quot;&gt;Size Based&lt;/h2&gt;

&lt;p&gt;We keep at most some number of entries in the cache.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;FIFO (First In First Out): We harness the FIFO property of the queue data structure to evict old entries.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;LFU (Least Frequently Used): When we must evict an entry, we will evict the least frequently used entry.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;LRU (Least Recently Used): When we must evict an entry, we will evict the least recently used entry.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;LFRU (Least Frequently and Recently Used): We evict the least valuable entry, the one that’s neither used frequently nor recently. This strategy gives the best results.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;metrics&quot;&gt;Metrics&lt;/h1&gt;
&lt;p&gt;We can use the following metrics to evaluate the performance of the cache:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Size: Increasing the size of the cache usually increases the response time and therefore reduces its performance.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Latency: The introduction of cache into the system must reduce latency from what it was earlier.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cache Hit Rate: It is the ratio of results found in the cache to the requests made to the cache. If the cache hit rate is low i.e., requests to cache are not returning the desired data, then it essentially slows down the system.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;caching-products&quot;&gt;Caching Products&lt;/h1&gt;

&lt;p&gt;It’s usually not recommended to write your own cache implementation, because there are a lot of really good cache implementations out there that you can use. Some of the most popular caching products that are available in the market are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ehcache&lt;/li&gt;
  &lt;li&gt;Hazelcast&lt;/li&gt;
  &lt;li&gt;Memcached&lt;/li&gt;
  &lt;li&gt;Redis&lt;/li&gt;
&lt;/ul&gt;
</description>
                <pubDate>Tue, 26 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/data-engineering-series23</link>
                <guid isPermaLink="true">http://localhost:4000/data-engineering-series23</guid>
                
                <category>Data_Engineering</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Data Engineering Series [Part22]: 시스템 디자인(3) Consistent Hashing</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#why-hashing&quot; id=&quot;markdown-toc-why-hashing&quot;&gt;Why hashing?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#consistent-hashing&quot; id=&quot;markdown-toc-consistent-hashing&quot;&gt;Consistent Hashing&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#where-is-it-used&quot; id=&quot;markdown-toc-where-is-it-used&quot;&gt;Where is it Used&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;why-hashing&quot;&gt;Why hashing?&lt;/h1&gt;

&lt;p&gt;Hash is basically a function that takes a value and converts it into another value of a specific format. Hash functions that are commonly used are MD5, SHA1, SHA256, etc.&lt;/p&gt;

&lt;p&gt;Suppose you build a distributed cache, where the data is distributed over various nodes, sometimes spanning multiple data centers. When we want to store the data for a user, we need to decide which node will cache this data. And when we want to retrieve this cached value, we must query the same node. So let us use a simple hash function for this again.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hash(user) = Sum(ASCII value of all characters in name) % 5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Where 5 is the number of nodes. This way, the hashes generated for users will be as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_8.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Since hash(Alice) is 0, Alice’s data will be stored in node 0. Similarly, Bob’s data will be stored in node 1 and Eve’s in 4. Now when you need to look up the information for Alice, you will use the same hash function to determine which node to query. Since hash(Alice) equals 0, you will query node 0 and fetch the information.&lt;/p&gt;

&lt;p&gt;But there is a problem with this solution. This model is not scalable. If the traffic increases and you want to add a new node, the formula to calculate the hash will get updated to&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hash(user) = Sum(ASCII value of all characters in name) % 6
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And similarly hash(Alice) will get updated to 2. So now you will search for Alice’s information in node 2, but the information is actually stored in node 0 so you won’t find it.&lt;/p&gt;

&lt;p&gt;To fix this, you will need to rehash all the data every time a node is added or removed, and once rehashed, you need to move the data to their respective new nodes, which could be across different data centers. This is not a very good solution as it uses up a lot of CPU resources and bandwidth.&lt;/p&gt;

&lt;p&gt;This is where Consistent Hashing comes in.&lt;/p&gt;

&lt;h1 id=&quot;consistent-hashing&quot;&gt;Consistent Hashing&lt;/h1&gt;

&lt;p&gt;Consistent Hashing tries to optimize the system in such a way that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;You don’t need to move around all the data while adding or removing nodes.&lt;/li&gt;
  &lt;li&gt;There will be minimal movement of data as if a node is removed, the data from that node will be supported by another node. Similarly, when a node is added, some data will be mapped to it as you don’t want it to sit idle.&lt;/li&gt;
  &lt;li&gt;You can have a nearly even distribution of data across all machines.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The idea is &lt;strong&gt;removing the number of nodes in the system out of the equation&lt;/strong&gt; while calculating the hash. Now hashes for data and nodes will all be independently calculated and adding or removing nodes won’t change these hashes.&lt;/p&gt;

&lt;p&gt;Now instead of assigning the data to these nodes in a sequential manner, we will plot these nodes, or their hashes, on the number line, and each node will be responsible for the range between its position and the position of the first node to its right.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_9.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;When the data comes in for storage, we will calculate its hash to determine its place on the number line. Based on which node’s range it falls in, we will map the data to that node.&lt;/p&gt;

&lt;p&gt;If you want to remove a node from this system, the range of the previous machine on the number line will be extended, and all the data from the removed node will be mapped to the previous node in the number line. This resolves the issue of data transfer as only the data from one machine will need to be mapped to another machine.&lt;/p&gt;

&lt;p&gt;But there is still a problem with this system. &lt;strong&gt;After removing a node, the ranges of certain machines might not be balanced.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;An ideal solution to this would be &lt;strong&gt;assigning data between various nodes.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The idea is to assign the same machine to multiple hashes and map each of these hashes on the number line.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_10.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This can be achieved by either using multiple hash functions or by assigning multiple identifiers to the same node, and then calculating the hashes for all of the instanced. Then, We can map them on the number line, or what we can now refer to as a consistent hashing ring, essentially representing the same node on the ring multiple times.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_11.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now the data handled by a removed node will be distributed across the ring. So when a node needs to be removed, all its identifiers will be removed and the data will be mapped to the nodes falling to the right of each identifier, as shown in the following diagram, making the distribution much more even.&lt;/p&gt;

&lt;p&gt;(노드가 삭제되도, 그 노드에 저장되어 있던 데이터가 여러 해시 함수에 의해 분리된 인스턴스에 흩어져서 저장되어 있었으므로, 다른 노드로 이동할 때도 각 인스턴스의 오른쪽 인스턴스로 저장되므로 여러 노드에 분산 저장되게 된다. -&amp;gt; 데이터가 훨씬 even해진다.)&lt;/p&gt;

&lt;p&gt;The reason why it gets even is because each identifier of machine is hashed separately, with the hash function, it is very likely that they would be arranged in a random fashion like Blue_4 - Red_1 - Blue_2 - Green_3 - Red_4 - Orange_1, which makes sure that when one machine is removed, it’s data us spread across multiple other machines.&lt;/p&gt;

&lt;p&gt;Similarly, when a new node is added, its identifiers will also be mapped across the ring, picking up data from various nodes, maintaining even distribution across the ring.&lt;/p&gt;

&lt;h1 id=&quot;where-is-it-used&quot;&gt;Where is it Used&lt;/h1&gt;

&lt;p&gt;Now we just saw how we could use consistent hashing while building a caching system. There are a lot of systems out there that use consistent hashing for improving their performance. For example, Cassandra, a distributed NoSQL Columnar DB that deals with huge traffic uses consistent hashing to distribute its data. Amazon’s Dynamo DB is another such example. It is a managed distributed DB which uses consistent hashing for distributing its data. Similarly, Couchbase is another NoSQL DB (a document DB) which uses consistent hashing to distribute its data across various instances.&lt;/p&gt;
</description>
                <pubDate>Tue, 26 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/data-engineering-series22</link>
                <guid isPermaLink="true">http://localhost:4000/data-engineering-series22</guid>
                
                <category>Data_Engineering</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Data Engineering Series [Part21]: 시스템 디자인(2) Inter-Service Communication</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#inter-service-communication&quot; id=&quot;markdown-toc-inter-service-communication&quot;&gt;Inter-Service Communication&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#modes-of-communication&quot; id=&quot;markdown-toc-modes-of-communication&quot;&gt;Modes of communication&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#synchronous-approach&quot; id=&quot;markdown-toc-synchronous-approach&quot;&gt;Synchronous Approach&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#asynchronous-approach&quot; id=&quot;markdown-toc-asynchronous-approach&quot;&gt;Asynchronous Approach&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#best-of-both-worlds&quot; id=&quot;markdown-toc-best-of-both-worlds&quot;&gt;Best of Both Worlds&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#message-queues&quot; id=&quot;markdown-toc-message-queues&quot;&gt;Message Queues&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#protocols-for-communication&quot; id=&quot;markdown-toc-protocols-for-communication&quot;&gt;Protocols for communication&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#how-clients-and-servers-interact&quot; id=&quot;markdown-toc-how-clients-and-servers-interact&quot;&gt;How clients and servers interact&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#http&quot; id=&quot;markdown-toc-http&quot;&gt;HTTP&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#websocket&quot; id=&quot;markdown-toc-websocket&quot;&gt;WebSocket&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h1 id=&quot;inter-service-communication&quot;&gt;Inter-Service Communication&lt;/h1&gt;

&lt;p&gt;In this article, we will be looking at how services interact with each other. Why is this important? Well, when you have a huge system with a lot of microservices interacting with each other, their communication needs to be efficient to provide the best user experience and also to avoid any cascading effects across the system.&lt;/p&gt;

&lt;h1 id=&quot;modes-of-communication&quot;&gt;Modes of communication&lt;/h1&gt;
&lt;p&gt;There are primarily two modes of communication between services:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Synchronous&lt;/strong&gt;: When a service &lt;strong&gt;waits&lt;/strong&gt; for a downstream system to respond before responding back to the client with a success or failure response.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Asynchronous&lt;/strong&gt;: This is a more of a fire and forget approach. A service will fire a call to the downstream system and won’t track it further.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;synchronous-approach&quot;&gt;Synchronous Approach&lt;/h1&gt;
&lt;p&gt;Let’s say you are building Amazon. You have a user U1 trying to place an order. U1 will reach out to the Order Service. Order Service will now talk to the Inventory Service to find out if a sufficient quantity of the product is available. If that is the case, Inventory Service will send a success response. Otherwise, it will respond with an error, and Order Service will respond to the user saying the order could not be placed.&lt;/p&gt;

&lt;p&gt;Now if the inventory response was a success, the Order Service will talk to the Payment Service to process the payment. Once the payment is successful, the Order Service will now talk to the Warehouse Service asking it to start packing and prepare for shipping the product to the user. Once Warehouse Service responds with a success, the Order Service will talk to a Notification Service to send an email to the user saying their order has been placed, with so and so payment details and sharing an ETA for the delivery of the product.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now, this is a happy scenario. What happens when one of the calls fails? Well, it depends on which call fails. If the call to Notification Service fails, does it make sense to cancel the order? No. We shouldn’t cancel an order just because the Notification Service failed. However, what if payment fails? Now we definitely need to cancel the order. But now we need to update the Inventory again to undo the change to the product quantity. What if the call to Inventory Service fails?&lt;/p&gt;

&lt;p&gt;So as you can see, there are some loopholes in a purely synchronous approach.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It has very high latency as the user does not get notified until all the calls have come back with a success or failure response.&lt;/li&gt;
  &lt;li&gt;The system is tightly coupled, and any failure will have cascading effects across the board.&lt;/li&gt;
  &lt;li&gt;The code becomes very complex since we need to handle all the cascading error scenarios.&lt;/li&gt;
  &lt;li&gt;Due to complexity, it requires extremely high maintenance.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;asynchronous-approach&quot;&gt;Asynchronous Approach&lt;/h1&gt;
&lt;p&gt;Let us see what happens in a purely asynchronous approach.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;U1 sends a call to the Order Service which makes asynchronous calls to all the downstream systems. In such a case, even if Inventory Service responds with an error code, or even if the payment fails, the order would get placed. Which is an even bigger mess! So how do we go about this?&lt;/p&gt;

&lt;p&gt;Well, as we can see, some parts of this process must be mandatory, and some can be done on a best-effort basis. If the Inventory Service or Payment Service responds with an error, we cannot place the order. But if the notification does not go through or the Warehouse Service is temporarily down, we don’t need to cancel our order. So we can follow a hybrid approach here; &lt;strong&gt;use a synchronous approach for the mandatory steps and an asynchronous approach for the rest.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;best-of-both-worlds&quot;&gt;Best of Both Worlds&lt;/h2&gt;
&lt;p&gt;The Hybrid approach suggests that the mandatory tasks need to be performed in a synchronous manner and everything else can be done asynchronously.&lt;/p&gt;

&lt;p&gt;So Order Service will send out a synchronous call to Inventory Service, and wait for a response. In case of success, it will call the Payment Service. If the Payment Service gives a successful response, Order Service will make parallel asynchronous calls to the Warehouse Service and Notification Service and, at the same time, respond to the user saying the order has been placed. If the Payment Service call had failed, Order Service would send an asynchronous call to the Inventory Service reverting the quantity change.&lt;/p&gt;

&lt;p&gt;So this looks like a much better solution. There are still some misses here though. What if the asynchronous call to Warehouse Service failed? It would lose the details for that order. This is where we would use &lt;strong&gt;Message Queues&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;message-queues&quot;&gt;Message Queues&lt;/h2&gt;
&lt;p&gt;Message Queues(Kafka, RabbitMQ, ActiveMQ 등) are highly fault-tolerant and persist messages for some time. How a message Queue works is, it has some Publishers adding messages to it, and some Subscribers listening to it and picking up the events meant for them at their own pace. Since these queues store messages for some time, if a subscriber is temporarily down, the messages will remain in the queue and will be picked up when the subscriber is running again.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So now, when Order Service wants to make asynchronous calls to Warehouse and Notification services, it will instead put an event in the Message Queue. Warehouse Service and Notification Service, which will be listening to the queue, will pick up the events meant for them. If one of the systems is down, the messages will remain in the queue until the service is back up and ready to receive messages again. This way, none of the data gets lost.&lt;/p&gt;

&lt;h1 id=&quot;protocols-for-communication&quot;&gt;Protocols for communication&lt;/h1&gt;

&lt;p&gt;In this article, we will look at the protocols we can use to interact with clients.&lt;/p&gt;

&lt;h2 id=&quot;how-clients-and-servers-interact&quot;&gt;How clients and servers interact&lt;/h2&gt;

&lt;p&gt;In a real-world scenario, rather than talking to a specific server, the client’s request will instead be sent to a data center, where it could be picked up by any of the servers. However, irrespective of which server receives the request, the response will be the same. Based on this flow, we can draw the following conclusions about this architecture:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It is client-driven. Only on the user’s button click will the client send the requests to the server, and the server will only respond to these requests.&lt;/li&gt;
  &lt;li&gt;It is a simple request-response model. For every request from the client, the server will respond with some information or a simple confirmation.&lt;/li&gt;
  &lt;li&gt;There are occasional requests from clients, only one request every few seconds based on the user’s actions i.e. from the client-side it is a low throughput system.&lt;/li&gt;
  &lt;li&gt;It is a stateless system i.e. irrespective of which server is responding, the response remains the same.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;http&quot;&gt;HTTP&lt;/h2&gt;

&lt;p&gt;These requirements make this a perfect use case for HTTP(s) protocol. Although these days, most architectures on HTTP have moved to HTTPS, which is a more secure version of HTTP as it prevents man-in-the-middle attacks.&lt;/p&gt;

&lt;p&gt;Now, when we are using HTTP, REST is usually the best API standard to follow as it is very widely used and very user friendly.&lt;/p&gt;

&lt;p&gt;Let us look at an example for a REST request and response:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Request:
Method: GET
URL: https://www.twitter.com/user/{id}

Response:
Status: 200 OK
Headers: &amp;lt;...&amp;gt;
Body: {
    “userId”: 1,
    “Email”: “someone@example.com”
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The client makes a request to twitter.com over HTTPS to get information about a user with an id. In response, the server sends a success status code along with the user’s user id and email. As you can see, REST API standard is pretty much self-documenting, which adds to its user friendliness.&lt;/p&gt;

&lt;p&gt;Now let us look at an example of a chat application.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We know that HTTP is a client-driven protocol, so the server cannot initiate any contact with the client. It can only respond to the client upon receiving a request. So when U1 sends a message to U2 via chat server, U2 doesn’t receive the message until it asks the server to share any pending messages. This leads to a delay when receiving messages.&lt;/p&gt;

&lt;p&gt;A solution to this would be that U2 sends frequent requests to the chat server in the hopes of receiving a message. But this puts a huge load on the chat server as it will receive a huge number of requests from all its clients.&lt;/p&gt;

&lt;p&gt;The best approach would be &lt;strong&gt;if the server could send a notification to the user every time there is a message&lt;/strong&gt;. For this, we use a protocol called &lt;strong&gt;WebSocket&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;(서버가 U2에게 보낼 메시지를 가지고 있음에도 불구하고, 능동적으로 U2에게 보내지 않는다. U2로부터 request를 받을때까지 기다린다.)&lt;br /&gt;
(U2는 언제 자신이 받아야할 메시지가 서버에 도착했는지 모르므로, 계속 서버에 request를 보내야 한다.)&lt;br /&gt;
(WebSocket을 사용하면 서버는 U2와 connection되어 있으면 request를 받지 않아도 알아서 U2에 메시지를 보낸다)&lt;br /&gt;
(connection되어 있지 않으면, 가만히 있다가, connection되고 U2가 request보내면 메시지 보낸다)&lt;br /&gt;
(WebSocket에도 단점은 있다. cost of maintaining a persistent connection with millions of users.)&lt;/p&gt;

&lt;h2 id=&quot;websocket&quot;&gt;WebSocket&lt;/h2&gt;
&lt;p&gt;A WebSocket connection is a persistent connection. It is also a bidirectional protocol, where communication can be initiated by the client or the server as long as there is an open connection. It is &lt;strong&gt;optimized for high-frequency communication&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Let’s look at how our chat application would work in the case of WebSocket protocol.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;First, U1 and U2 will establish HTTP connections with the chat server, which are then upgraded to a WebSocket connection. When U1 sends a message for U2 via the chat server, it will store the message along with its status, RECEIVED, let’s say.&lt;/p&gt;

&lt;p&gt;The chat server, if it has an open connection with U2, will then send the message to U2 and update the status to SENT. If U2 was not online and there was no open connection between U2 and the server, the messages will be saved until U2 comes online and requests the server to send all pending messages. The server will send all messages with the status RECEIVED and update the status to SENT.&lt;/p&gt;

&lt;p&gt;As you can see, with this approach we have:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Reduced the latency, since the server can simply send the messages over an open connection&lt;/li&gt;
  &lt;li&gt;Saved on CPU and bandwidth, as the client doesn’t need to unnecessarily send requests to the server and the server is not under unnecessary load&lt;/li&gt;
  &lt;li&gt;Provided better user experience&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Even with the benefits, there is a high cost to using WebSockets; that is the cost of maintaining a persistent connection with millions of users.&lt;/p&gt;

&lt;p&gt;So how do we decide whether to use HTTP or WebSocket? Do we always go for Websocket then? Well, not really, as WebSocket is much more expensive than HTTP. We can safely say, if the communication between client and server is at a &lt;strong&gt;lower throughput on the client-side&lt;/strong&gt;, HTTP is the way to go. &lt;strong&gt;If the communication is always client-driven&lt;/strong&gt;, WebSocket is not needed. Also, if you are on a &lt;strong&gt;tight budget&lt;/strong&gt;, HTTP may be the better choice.&lt;/p&gt;

&lt;p&gt;On the other hand, if the communication from the &lt;strong&gt;client is at a higher throughput&lt;/strong&gt;, WebSocket may be a better option. If the &lt;strong&gt;communication can be driven by both client and server&lt;/strong&gt;, WebSocket is the way to go. Although here comes the tradeoff between cost and performance. We must decide if the optimization is really worth the huge cost of maintaining persistent connections with so many users.&lt;/p&gt;
</description>
                <pubDate>Tue, 26 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/data-engineering-series21</link>
                <guid isPermaLink="true">http://localhost:4000/data-engineering-series21</guid>
                
                <category>Data_Engineering</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Data Engineering Series [Part20]: 시스템 디자인(1) Intro + Architecture</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#intro&quot; id=&quot;markdown-toc-intro&quot;&gt;Intro&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#what-will-be-covered&quot; id=&quot;markdown-toc-what-will-be-covered&quot;&gt;What will be covered?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#high-level-system-design&quot; id=&quot;markdown-toc-high-level-system-design&quot;&gt;High Level System Design&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#low-level-system-design-code-quality&quot; id=&quot;markdown-toc-low-level-system-design-code-quality&quot;&gt;Low Level System Design (Code Quality)&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#application-architecture&quot; id=&quot;markdown-toc-application-architecture&quot;&gt;Application Architecture&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#monolithic-architecture&quot; id=&quot;markdown-toc-monolithic-architecture&quot;&gt;Monolithic Architecture&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#microservice-architecture&quot; id=&quot;markdown-toc-microservice-architecture&quot;&gt;Microservice Architecture&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot; id=&quot;markdown-toc-conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h1 id=&quot;intro&quot;&gt;Intro&lt;/h1&gt;

&lt;h2 id=&quot;what-will-be-covered&quot;&gt;What will be covered?&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Introduction to System Design: Start with an introduction of the course, explanations on high level and low level design, interviewer’s expectations, and how to approach these kind in an interview.&lt;/li&gt;
  &lt;li&gt;System Design Basics: Build a strong foundation of System Design fundamentals that are useful in understanding the dynamics of highly scalable systems.&lt;/li&gt;
  &lt;li&gt;System Design Case Studies: Cover the 11 most frequently asked interview questions with a detailed walkthrough.&lt;/li&gt;
  &lt;li&gt;Problem Solving: Apply your understanding of the preceding chapters with the help of some practice problems and quizzes.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;high-level-system-design&quot;&gt;High Level System Design&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Overall architecture&lt;/strong&gt;: How the system can be built such that it takes care of scalability, latency, and other performance requirements&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Components and services&lt;/strong&gt;: Any system is a collection of various services and other components interacting with each other. In this part of high level design, we need to decide how the system will be broken down, what will the microservices be, and their scope.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Interaction between the systems&lt;/strong&gt;: How will the systems interact with each other? What protocols will you use? Will it be synchronous or asynchronous? You need to make these decisions based on the requirements.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Databases&lt;/strong&gt;: What databases will you need? What kind of data do you need to store? SQL or NoSQL, what will be the database schema? Depending on how much detail the interviewer wants you to go into, you may have to make these decisions as well.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;low-level-system-design-code-quality&quot;&gt;Low Level System Design (Code Quality)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: If you’re trying to build a web server, define your APIs clearly. For example, if you decide to make REST APIs, ensure they follow REST standards. Similarly, if you are building a library, define the APIs in a very clean manner as publicly accessible functions such that the client can easily integrate them&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Test Code&lt;/strong&gt;: This means we should have a working code with some basic test cases that are passing for the logic we have written.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Modular&lt;/strong&gt;: how easy it is to add new features without interfering with existing code.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;application-architecture&quot;&gt;Application Architecture&lt;/h1&gt;

&lt;h2 id=&quot;monolithic-architecture&quot;&gt;Monolithic Architecture&lt;/h2&gt;

&lt;p&gt;Back when the internet was just starting to gain popularity, websites used to serve mostly static content. There wasn’t a lot of user interaction like we see now. The applications were much less complex, and so was their architecture. A single application used to take care of the entire user journey, everything from UI rendering to backend business logic to fetching the data from DBs or File Systems. This was the world of Web 1.0.&lt;/p&gt;

&lt;p&gt;Then came Web 2.0 with social networks, e-commerce, and online gaming and things became a lot more interactive. By this time everything was still maintained in a single huge codebase. If you consider an e-commerce system, back then everything from UI to business logic for payments, carts, orders, etc. was maintained in a single codebase. This is known as Monolithic Architecture.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The problem with this approach was that the code was very complex, difficult to maintain, and hard to iterate and improve. On top of that, multiple people were working on the same codebase; it was a recipe for disaster.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Disadvantage of Monolithic Architecture&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;One of the most common problems with monoliths is that you are &lt;strong&gt;bound to a single technology stack&lt;/strong&gt;. Suppose you have a monolith built on Java with Spring framework. Now you need to add some Machine Learning logic, and you want to use Python for it. That is nearly impossible in monolithic architecture. You either need to figure out a way to do this with Java, or you need a standalone application that handles your machine learning logic, which defeats the purpose of a monolithic app.&lt;/li&gt;
  &lt;li&gt;Another problem would be that it is very &lt;strong&gt;easy to break&lt;/strong&gt; things in such an architecture. That is because, when you have such a huge codebase, it is nearly impossible for everyone to know everything about how the entire system works. If you change some logic in the shared code, you might end up breaking someone else’s feature. Sure you can have test cases, but even those are not enough sometimes.&lt;/li&gt;
  &lt;li&gt;Another major issue is scalability. It is very &lt;strong&gt;tricky to scale a monolithic application&lt;/strong&gt;. Let us look at the example of an e-commerce application. In case of a Black Friday sale, you might need to scale your payments and cart modules, but Warehouse and Notification modules can continue to work at the same pace. This cannot be done in a monolithic app. Since it is the same codebase, you will need to deploy the entire system again and again. This means the capacity meant for the Warehouse module might be sitting idle or that the Payment and Cart modules may choke the rest of the system.&lt;/li&gt;
  &lt;li&gt;Deployments are also a very tedious process here. Since the code is huge, it takes &lt;strong&gt;much longer to build&lt;/strong&gt;, package, and deploy the code. That said, if you update the code for Warehousing, even the Payments module must be redeployed since everything is packaged together.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;microservice-architecture&quot;&gt;Microservice Architecture&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The idea is to break down the application into logical components such that these components become services of their own. Normally this is also how the teams would be structured, so each team would work on the services that handle their features. These services will now be communicating with each other via a set of API calls like REST APIs or Remote Procedure Calls.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Benefits of Microservice Architecture&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We are not bound to a single technology stack anymore. Different services can use different languages or databases as needed.&lt;/li&gt;
  &lt;li&gt;Each system does one thing and does it well, without worrying about breaking another set of features.&lt;/li&gt;
  &lt;li&gt;Engineers will be working on and maintaining a smaller codebase.&lt;/li&gt;
  &lt;li&gt;Iterating, deploying, and testing becomes a lot easier.&lt;/li&gt;
  &lt;li&gt;Unlike in monolith, we can now independently scale up Cart and Payments Services, and the rest of the services can continue working as they are. This ensures optimized use of resources and makes auto-scaling a lot easier.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantage of Microservice Architecture&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Latency
    &lt;ul&gt;
      &lt;li&gt;One of the key reasons is latency. Function calls are faster than API calls, so it makes sense that monoliths will have lower latency. Usually, this latency is not high enough to be noticed by the user, but if you are working on something that needs a response in a few microseconds then you should definitely think about using monolithic architecture.&lt;/li&gt;
      &lt;li&gt;With network calls comes the possibility of network failures and slightly increases the complexity of error handling and retries.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Backward Compatibility
    &lt;ul&gt;
      &lt;li&gt;If a service needs a new mandatory parameter and the other services have not made the change accordingly, certain flows will break.&lt;/li&gt;
      &lt;li&gt;In monolith it will be caught in the development phase since the compiler will throw an error. To solve this we need some good automated test cases.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Logging
    &lt;ul&gt;
      &lt;li&gt;If you need to trace logs for a user in monoliths, it is easy to do so as they are all in the same place. But in microservices, for each request from the user there will be multiple service calls.&lt;/li&gt;
      &lt;li&gt;In the below example, consider a single request from the user to the order service. The order service is talking to Inventory, Payment, Warehouse, and Notification Services, and thus there will be logs in each of these services. So tracing exactly what happened becomes very difficult as we need to check logs in each system.&lt;/li&gt;
      &lt;li&gt;A better approach would be to store all the logs in a central place where they can be queried. This is a cost since you either need to build a Log Aggregation System or buy a third-party system’s license.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;In conclusion, if you are a small business working with a small team and have a limited set of features, monolith might be a better approach for you. However, if you are working on a huge product with hundreds of microservices, the maintenance cost of microservices will be worthwhile.&lt;/p&gt;

&lt;p&gt;Also, usually, when you think about HLD(High Level Design) interviews, chances are you will be developing an overall architecture for a complex system that might be difficult to design in a monolithic manner. So thinking in terms of microservices will be a good idea.&lt;/p&gt;
</description>
                <pubDate>Tue, 26 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/data-engineering-series20</link>
                <guid isPermaLink="true">http://localhost:4000/data-engineering-series20</guid>
                
                <category>Data_Engineering</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Data Engineering Series [Part19]: 로그 구조 스토리지</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;
</description>
                <pubDate>Mon, 25 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/data-engineering-series19</link>
                <guid isPermaLink="true">http://localhost:4000/data-engineering-series19</guid>
                
                <category>Data_Engineering</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Data Engineering Series [Part18]: APIs</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#event-driven-api&quot; id=&quot;markdown-toc-event-driven-api&quot;&gt;Event Driven API&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#web-api&quot; id=&quot;markdown-toc-web-api&quot;&gt;Web API&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;event-driven-api&quot;&gt;Event Driven API&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Webhooks&lt;/li&gt;
  &lt;li&gt;Websockets&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;web-api&quot;&gt;Web API&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;REST&lt;/li&gt;
  &lt;li&gt;RPC&lt;/li&gt;
  &lt;li&gt;GraphQL&lt;/li&gt;
&lt;/ul&gt;
</description>
                <pubDate>Sun, 24 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/data-engineering-series18</link>
                <guid isPermaLink="true">http://localhost:4000/data-engineering-series18</guid>
                
                <category>Data_Engineering</category>
                
                
                <category>DE</category>
                
            </item>
        
    </channel>
</rss>