<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Code Museum</title>
        <description>Jay Tech personal blogging theme for Jekyll</description>
        <link>http://localhost:4000/</link>
        <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
        <pubDate>Tue, 09 Aug 2022 13:12:56 +0900</pubDate>
        <lastBuildDate>Tue, 09 Aug 2022 13:12:56 +0900</lastBuildDate>
        <generator>Jekyll v4.2.1</generator>
        
            <item>
                <title>MySQL Series [Part15] IntelliJ IDE를 이용한 데이터베이스 시각화</title>
                <description>&lt;hr /&gt;
&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#참고&quot; id=&quot;markdown-toc-참고&quot;&gt;참고&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;참고&quot;&gt;참고&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.jetbrains.com/help/idea/creating-diagrams.html&quot; target=&quot;_blank&quot;&gt;IntelliJ: Database diagrams&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
                <pubDate>Fri, 29 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/mysql-series15</link>
                <guid isPermaLink="true">http://localhost:4000/mysql-series15</guid>
                
                <category>MySQL</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>MySQL Series [Part14] MySQL Optimizing SELECT Statements</title>
                <description>&lt;hr /&gt;
&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#optimization-overview&quot; id=&quot;markdown-toc-optimization-overview&quot;&gt;Optimization Overview&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#things-to-consider-for-optimization&quot; id=&quot;markdown-toc-things-to-consider-for-optimization&quot;&gt;Things to Consider for Optimization&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#select&quot; id=&quot;markdown-toc-select&quot;&gt;SELECT&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#where&quot; id=&quot;markdown-toc-where&quot;&gt;WHERE&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#group-by&quot; id=&quot;markdown-toc-group-by&quot;&gt;GROUP BY&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#join&quot; id=&quot;markdown-toc-join&quot;&gt;JOIN&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#subquery&quot; id=&quot;markdown-toc-subquery&quot;&gt;Subquery&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#temporary-table&quot; id=&quot;markdown-toc-temporary-table&quot;&gt;Temporary Table&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#order-by&quot; id=&quot;markdown-toc-order-by&quot;&gt;ORDER BY&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#정렬-처리-방법&quot; id=&quot;markdown-toc-정렬-처리-방법&quot;&gt;정렬 처리 방법&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#참고&quot; id=&quot;markdown-toc-참고&quot;&gt;참고&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h1 id=&quot;optimization-overview&quot;&gt;Optimization Overview&lt;/h1&gt;

&lt;p&gt;Database performance depends on several factors at the database level, such as tables, queries, and configuration settings. These software constructs result in CPU and I/O operations at the hardware level, which you must minimize and make as efficient as possible.&lt;/p&gt;

&lt;h1 id=&quot;things-to-consider-for-optimization&quot;&gt;Things to Consider for Optimization&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Are the tables structured properly? In particular, do the columns have the right data types, and does each table have the appropriate columns for the type of work? For example, applications that perform frequent updates often have many tables with few columns, while applications that analyze large amounts of data often have few tables with many columns.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Are the right indexes in place to make queries efficient?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Are you using the appropriate storage engine for each table, and taking advantage of the strengths and features of each storage engine you use? In particular, the choice of a transactional storage engine such as InnoDB or a nontransactional one such as MyISAM can be very important for performance and scalability.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Does each table use an appropriate row format? This choice also depends on the storage engine used for the table. In particular, compressed tables use less disk space and so require less disk I/O to read and write the data. Compression is available for all kinds of workloads with InnoDB tables, and for read-only MyISAM tables.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Does the application use an appropriate locking strategy? For example, by allowing shared access when possible so that database operations can run concurrently, and requesting exclusive access when appropriate so that critical operations get top priority. Again, the choice of storage engine is significant. The InnoDB storage engine handles most locking issues without involvement from you, allowing for better concurrency in the database and reducing the amount of experimentation and tuning for your code.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Are all memory areas used for caching sized correctly? That is, large enough to hold frequently accessed data, but not so large that they overload physical memory and cause paging. The main memory areas to configure are the InnoDB buffer pool and the MyISAM key cache.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;select&quot;&gt;SELECT&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Avoid using *&lt;/li&gt;
  &lt;li&gt;Avoid using DISTINCT -&amp;gt; 중복 데이터 제거를 위해 테이블 풀 스캔 해야함&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;where&quot;&gt;WHERE&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Use Indexes Where Appropriate&lt;/li&gt;
  &lt;li&gt;Avoid % Wildcard in a Predicate&lt;/li&gt;
  &lt;li&gt;Avoid using a function in the predicate of a query&lt;/li&gt;
  &lt;li&gt;BETWEEN, IN, &amp;lt;, &amp;gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;group-by&quot;&gt;GROUP BY&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;GROUP BY 작업은 크게 인덱스를 사용하는 경우와 사용할 수 없는 경우(임시 테이블을 사용)&lt;/li&gt;
  &lt;li&gt;인덱스를 사용할 수 없는 경우, 전체 테이블을 스캔하여 각 그룹의 모든 행이 연속되는 새 임시 테이블을 만든 다음 이 임시 테이블을 사용하여 그룹을 검색하고 집계 함수를 적용하는 것
    &lt;ul&gt;
      &lt;li&gt;이렇게 인덱스를 사용할 수 없을 때 할 수 있는 최선의 방법은 WHERE절을 이용해 GROUP BY 하기 전에 데이터량을 줄이는 것&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;인덱스를 잘 설정한다면 임시 테이블을 생성하지 않고 빠르게 데이터를 가져올 수 있다
    &lt;ul&gt;
      &lt;li&gt;인덱스를 최대로 활용하기 위해서는 GROUP BY 컬럼과, 인덱스되어 있는 컬럼간의 순서가 중요함&lt;/li&gt;
      &lt;li&gt;SELECT절에 사용되는 집계함수의 경우 MIN(), MAX()는 인덱스의 성능을 최대로 활용할 수 있도록 함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;참고로 MySQL 8.0부터는 GROUP BY를 한다고 해서 암묵적으로 정렬이 이루어지지 않음 -&amp;gt; 정렬 필요하면 명시적으로 ORDER BY 써야함&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;루스 인덱스 스캔을 사용할 수 있는 경우
    &lt;ul&gt;
      &lt;li&gt;루스 인덱스 스캔은 레코드를 건너뛰면서 필요한 부분만 가져오는 스캔 방식&lt;/li&gt;
      &lt;li&gt;EXPLAIN을 통헤 실행 계획을 확인해보면 Extra 컬럼에 ‘Using index for group-by’ 라고 표기됨&lt;/li&gt;
      &lt;li&gt;MIN(), MAX() 이외의 함수가 SELECT 절에 사용되면 루스 인덱스 스캔을 사용할 수 없음&lt;/li&gt;
      &lt;li&gt;인덱스가 (col1 col2, col3) 일 때 , GROUP BY col1, col2 과 같아야 함 (GROUP BY col2, col3은 안됨)&lt;/li&gt;
      &lt;li&gt;SELECT 절과 GROUP BY 절의 컬럼이 일치해야 함. SELECT col1, col2, MAX(col3) GROUP BY col1, col2 과 같아야 함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;타이트 인덱스 스캔을 사용하는 경우
    &lt;ul&gt;
      &lt;li&gt;SELECT 절과 GROUP BY 절의 컬럼이 일치하지 않지만, 조건절을 이용해 범위 스캔이 가능한 경우
        &lt;ul&gt;
          &lt;li&gt;SELECT c1, c2, c3 FROM t1 WHERE c2 = ‘a’ GROUP BY c1, c3;&lt;/li&gt;
          &lt;li&gt;SELECT c1, c2, c3 FROM t1 WHERE c1 = ‘a’ GROUP BY c2, c3;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;join&quot;&gt;JOIN&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;INNER joins, order doesn’t matter&lt;/li&gt;
  &lt;li&gt;OUTER joins, the order matters&lt;/li&gt;
  &lt;li&gt;여러 조인을 포함하는 LOOP JOIN 에서는 드라이빙 테이블(Driving Table)이 행들을 최소한으로 리턴하도록 해야됨&lt;/li&gt;
  &lt;li&gt;JOIN 되는 컬럼의 한쪽에만 INDEX가 있는 경우는 INDEX가 지정된 TABLE이 DRIVING TABLE이 된다&lt;/li&gt;
  &lt;li&gt;JOIN 시 자주 사용하는 칼럼은 인덱스로 등록한다&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;인덱스 레인지 스캔은 인덱스를 탐색(Index Seek)하는 단계와 인덱스를 스캔(Index Scan)하는 과정으로 구분해 볼 수 있다. 일반적으로 인덱스를 이용해서 쿼리하는 작업에서는 가져오는 레코드의 건수가 소량(전체 데이터 크기의 20% 이내)이기 때문에 인덱스 스캔 작업은 부하가 작고, 특정 인덱스 키를 찾는 인덱스 탐색 작업이 부하가 높은 편이다.&lt;/p&gt;

&lt;p&gt;JOIN 작업에서 드라이빙 테이블을 읽을 때는 인덱스 탐색 작업을 단 한 번만 수행하고, 그 이후부터는 스캔만 실행하면 된다.&lt;/p&gt;

&lt;p&gt;하지만 드리븐 테이블에서는 인덱스 탐색 작업과 스캔 작업을 드라이빙 테이블에서 읽은 레코드 건수만큼 반복한다.&lt;/p&gt;

&lt;p&gt;드라이빙 테이블과 드리븐 테이블이 1:1 조인되더라도 &lt;strong&gt;드리븐 테이블을 읽는 것이 훨씬 더 큰 부하를 차지&lt;/strong&gt;한다.&lt;/p&gt;

&lt;p&gt;그래서 옵티마이저는 항상 드라이빙 테이블이 아니라 드리븐 테이블을 최적으로 읽을 수 있게 실행 계획을 수립한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-SQL&quot;&gt;SELECT *
FROM employees e, dept_emp de
WHERE e.emp_no=de.emp_no
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;여기서 각 테이블의 emp_no 컬럼에 인덱스가 있을 때와 없을 때 조인 순서가 어떻게 달라지는 한 번 살펴보자.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;두 컬럼 모두 인덱스가 있는 경우
    &lt;ul&gt;
      &lt;li&gt;어느 테이블을 드라이빙으로 선택하든 인덱스를 이용해 드리븐 테이블의 검색 작업을 빠르게 처리할 수 있다&lt;/li&gt;
      &lt;li&gt;보통의 경우 어느 쪽 테이블이 드라이빙 테이블이 되든 옵티마이저가 선택하는 방법이 최적일 때가 많다&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;employees 테이블에만 인덱스가 있는경우
    &lt;ul&gt;
      &lt;li&gt;이 때는 employees 테이블을 드리븐 테이블로 선택한다&lt;/li&gt;
      &lt;li&gt;드리븐 테이블을 읽는 것이 훨씬 더 큰 부하를 차지하기 때문에 드리븐 테이블에서 인덱스를 활용하는 것이 중요한다&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;INNER JOIN은 조인 대상 테이블 모두에 해당하는 레코드만 반환한다. 이같은 특성 때문에 OUTER JOIN으로만 조인을 실행하는 쿼리들도 자주 보인다. 하지만 대개의 경우 OUTER JOIN은 대상 테이블들의 데이터가 일관되지 않은 경우에만 필요하다.&lt;/p&gt;

&lt;p&gt;MySQL 옵티마이저는 OUTER JOIN시 조인 되는 테이블(FROM A LEFT JOIN B에서 B)을 드라이빙 테이블로 선택하지 못하기 때문에 무조건 앞에 등장하는 테이블을 드라이빙 테이블로 선택한다. 그 결과 인덱스 유무에 따라 조인 순서를 변경함으로써 얻게 되는 최적화의 이점을 얻지 못하기 때문에 쿼리 성능이 나빠질 수 있다. 그래서 꼭 필요한 경우가 아니라면 INNER JOIN을 사용하는 것이 쿼리의 성능에 도움이 된다.&lt;/p&gt;

&lt;p&gt;JOIN의 순서&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;INNER JOIN인 경우
    &lt;ul&gt;
      &lt;li&gt;어차피 A and B and C 이기 때문에 A JOIN B JOIN C이든 B JOIN A JOIN C이든 같다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;LEFT JOIN의 경우 결과도 성능도 달라진다.
    &lt;ul&gt;
      &lt;li&gt;일단 가장 먼저 등장하는 테이블이 드라이빙 테이블이 된다 -&amp;gt; 이 말은 뒤에 따라오는 테이블은 드리븐 테이블이 된다는 말이다 -&amp;gt; 드리븐 테이블은 인덱스가 없으면 성능이 떨어진다 -&amp;gt; 뒤에 조인되는 테이블의 인덱스 유무에 따라 쿼리 성능이 달라진다&lt;/li&gt;
      &lt;li&gt;결과 자체도 맨 앞에 등장하는 테이블의 모든 레코드가 기준이 되기 때문에 순서에 따라 달라진다&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;INNER JOIN과 OUTER JOIN이 결합되는 경우
    &lt;ul&gt;
      &lt;li&gt;가능하다면 INNER JOIN이 앞에 오도록 하는 것이 좋다&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;subquery&quot;&gt;Subquery&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Avoid correlated sub queries as it searches row by row, impacting the speed of SQL query processing&lt;/li&gt;
  &lt;li&gt;JOIN으로 해결되면 서브쿼리 대신 JOIN을 사용하자&lt;/li&gt;
  &lt;li&gt;서브쿼리 안에 where절과 group by를 통해 불러오는 데이터양을 감소시킬 수 있습니다&lt;/li&gt;
  &lt;li&gt;서브쿼리는 인덱스 또는 제약 정보를 가지지 않기 때문에 최적화되지 못한다&lt;/li&gt;
  &lt;li&gt;윈도우 함수를 고려해보자&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;temporary-table&quot;&gt;Temporary Table&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Use a temporary table to handle bulk data&lt;/li&gt;
  &lt;li&gt;Temporary table vs Using index access&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;order-by&quot;&gt;ORDER BY&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;대부분의 SELECT 쿼리에서 정렬은 필수적&lt;/li&gt;
  &lt;li&gt;정렬을 처리하는 방법은 &lt;strong&gt;인덱스를 이용하는 방법&lt;/strong&gt;과 &lt;strong&gt;Filesort&lt;/strong&gt;라는 별도의 처리를 이용하는 방법&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;방법&lt;/td&gt;
      &lt;td&gt;장점&lt;/td&gt;
      &lt;td&gt;단점&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;인덱스 이용&lt;/td&gt;
      &lt;td&gt;SELECT 문을 실행할 때 이미 인덱스가 정렬돼 있어 순서대로 읽기만 하면 되므로 매우 빠르다&lt;/td&gt;
      &lt;td&gt;INSERT, UPDATE, DELETE 작업시 부가적인 인덱스 추가/삭제 작업이 필요하므로 느리다&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Filesort 이용&lt;/td&gt;
      &lt;td&gt;인덱스 이용과 반대로 INSERT, UPDATE, DELETE 작업이 빠르다&lt;/td&gt;
      &lt;td&gt;정렬 작업이 쿼리 실행 시 처리되어 쿼리의 응답 속도가 느려진다&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Filesort를 사용해야 하는 경우&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;정렬 기준이 너무 많아서 모든 인덱스를 생성하는 것이 불가능한 경우&lt;/li&gt;
  &lt;li&gt;어떤 처리의 결과를 정렬해야 하는 경우&lt;/li&gt;
  &lt;li&gt;랜덤하게 결과 레코드를 가져와야 하는 경우&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;소트 버퍼&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MySQL은 정렬을 수행하기 위해 별도의 메모리 공간을 할당받아서 사용하는데 이 메모리 공간을 소트 버퍼라고 한다&lt;/li&gt;
  &lt;li&gt;정렬해야 할 레코드의 건수가 소트 버퍼의 크기보다 크다면 어떻게 해야 할까?
    &lt;ul&gt;
      &lt;li&gt;정렬해야 할 레코드를 여러 조각으로 나눠서 처리하게 됨. 이 과정에서 임시 저장을 위해 디스크를 사용&lt;/li&gt;
      &lt;li&gt;일부를 처리하고 디스크에 저장하기를 반복 수행함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;정렬 알고리즘&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;정렬 대상 컬럼과 프라이머리 키만 가져와서 정렬하는 방식
    &lt;ul&gt;
      &lt;li&gt;정렬 대상 컬럼과 프라이머리 키 값만 소트 버퍼에 담아 정렬을 수행&lt;/li&gt;
      &lt;li&gt;그리고 다시 정렬 순서대로 프라이머리 키로 테이블을 읽어서 SELECT할 컬럼을 가져옴&lt;/li&gt;
      &lt;li&gt;가져오는 컬럼이 두 개 뿐이라 소트 버퍼에 많은 레코드를 한 번에 읽어올 수 있음&lt;/li&gt;
      &lt;li&gt;단점은 테이블을 두 번 읽어야 함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;정렬 대상 컬럼과 SELECT문으로 요청한 컬럼을 모두 가져와서 정렬하는 방식
    &lt;ul&gt;
      &lt;li&gt;최신 버전의 MySQL에서 일반적으로 사용하는 방식&lt;/li&gt;
      &lt;li&gt;SELECT 문에서 요청한 컬럼의 개수가 많아지면 계속 분할해서 소트 버퍼에 읽어와야함&lt;/li&gt;
      &lt;li&gt;레코드의 크기나 건수가 작은 경우 성능이 좋음&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;정렬-처리-방법&quot;&gt;정렬 처리 방법&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;인덱스를 사용한 정렬
    &lt;ul&gt;
      &lt;li&gt;인덱스를 이용해 정렬을 하기 위해서는 반드시 ORDER BY의 순서대로 생성된 인덱스가 있어야 함&lt;/li&gt;
      &lt;li&gt;인덱스를 이용해 정렬이 가능한 이유는 B-Tree 인덱스가 키 값으로 정렬되어 있기 때문&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Filesort를 사용한 정렬
    &lt;ul&gt;
      &lt;li&gt;인덱스를 사용할 수 없는 경우, WHERE 조건에 일치하는 레코드를 검색해 정렬 버퍼에 저장하면서 정렬을 처리(FIlesort)함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;참고&quot;&gt;참고&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://dev.mysql.com/doc/refman/8.0/en/select-optimization.html&quot; target=&quot;_blank&quot;&gt;MySQL 공식문서: Optimizing SELECT Statements&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://phoenixnap.com/kb/improve-mysql-performance-tuning-optimization&quot; target=&quot;_blank&quot;&gt;MySQL Performance Tuning and Optimization Tips&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://danbi-ncsoft.github.io/works/2021/11/05/etl-performace-tips.html&quot; target=&quot;_blank&quot;&gt;ETL 성능 향상을 위한 몇 가지 팁들&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://til.songyunseop.com/mysql/group-by-optimization.html&quot; target=&quot;_blank&quot;&gt;전지적 송윤섭시점 TIL, GROUP BY 최적화&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://otsteam.tistory.com/136&quot; target=&quot;_blank&quot;&gt;SQL 성능을 위한 25가지 규칙&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://jojoldu.tistory.com/173?category=761883&quot; target=&quot;_blank&quot;&gt;패스트캠퍼스 SQL튜닝캠프 4일차 - 조인의 기본 원리와 활용&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://brightestbulb.tistory.com/147&quot; target=&quot;_blank&quot;&gt;취미는 공부 특기는 기록, Nested Loop Join, Driving Table&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/9614922/does-the-join-order-matter-in-sql&quot; target=&quot;_blank&quot;&gt;stackoverflow, Does the join order matter in SQL?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://coding-factory.tistory.com/756&quot; target=&quot;_blank&quot;&gt;코딩팩토리, [DB] 데이터베이스 NESTED LOOPS JOIN (중첩 루프 조인)에 대하여&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://schatz37.tistory.com/2&quot; target=&quot;_blank&quot;&gt;고동의 데이터 분석, [SQL] “성능 관점”에서 보는 결합(Join)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://schatz37.tistory.com/3?category=878798&quot; target=&quot;_blank&quot;&gt;고동의 데이터 분석, [SQL] 성능 관점에서의 서브쿼리(Subquery)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
                <pubDate>Fri, 29 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/mysql-series14</link>
                <guid isPermaLink="true">http://localhost:4000/mysql-series14</guid>
                
                <category>MySQL</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Coding Test Series [Part21]: 파이썬 문법</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#in-python-and-operation-will-not-return-a-boolean-value&quot; id=&quot;markdown-toc-in-python-and-operation-will-not-return-a-boolean-value&quot;&gt;In python, ‘and’ operation will not return a boolean value&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;in-python-and-operation-will-not-return-a-boolean-value&quot;&gt;In python, ‘and’ operation will not return a boolean value&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;If it’s true, it will return the last true value, remember is the value, not True. Otherwise, it will return the first false value.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;'ban' and 'car' -&amp;gt; 'car'
0 and 'car' -&amp;gt; 0
'ban' and False -&amp;gt; False
'ban' or False -&amp;gt; 'ban'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
                <pubDate>Fri, 29 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/python-things</link>
                <guid isPermaLink="true">http://localhost:4000/python-things</guid>
                
                <category>Coding_Test</category>
                
                
                <category>CS</category>
                
            </item>
        
            <item>
                <title>Data Engineering Series [Part24]: 시스템 디자인(4) Database</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#factors&quot; id=&quot;markdown-toc-factors&quot;&gt;Factors&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#caching-solution&quot; id=&quot;markdown-toc-caching-solution&quot;&gt;Caching Solution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#file-storage-solution&quot; id=&quot;markdown-toc-file-storage-solution&quot;&gt;File Storage Solution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#storage-solutions-offering-text-search-capability&quot; id=&quot;markdown-toc-storage-solutions-offering-text-search-capability&quot;&gt;Storage Solutions Offering Text Search Capability&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#time-series-database&quot; id=&quot;markdown-toc-time-series-database&quot;&gt;Time Series Database&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#data-warehousing-storage-solution&quot; id=&quot;markdown-toc-data-warehousing-storage-solution&quot;&gt;Data Warehousing Storage Solution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#rdbms-vs-nosql&quot; id=&quot;markdown-toc-rdbms-vs-nosql&quot;&gt;RDBMS vs NoSQL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;Databases will not impact your functional requirements. Whichever database you use, you can still achieve your functional requirements somehow, but at the cost of huge performance degradation. So when we say requirement, we usually mean non-functional requirements.&lt;/p&gt;

&lt;h1 id=&quot;factors&quot;&gt;Factors&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Structure of the data&lt;/li&gt;
  &lt;li&gt;Query pattern&lt;/li&gt;
  &lt;li&gt;Amount or scale that you need to handle&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These are the factors we need to consider when selecting which database to use. Now let us look at various types of storage solutions and some use cases where they will be suitable.&lt;/p&gt;

&lt;h1 id=&quot;caching-solution&quot;&gt;Caching Solution&lt;/h1&gt;
&lt;p&gt;If you are calling your database very frequently or making a remote call to independent services with high latency, you might want to cache some data locally at your end. Some of the most commonly used caching solutions are Memcached, Hazelcast, and Redis. You could also use some other solutions; this is not an exhaustive list. In the following articles, we will usually use Redis as it is one of the most widely used and stable solutions.&lt;/p&gt;

&lt;h1 id=&quot;file-storage-solution&quot;&gt;File Storage Solution&lt;/h1&gt;

&lt;p&gt;Assume you are working on something like Netflix and you need a data store for images, videos, etc. Now, in this case, a database is not very useful to us as we are storing files rather than information. &lt;strong&gt;Databases are meant to store information that can be queried&lt;/strong&gt;, whereas files you do not need to query. You just deliver them as they are.&lt;/p&gt;

&lt;p&gt;This is when we use something called Blob (Binary Large Object) storage. Amazon S3 is an example of blob storage. Usually, blob storage is used in combination with a Content delivery network or a CDN. A CDN is a network of servers around the world that delivers content in different geographical locations with reduced latency. If the server you are getting content from is closer to your geographic location, the content will take less time (reduced latency) to be delivered from the server to you.&lt;/p&gt;

&lt;h1 id=&quot;storage-solutions-offering-text-search-capability&quot;&gt;Storage Solutions Offering Text Search Capability&lt;/h1&gt;

&lt;p&gt;Let’s again take the Netflix example. Suppose you want to build a search functionality where the user can search by movie, genre, actor, actress, director, etc. Here you use a search engine like Solr or Elasticsearch which can support fuzzy search.&lt;/p&gt;

&lt;p&gt;To understand fuzzy search, let us take an example of an Uber user searching for airprot. If you notice this is a typo, what the user means to search is airport. But if, because of this typo, we don’t provide any search results, it will be a very poor user experience. So we search for terms similar to airport in the database. This is known as fuzzy search.&lt;/p&gt;

&lt;p&gt;Now a key point here is that these search engines are not databases. Databases provide a guarantee that once stored, our data will not be lost unless we delete it; search engines offer no such guarantee. This is why we should never use search engines like Elasticsearch as our primary data source. We can load the data to them from our primary database to reduce search latency and provide fuzzy and relevance-based text search.&lt;/p&gt;

&lt;h1 id=&quot;time-series-database&quot;&gt;Time Series Database&lt;/h1&gt;

&lt;p&gt;Suppose we are trying to build a metric tracking system. We will need something called a time-series database. Time-series databases are, in a way, an extension of relational databases, but unlike a standard relational DB, time-series databases will never be randomly updated. It will be &lt;strong&gt;updated sequentially in an append-only format&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Also, it will have more bulk reads for a certain time range as opposed to random reads. For example, how many people watched a video in the last 1 week, 10 days, 1 month, 1 year, and so on. Some examples of time series databases are OpenTSDB and InfluxDB.&lt;/p&gt;

&lt;h1 id=&quot;data-warehousing-storage-solution&quot;&gt;Data Warehousing Storage Solution&lt;/h1&gt;

&lt;p&gt;Sometimes we need a large database to dump all of the data available to us, to perform analytics. Eg. a company like Uber will store all of their data so they can perform analytics to identify where Uber is not used very much, where are the hotspots, what are the peak hours, etc. These systems are not used for regular transactions but offline reporting. Hadoop is a very commonly used Data warehouse.&lt;/p&gt;

&lt;h1 id=&quot;rdbms-vs-nosql&quot;&gt;RDBMS vs NoSQL&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_14.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If you need ACID properties, then you need to use a relational DBMS. Some examples are MySQL, Oracle, and Postgres. But what if you don’t need ACID? Well, you can still use RDBMS, or you can use a Non-relational database.&lt;/p&gt;

&lt;p&gt;Let’s consider an example. Suppose you are trying to build a catalog for something like Amazon, where you want to store information about different products that have various attributes. These attributes will normally not be the same for different products. In such a case, our data cannot be represented as a table. This means we need to use a NoSQL database.&lt;/p&gt;

&lt;p&gt;Also, we don’t just need to store this data but also &lt;strong&gt;query on this data&lt;/strong&gt;. Here comes the factor of query pattern. Which type of database we use here will be decided based on what type of data we store and what types of queries will be run on it. If we have vast data - not just volume but also a vast variety of attributes - and we need to run a vast variety of queries, we need to use something called a Document DB. Couchbase and MongoDB are some commonly used document databases. (Elasticsearch is special cases of document DB)&lt;/p&gt;

&lt;p&gt;But what if &lt;strong&gt;you don’t have a vast variety of attributes&lt;/strong&gt; i.e. very &lt;strong&gt;limited variety of queries&lt;/strong&gt;, but the &lt;strong&gt;size of the database increases very rapidly&lt;/strong&gt;? For example, data collected by Uber for their drivers’ location pings. Now the number of Uber drivers will keep increasing day by day, and therefore so will the data collected every day. This results in an ever-increasing amount of data. In such cases, we use &lt;strong&gt;Columnar DBs like Cassandra or HBase&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Using Cassandra is lighter to deploy, whereas HBase is built on top of Hadoop; we would need to first set up Hadoop and then setup HBase on top of it. This makes the setup of HBase a little lengthy, but performance-wise both are pretty much the same.&lt;/p&gt;

&lt;p&gt;Let us assume we have stored Uber’s ride-related data in a Cassandra with driver id as a partition key. Now when we want to fetch a ride for a particular driver on a particular date, Cassandra can find it easily enough. But if we want to find a customer’s ride on a particular date, Cassandra will have to fan out this query to all the partitions since customer id is not a partition key. So what is the point of using Cassandra if it is not going to scale well!&lt;/p&gt;

&lt;p&gt;Well, there is a simple enough fix. We can replicate the same data to another table or column family with a different partition key. Now when we receive the query for customer id and date, we can simply direct it to the table where the partition key is customer id. This is what we mean by a limited variety of queries but a huge scale. Cassandra (and HBase) can scale massively as long as the queries are of similar types.&lt;/p&gt;

&lt;p&gt;If the queries are more diverse, then we will have to replicate again and again for each partition key, which we can, but only to a certain limit. If we cannot control the types of queries, then something like MongoDB might be the way to go. But if we just need a huge scale for a few types of queries, the Cassandra is the perfect solution.&lt;/p&gt;

&lt;p&gt;Now let’s shake things up a bit!&lt;/p&gt;

&lt;p&gt;Let’s consider the Amazon example again. If for a product we have only one item in stock but multiple users are trying to buy it, it should only be sold to one user, which means we need ACID here. So we should choose a Relational DB like MySQL.&lt;/p&gt;

&lt;p&gt;But the orders-related data for Amazon will be ever-increasing and will have a variety of attributes. That means we should use a Columnar NoSQL database like Cassandra. So which one to go for? We decide to go with a combination of both. We can store the data of orders that are not yet delivered in a MySQL database, and once the order is completed, we can move it to Cassandra to be permanently stored.&lt;/p&gt;

&lt;p&gt;But again, our requirements might be a little more complex. Suppose you want to build a reporting system for how many people bought a particular item. Now, on Amazon, products are sold by various users of different brands and different variations. So the report can not target a single product, rather, it should target a subset of products, which can be in either Cassandra or MySQL.&lt;/p&gt;

&lt;p&gt;Such a requirement is an example of a situation where our best choice would be a document DB like Mongo DB. So we decide to keep a subset of this orders data in Mongo DB that tells us which users bought how much quantity of a certain product, at what time, on what date, etc. So suppose you want to check how many people bought sugar in the last month. You can get order ids from Mongo DB and use this order id to pick up the rest of the data from Cassandra or MySQL.&lt;/p&gt;

&lt;p&gt;That should be it for Storage Solutions in System Design!&lt;/p&gt;
</description>
                <pubDate>Tue, 26 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/data-engineering-series24</link>
                <guid isPermaLink="true">http://localhost:4000/data-engineering-series24</guid>
                
                <category>Data_Engineering</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Data Engineering Series [Part23]: 시스템 디자인(4) Caching</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#what-is-a-cache&quot; id=&quot;markdown-toc-what-is-a-cache&quot;&gt;What is a Cache?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#when-to-cache&quot; id=&quot;markdown-toc-when-to-cache&quot;&gt;When to Cache?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#how-does-caching-work&quot; id=&quot;markdown-toc-how-does-caching-work&quot;&gt;How Does Caching Work?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#when-not-to-cache&quot; id=&quot;markdown-toc-when-not-to-cache&quot;&gt;When Not to Cache?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#cache-eviction-strategies&quot; id=&quot;markdown-toc-cache-eviction-strategies&quot;&gt;Cache Eviction Strategies&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#time-based&quot; id=&quot;markdown-toc-time-based&quot;&gt;Time Based&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#size-based&quot; id=&quot;markdown-toc-size-based&quot;&gt;Size Based&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#metrics&quot; id=&quot;markdown-toc-metrics&quot;&gt;Metrics&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#caching-products&quot; id=&quot;markdown-toc-caching-products&quot;&gt;Caching Products&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;what-is-a-cache&quot;&gt;What is a Cache?&lt;/h1&gt;
&lt;p&gt;A cache is high-speed data access and storage layer that helps us fetch data that we had previously retrieved or computed.&lt;/p&gt;

&lt;p&gt;If we need frequent or repeated access to certain information that we have already queried from a service or a database, then instead of repeatedly querying the service, it’s better to cache that information for subsequent use, for it to be readily available.&lt;/p&gt;

&lt;p&gt;For Example, for Twitter users, we can cache all the information that is needed to load the homepage of a user (like followers, tweets, etc.). Caching will help avoid repeatedly querying the same service, caused by the refreshing of the browser by the user or other similar use cases. In this case, caching helps to reduce latency and improve resource utilization of servers.&lt;/p&gt;

&lt;h1 id=&quot;when-to-cache&quot;&gt;When to Cache?&lt;/h1&gt;
&lt;p&gt;A cache is primarily used in the following scenarios:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;When the data involves a lot of computation, then to reduce latency and CPU utilization, it’s good to cache the pre-calculated information for fast retrieval later on.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;To reduce frequent database or network (API) calls, it’s beneficial to cache the previously fetched data for fast retrieval. This helps reduce latency as well as bandwidth requirements.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;how-does-caching-work&quot;&gt;How Does Caching Work?&lt;/h1&gt;

&lt;p&gt;A cache is primarily used to store the most recently or frequently used data, in the hope that it will soon be fetched again. Caches are typically faster than databases and services when it comes to re-accessing this stored information. What makes them so fast is the fact that caches store data in SSDs and mostly RAMs which reduces the lookup time. However, this does not mean that we should cache everything.&lt;/p&gt;

&lt;h1 id=&quot;when-not-to-cache&quot;&gt;When Not to Cache?&lt;/h1&gt;
&lt;p&gt;There are some scenarios where the negative aspects of caching outweigh its benefits:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;High Consistency requirements: When we fetch the previously stored data from the cache, there is a possibility of stale data being displayed to the user. For example, for a social media app, then some stale data is probably fine. However, for a stock price display app, then the cache must be in sync with the primary data source.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Write heavy / Read Once: When write operations (updates to data) are more frequent than read operations (data retrieval). For example, caching the data of an analytics system would only increase the hardware maintenance cost.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Low repetition: When the action of retrieval of the same information is not frequently repeated by the user. For example, the cost calculated by the trip cost estimation module of a cab booking app between the exact two points need not be cached.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;cache-eviction-strategies&quot;&gt;Cache Eviction Strategies&lt;/h1&gt;
&lt;p&gt;We need to regularly expel data from the cache to limit the size of the cache and to maintain its speed while ensuring that the entries are up to date.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_12.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;time-based&quot;&gt;Time Based&lt;/h2&gt;

&lt;p&gt;We keep an entry in the cache for some amount of time. In this strategy, we set a TTL (Time To Live). We will evict the entry from the cache after a certain pre-determined time has elapsed. The time which an entry stays in the cache before being evicted is called TTL.&lt;/p&gt;

&lt;h2 id=&quot;size-based&quot;&gt;Size Based&lt;/h2&gt;

&lt;p&gt;We keep at most some number of entries in the cache.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;FIFO (First In First Out): We harness the FIFO property of the queue data structure to evict old entries.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;LFU (Least Frequently Used): When we must evict an entry, we will evict the least frequently used entry.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;LRU (Least Recently Used): When we must evict an entry, we will evict the least recently used entry.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;LFRU (Least Frequently and Recently Used): We evict the least valuable entry, the one that’s neither used frequently nor recently. This strategy gives the best results.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;metrics&quot;&gt;Metrics&lt;/h1&gt;
&lt;p&gt;We can use the following metrics to evaluate the performance of the cache:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Size: Increasing the size of the cache usually increases the response time and therefore reduces its performance.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Latency: The introduction of cache into the system must reduce latency from what it was earlier.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cache Hit Rate: It is the ratio of results found in the cache to the requests made to the cache. If the cache hit rate is low i.e., requests to cache are not returning the desired data, then it essentially slows down the system.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;caching-products&quot;&gt;Caching Products&lt;/h1&gt;

&lt;p&gt;It’s usually not recommended to write your own cache implementation, because there are a lot of really good cache implementations out there that you can use. Some of the most popular caching products that are available in the market are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ehcache&lt;/li&gt;
  &lt;li&gt;Hazelcast&lt;/li&gt;
  &lt;li&gt;Memcached&lt;/li&gt;
  &lt;li&gt;Redis&lt;/li&gt;
&lt;/ul&gt;
</description>
                <pubDate>Tue, 26 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/data-engineering-series23</link>
                <guid isPermaLink="true">http://localhost:4000/data-engineering-series23</guid>
                
                <category>Data_Engineering</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Data Engineering Series [Part22]: 시스템 디자인(3) Consistent Hashing</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#why-hashing&quot; id=&quot;markdown-toc-why-hashing&quot;&gt;Why hashing?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#consistent-hashing&quot; id=&quot;markdown-toc-consistent-hashing&quot;&gt;Consistent Hashing&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#where-is-it-used&quot; id=&quot;markdown-toc-where-is-it-used&quot;&gt;Where is it Used&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;why-hashing&quot;&gt;Why hashing?&lt;/h1&gt;

&lt;p&gt;Hash is basically a function that takes a value and converts it into another value of a specific format. Hash functions that are commonly used are MD5, SHA1, SHA256, etc.&lt;/p&gt;

&lt;p&gt;Suppose you build a distributed cache, where the data is distributed over various nodes, sometimes spanning multiple data centers. When we want to store the data for a user, we need to decide which node will cache this data. And when we want to retrieve this cached value, we must query the same node. So let us use a simple hash function for this again.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hash(user) = Sum(ASCII value of all characters in name) % 5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Where 5 is the number of nodes. This way, the hashes generated for users will be as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_8.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Since hash(Alice) is 0, Alice’s data will be stored in node 0. Similarly, Bob’s data will be stored in node 1 and Eve’s in 4. Now when you need to look up the information for Alice, you will use the same hash function to determine which node to query. Since hash(Alice) equals 0, you will query node 0 and fetch the information.&lt;/p&gt;

&lt;p&gt;But there is a problem with this solution. This model is not scalable. If the traffic increases and you want to add a new node, the formula to calculate the hash will get updated to&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hash(user) = Sum(ASCII value of all characters in name) % 6
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And similarly hash(Alice) will get updated to 2. So now you will search for Alice’s information in node 2, but the information is actually stored in node 0 so you won’t find it.&lt;/p&gt;

&lt;p&gt;To fix this, you will need to rehash all the data every time a node is added or removed, and once rehashed, you need to move the data to their respective new nodes, which could be across different data centers. This is not a very good solution as it uses up a lot of CPU resources and bandwidth.&lt;/p&gt;

&lt;p&gt;This is where Consistent Hashing comes in.&lt;/p&gt;

&lt;h1 id=&quot;consistent-hashing&quot;&gt;Consistent Hashing&lt;/h1&gt;

&lt;p&gt;Consistent Hashing tries to optimize the system in such a way that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;You don’t need to move around all the data while adding or removing nodes.&lt;/li&gt;
  &lt;li&gt;There will be minimal movement of data as if a node is removed, the data from that node will be supported by another node. Similarly, when a node is added, some data will be mapped to it as you don’t want it to sit idle.&lt;/li&gt;
  &lt;li&gt;You can have a nearly even distribution of data across all machines.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The idea is &lt;strong&gt;removing the number of nodes in the system out of the equation&lt;/strong&gt; while calculating the hash. Now hashes for data and nodes will all be independently calculated and adding or removing nodes won’t change these hashes.&lt;/p&gt;

&lt;p&gt;Now instead of assigning the data to these nodes in a sequential manner, we will plot these nodes, or their hashes, on the number line, and each node will be responsible for the range between its position and the position of the first node to its right.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_9.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;When the data comes in for storage, we will calculate its hash to determine its place on the number line. Based on which node’s range it falls in, we will map the data to that node.&lt;/p&gt;

&lt;p&gt;If you want to remove a node from this system, the range of the previous machine on the number line will be extended, and all the data from the removed node will be mapped to the previous node in the number line. This resolves the issue of data transfer as only the data from one machine will need to be mapped to another machine.&lt;/p&gt;

&lt;p&gt;But there is still a problem with this system. &lt;strong&gt;After removing a node, the ranges of certain machines might not be balanced.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;An ideal solution to this would be &lt;strong&gt;assigning data between various nodes.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The idea is to assign the same machine to multiple hashes and map each of these hashes on the number line.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_10.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This can be achieved by either using multiple hash functions or by assigning multiple identifiers to the same node, and then calculating the hashes for all of the instanced. Then, We can map them on the number line, or what we can now refer to as a consistent hashing ring, essentially representing the same node on the ring multiple times.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_11.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now the data handled by a removed node will be distributed across the ring. So when a node needs to be removed, all its identifiers will be removed and the data will be mapped to the nodes falling to the right of each identifier, as shown in the following diagram, making the distribution much more even.&lt;/p&gt;

&lt;p&gt;(노드가 삭제되도, 그 노드에 저장되어 있던 데이터가 여러 해시 함수에 의해 분리된 인스턴스에 흩어져서 저장되어 있었으므로, 다른 노드로 이동할 때도 각 인스턴스의 오른쪽 인스턴스로 저장되므로 여러 노드에 분산 저장되게 된다. -&amp;gt; 데이터가 훨씬 even해진다.)&lt;/p&gt;

&lt;p&gt;The reason why it gets even is because each identifier of machine is hashed separately, with the hash function, it is very likely that they would be arranged in a random fashion like Blue_4 - Red_1 - Blue_2 - Green_3 - Red_4 - Orange_1, which makes sure that when one machine is removed, it’s data us spread across multiple other machines.&lt;/p&gt;

&lt;p&gt;Similarly, when a new node is added, its identifiers will also be mapped across the ring, picking up data from various nodes, maintaining even distribution across the ring.&lt;/p&gt;

&lt;h1 id=&quot;where-is-it-used&quot;&gt;Where is it Used&lt;/h1&gt;

&lt;p&gt;Now we just saw how we could use consistent hashing while building a caching system. There are a lot of systems out there that use consistent hashing for improving their performance. For example, Cassandra, a distributed NoSQL Columnar DB that deals with huge traffic uses consistent hashing to distribute its data. Amazon’s Dynamo DB is another such example. It is a managed distributed DB which uses consistent hashing for distributing its data. Similarly, Couchbase is another NoSQL DB (a document DB) which uses consistent hashing to distribute its data across various instances.&lt;/p&gt;
</description>
                <pubDate>Tue, 26 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/data-engineering-series22</link>
                <guid isPermaLink="true">http://localhost:4000/data-engineering-series22</guid>
                
                <category>Data_Engineering</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Data Engineering Series [Part21]: 시스템 디자인(2) Inter-Service Communication</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#inter-service-communication&quot; id=&quot;markdown-toc-inter-service-communication&quot;&gt;Inter-Service Communication&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#modes-of-communication&quot; id=&quot;markdown-toc-modes-of-communication&quot;&gt;Modes of communication&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#synchronous-approach&quot; id=&quot;markdown-toc-synchronous-approach&quot;&gt;Synchronous Approach&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#asynchronous-approach&quot; id=&quot;markdown-toc-asynchronous-approach&quot;&gt;Asynchronous Approach&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#best-of-both-worlds&quot; id=&quot;markdown-toc-best-of-both-worlds&quot;&gt;Best of Both Worlds&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#message-queues&quot; id=&quot;markdown-toc-message-queues&quot;&gt;Message Queues&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#protocols-for-communication&quot; id=&quot;markdown-toc-protocols-for-communication&quot;&gt;Protocols for communication&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#how-clients-and-servers-interact&quot; id=&quot;markdown-toc-how-clients-and-servers-interact&quot;&gt;How clients and servers interact&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#http&quot; id=&quot;markdown-toc-http&quot;&gt;HTTP&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#websocket&quot; id=&quot;markdown-toc-websocket&quot;&gt;WebSocket&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h1 id=&quot;inter-service-communication&quot;&gt;Inter-Service Communication&lt;/h1&gt;

&lt;p&gt;In this article, we will be looking at how services interact with each other. Why is this important? Well, when you have a huge system with a lot of microservices interacting with each other, their communication needs to be efficient to provide the best user experience and also to avoid any cascading effects across the system.&lt;/p&gt;

&lt;h1 id=&quot;modes-of-communication&quot;&gt;Modes of communication&lt;/h1&gt;
&lt;p&gt;There are primarily two modes of communication between services:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Synchronous&lt;/strong&gt;: When a service &lt;strong&gt;waits&lt;/strong&gt; for a downstream system to respond before responding back to the client with a success or failure response.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Asynchronous&lt;/strong&gt;: This is a more of a fire and forget approach. A service will fire a call to the downstream system and won’t track it further.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;synchronous-approach&quot;&gt;Synchronous Approach&lt;/h1&gt;
&lt;p&gt;Let’s say you are building Amazon. You have a user U1 trying to place an order. U1 will reach out to the Order Service. Order Service will now talk to the Inventory Service to find out if a sufficient quantity of the product is available. If that is the case, Inventory Service will send a success response. Otherwise, it will respond with an error, and Order Service will respond to the user saying the order could not be placed.&lt;/p&gt;

&lt;p&gt;Now if the inventory response was a success, the Order Service will talk to the Payment Service to process the payment. Once the payment is successful, the Order Service will now talk to the Warehouse Service asking it to start packing and prepare for shipping the product to the user. Once Warehouse Service responds with a success, the Order Service will talk to a Notification Service to send an email to the user saying their order has been placed, with so and so payment details and sharing an ETA for the delivery of the product.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now, this is a happy scenario. What happens when one of the calls fails? Well, it depends on which call fails. If the call to Notification Service fails, does it make sense to cancel the order? No. We shouldn’t cancel an order just because the Notification Service failed. However, what if payment fails? Now we definitely need to cancel the order. But now we need to update the Inventory again to undo the change to the product quantity. What if the call to Inventory Service fails?&lt;/p&gt;

&lt;p&gt;So as you can see, there are some loopholes in a purely synchronous approach.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It has very high latency as the user does not get notified until all the calls have come back with a success or failure response.&lt;/li&gt;
  &lt;li&gt;The system is tightly coupled, and any failure will have cascading effects across the board.&lt;/li&gt;
  &lt;li&gt;The code becomes very complex since we need to handle all the cascading error scenarios.&lt;/li&gt;
  &lt;li&gt;Due to complexity, it requires extremely high maintenance.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;asynchronous-approach&quot;&gt;Asynchronous Approach&lt;/h1&gt;
&lt;p&gt;Let us see what happens in a purely asynchronous approach.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;U1 sends a call to the Order Service which makes asynchronous calls to all the downstream systems. In such a case, even if Inventory Service responds with an error code, or even if the payment fails, the order would get placed. Which is an even bigger mess! So how do we go about this?&lt;/p&gt;

&lt;p&gt;Well, as we can see, some parts of this process must be mandatory, and some can be done on a best-effort basis. If the Inventory Service or Payment Service responds with an error, we cannot place the order. But if the notification does not go through or the Warehouse Service is temporarily down, we don’t need to cancel our order. So we can follow a hybrid approach here; &lt;strong&gt;use a synchronous approach for the mandatory steps and an asynchronous approach for the rest.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;best-of-both-worlds&quot;&gt;Best of Both Worlds&lt;/h2&gt;
&lt;p&gt;The Hybrid approach suggests that the mandatory tasks need to be performed in a synchronous manner and everything else can be done asynchronously.&lt;/p&gt;

&lt;p&gt;So Order Service will send out a synchronous call to Inventory Service, and wait for a response. In case of success, it will call the Payment Service. If the Payment Service gives a successful response, Order Service will make parallel asynchronous calls to the Warehouse Service and Notification Service and, at the same time, respond to the user saying the order has been placed. If the Payment Service call had failed, Order Service would send an asynchronous call to the Inventory Service reverting the quantity change.&lt;/p&gt;

&lt;p&gt;So this looks like a much better solution. There are still some misses here though. What if the asynchronous call to Warehouse Service failed? It would lose the details for that order. This is where we would use &lt;strong&gt;Message Queues&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;message-queues&quot;&gt;Message Queues&lt;/h2&gt;
&lt;p&gt;Message Queues(Kafka, RabbitMQ, ActiveMQ 등) are highly fault-tolerant and persist messages for some time. How a message Queue works is, it has some Publishers adding messages to it, and some Subscribers listening to it and picking up the events meant for them at their own pace. Since these queues store messages for some time, if a subscriber is temporarily down, the messages will remain in the queue and will be picked up when the subscriber is running again.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So now, when Order Service wants to make asynchronous calls to Warehouse and Notification services, it will instead put an event in the Message Queue. Warehouse Service and Notification Service, which will be listening to the queue, will pick up the events meant for them. If one of the systems is down, the messages will remain in the queue until the service is back up and ready to receive messages again. This way, none of the data gets lost.&lt;/p&gt;

&lt;h1 id=&quot;protocols-for-communication&quot;&gt;Protocols for communication&lt;/h1&gt;

&lt;p&gt;In this article, we will look at the protocols we can use to interact with clients.&lt;/p&gt;

&lt;h2 id=&quot;how-clients-and-servers-interact&quot;&gt;How clients and servers interact&lt;/h2&gt;

&lt;p&gt;In a real-world scenario, rather than talking to a specific server, the client’s request will instead be sent to a data center, where it could be picked up by any of the servers. However, irrespective of which server receives the request, the response will be the same. Based on this flow, we can draw the following conclusions about this architecture:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It is client-driven. Only on the user’s button click will the client send the requests to the server, and the server will only respond to these requests.&lt;/li&gt;
  &lt;li&gt;It is a simple request-response model. For every request from the client, the server will respond with some information or a simple confirmation.&lt;/li&gt;
  &lt;li&gt;There are occasional requests from clients, only one request every few seconds based on the user’s actions i.e. from the client-side it is a low throughput system.&lt;/li&gt;
  &lt;li&gt;It is a stateless system i.e. irrespective of which server is responding, the response remains the same.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;http&quot;&gt;HTTP&lt;/h2&gt;

&lt;p&gt;These requirements make this a perfect use case for HTTP(s) protocol. Although these days, most architectures on HTTP have moved to HTTPS, which is a more secure version of HTTP as it prevents man-in-the-middle attacks.&lt;/p&gt;

&lt;p&gt;Now, when we are using HTTP, REST is usually the best API standard to follow as it is very widely used and very user friendly.&lt;/p&gt;

&lt;p&gt;Let us look at an example for a REST request and response:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Request:
Method: GET
URL: https://www.twitter.com/user/{id}

Response:
Status: 200 OK
Headers: &amp;lt;...&amp;gt;
Body: {
    “userId”: 1,
    “Email”: “someone@example.com”
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The client makes a request to twitter.com over HTTPS to get information about a user with an id. In response, the server sends a success status code along with the user’s user id and email. As you can see, REST API standard is pretty much self-documenting, which adds to its user friendliness.&lt;/p&gt;

&lt;p&gt;Now let us look at an example of a chat application.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We know that HTTP is a client-driven protocol, so the server cannot initiate any contact with the client. It can only respond to the client upon receiving a request. So when U1 sends a message to U2 via chat server, U2 doesn’t receive the message until it asks the server to share any pending messages. This leads to a delay when receiving messages.&lt;/p&gt;

&lt;p&gt;A solution to this would be that U2 sends frequent requests to the chat server in the hopes of receiving a message. But this puts a huge load on the chat server as it will receive a huge number of requests from all its clients.&lt;/p&gt;

&lt;p&gt;The best approach would be &lt;strong&gt;if the server could send a notification to the user every time there is a message&lt;/strong&gt;. For this, we use a protocol called &lt;strong&gt;WebSocket&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;(서버가 U2에게 보낼 메시지를 가지고 있음에도 불구하고, 능동적으로 U2에게 보내지 않는다. U2로부터 request를 받을때까지 기다린다.)&lt;br /&gt;
(U2는 언제 자신이 받아야할 메시지가 서버에 도착했는지 모르므로, 계속 서버에 request를 보내야 한다.)&lt;br /&gt;
(WebSocket을 사용하면 서버는 U2와 connection되어 있으면 request를 받지 않아도 알아서 U2에 메시지를 보낸다)&lt;br /&gt;
(connection되어 있지 않으면, 가만히 있다가, connection되고 U2가 request보내면 메시지 보낸다)&lt;br /&gt;
(WebSocket에도 단점은 있다. cost of maintaining a persistent connection with millions of users.)&lt;/p&gt;

&lt;h2 id=&quot;websocket&quot;&gt;WebSocket&lt;/h2&gt;
&lt;p&gt;A WebSocket connection is a persistent connection. It is also a bidirectional protocol, where communication can be initiated by the client or the server as long as there is an open connection. It is &lt;strong&gt;optimized for high-frequency communication&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Let’s look at how our chat application would work in the case of WebSocket protocol.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;First, U1 and U2 will establish HTTP connections with the chat server, which are then upgraded to a WebSocket connection. When U1 sends a message for U2 via the chat server, it will store the message along with its status, RECEIVED, let’s say.&lt;/p&gt;

&lt;p&gt;The chat server, if it has an open connection with U2, will then send the message to U2 and update the status to SENT. If U2 was not online and there was no open connection between U2 and the server, the messages will be saved until U2 comes online and requests the server to send all pending messages. The server will send all messages with the status RECEIVED and update the status to SENT.&lt;/p&gt;

&lt;p&gt;As you can see, with this approach we have:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Reduced the latency, since the server can simply send the messages over an open connection&lt;/li&gt;
  &lt;li&gt;Saved on CPU and bandwidth, as the client doesn’t need to unnecessarily send requests to the server and the server is not under unnecessary load&lt;/li&gt;
  &lt;li&gt;Provided better user experience&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Even with the benefits, there is a high cost to using WebSockets; that is the cost of maintaining a persistent connection with millions of users.&lt;/p&gt;

&lt;p&gt;So how do we decide whether to use HTTP or WebSocket? Do we always go for Websocket then? Well, not really, as WebSocket is much more expensive than HTTP. We can safely say, if the communication between client and server is at a &lt;strong&gt;lower throughput on the client-side&lt;/strong&gt;, HTTP is the way to go. &lt;strong&gt;If the communication is always client-driven&lt;/strong&gt;, WebSocket is not needed. Also, if you are on a &lt;strong&gt;tight budget&lt;/strong&gt;, HTTP may be the better choice.&lt;/p&gt;

&lt;p&gt;On the other hand, if the communication from the &lt;strong&gt;client is at a higher throughput&lt;/strong&gt;, WebSocket may be a better option. If the &lt;strong&gt;communication can be driven by both client and server&lt;/strong&gt;, WebSocket is the way to go. Although here comes the tradeoff between cost and performance. We must decide if the optimization is really worth the huge cost of maintaining persistent connections with so many users.&lt;/p&gt;
</description>
                <pubDate>Tue, 26 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/data-engineering-series21</link>
                <guid isPermaLink="true">http://localhost:4000/data-engineering-series21</guid>
                
                <category>Data_Engineering</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Data Engineering Series [Part20]: 시스템 디자인(1) Intro + Architecture</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#intro&quot; id=&quot;markdown-toc-intro&quot;&gt;Intro&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#what-will-be-covered&quot; id=&quot;markdown-toc-what-will-be-covered&quot;&gt;What will be covered?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#high-level-system-design&quot; id=&quot;markdown-toc-high-level-system-design&quot;&gt;High Level System Design&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#low-level-system-design-code-quality&quot; id=&quot;markdown-toc-low-level-system-design-code-quality&quot;&gt;Low Level System Design (Code Quality)&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#application-architecture&quot; id=&quot;markdown-toc-application-architecture&quot;&gt;Application Architecture&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#monolithic-architecture&quot; id=&quot;markdown-toc-monolithic-architecture&quot;&gt;Monolithic Architecture&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#microservice-architecture&quot; id=&quot;markdown-toc-microservice-architecture&quot;&gt;Microservice Architecture&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot; id=&quot;markdown-toc-conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h1 id=&quot;intro&quot;&gt;Intro&lt;/h1&gt;

&lt;h2 id=&quot;what-will-be-covered&quot;&gt;What will be covered?&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Introduction to System Design: Start with an introduction of the course, explanations on high level and low level design, interviewer’s expectations, and how to approach these kind in an interview.&lt;/li&gt;
  &lt;li&gt;System Design Basics: Build a strong foundation of System Design fundamentals that are useful in understanding the dynamics of highly scalable systems.&lt;/li&gt;
  &lt;li&gt;System Design Case Studies: Cover the 11 most frequently asked interview questions with a detailed walkthrough.&lt;/li&gt;
  &lt;li&gt;Problem Solving: Apply your understanding of the preceding chapters with the help of some practice problems and quizzes.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;high-level-system-design&quot;&gt;High Level System Design&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Overall architecture&lt;/strong&gt;: How the system can be built such that it takes care of scalability, latency, and other performance requirements&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Components and services&lt;/strong&gt;: Any system is a collection of various services and other components interacting with each other. In this part of high level design, we need to decide how the system will be broken down, what will the microservices be, and their scope.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Interaction between the systems&lt;/strong&gt;: How will the systems interact with each other? What protocols will you use? Will it be synchronous or asynchronous? You need to make these decisions based on the requirements.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Databases&lt;/strong&gt;: What databases will you need? What kind of data do you need to store? SQL or NoSQL, what will be the database schema? Depending on how much detail the interviewer wants you to go into, you may have to make these decisions as well.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;low-level-system-design-code-quality&quot;&gt;Low Level System Design (Code Quality)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: If you’re trying to build a web server, define your APIs clearly. For example, if you decide to make REST APIs, ensure they follow REST standards. Similarly, if you are building a library, define the APIs in a very clean manner as publicly accessible functions such that the client can easily integrate them&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Test Code&lt;/strong&gt;: This means we should have a working code with some basic test cases that are passing for the logic we have written.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Modular&lt;/strong&gt;: how easy it is to add new features without interfering with existing code.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;application-architecture&quot;&gt;Application Architecture&lt;/h1&gt;

&lt;h2 id=&quot;monolithic-architecture&quot;&gt;Monolithic Architecture&lt;/h2&gt;

&lt;p&gt;Back when the internet was just starting to gain popularity, websites used to serve mostly static content. There wasn’t a lot of user interaction like we see now. The applications were much less complex, and so was their architecture. A single application used to take care of the entire user journey, everything from UI rendering to backend business logic to fetching the data from DBs or File Systems. This was the world of Web 1.0.&lt;/p&gt;

&lt;p&gt;Then came Web 2.0 with social networks, e-commerce, and online gaming and things became a lot more interactive. By this time everything was still maintained in a single huge codebase. If you consider an e-commerce system, back then everything from UI to business logic for payments, carts, orders, etc. was maintained in a single codebase. This is known as Monolithic Architecture.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The problem with this approach was that the code was very complex, difficult to maintain, and hard to iterate and improve. On top of that, multiple people were working on the same codebase; it was a recipe for disaster.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Disadvantage of Monolithic Architecture&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;One of the most common problems with monoliths is that you are &lt;strong&gt;bound to a single technology stack&lt;/strong&gt;. Suppose you have a monolith built on Java with Spring framework. Now you need to add some Machine Learning logic, and you want to use Python for it. That is nearly impossible in monolithic architecture. You either need to figure out a way to do this with Java, or you need a standalone application that handles your machine learning logic, which defeats the purpose of a monolithic app.&lt;/li&gt;
  &lt;li&gt;Another problem would be that it is very &lt;strong&gt;easy to break&lt;/strong&gt; things in such an architecture. That is because, when you have such a huge codebase, it is nearly impossible for everyone to know everything about how the entire system works. If you change some logic in the shared code, you might end up breaking someone else’s feature. Sure you can have test cases, but even those are not enough sometimes.&lt;/li&gt;
  &lt;li&gt;Another major issue is scalability. It is very &lt;strong&gt;tricky to scale a monolithic application&lt;/strong&gt;. Let us look at the example of an e-commerce application. In case of a Black Friday sale, you might need to scale your payments and cart modules, but Warehouse and Notification modules can continue to work at the same pace. This cannot be done in a monolithic app. Since it is the same codebase, you will need to deploy the entire system again and again. This means the capacity meant for the Warehouse module might be sitting idle or that the Payment and Cart modules may choke the rest of the system.&lt;/li&gt;
  &lt;li&gt;Deployments are also a very tedious process here. Since the code is huge, it takes &lt;strong&gt;much longer to build&lt;/strong&gt;, package, and deploy the code. That said, if you update the code for Warehousing, even the Payments module must be redeployed since everything is packaged together.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;microservice-architecture&quot;&gt;Microservice Architecture&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/system_design_2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The idea is to break down the application into logical components such that these components become services of their own. Normally this is also how the teams would be structured, so each team would work on the services that handle their features. These services will now be communicating with each other via a set of API calls like REST APIs or Remote Procedure Calls.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Benefits of Microservice Architecture&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We are not bound to a single technology stack anymore. Different services can use different languages or databases as needed.&lt;/li&gt;
  &lt;li&gt;Each system does one thing and does it well, without worrying about breaking another set of features.&lt;/li&gt;
  &lt;li&gt;Engineers will be working on and maintaining a smaller codebase.&lt;/li&gt;
  &lt;li&gt;Iterating, deploying, and testing becomes a lot easier.&lt;/li&gt;
  &lt;li&gt;Unlike in monolith, we can now independently scale up Cart and Payments Services, and the rest of the services can continue working as they are. This ensures optimized use of resources and makes auto-scaling a lot easier.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantage of Microservice Architecture&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Latency
    &lt;ul&gt;
      &lt;li&gt;One of the key reasons is latency. Function calls are faster than API calls, so it makes sense that monoliths will have lower latency. Usually, this latency is not high enough to be noticed by the user, but if you are working on something that needs a response in a few microseconds then you should definitely think about using monolithic architecture.&lt;/li&gt;
      &lt;li&gt;With network calls comes the possibility of network failures and slightly increases the complexity of error handling and retries.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Backward Compatibility
    &lt;ul&gt;
      &lt;li&gt;If a service needs a new mandatory parameter and the other services have not made the change accordingly, certain flows will break.&lt;/li&gt;
      &lt;li&gt;In monolith it will be caught in the development phase since the compiler will throw an error. To solve this we need some good automated test cases.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Logging
    &lt;ul&gt;
      &lt;li&gt;If you need to trace logs for a user in monoliths, it is easy to do so as they are all in the same place. But in microservices, for each request from the user there will be multiple service calls.&lt;/li&gt;
      &lt;li&gt;In the below example, consider a single request from the user to the order service. The order service is talking to Inventory, Payment, Warehouse, and Notification Services, and thus there will be logs in each of these services. So tracing exactly what happened becomes very difficult as we need to check logs in each system.&lt;/li&gt;
      &lt;li&gt;A better approach would be to store all the logs in a central place where they can be queried. This is a cost since you either need to build a Log Aggregation System or buy a third-party system’s license.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;In conclusion, if you are a small business working with a small team and have a limited set of features, monolith might be a better approach for you. However, if you are working on a huge product with hundreds of microservices, the maintenance cost of microservices will be worthwhile.&lt;/p&gt;

&lt;p&gt;Also, usually, when you think about HLD(High Level Design) interviews, chances are you will be developing an overall architecture for a complex system that might be difficult to design in a monolithic manner. So thinking in terms of microservices will be a good idea.&lt;/p&gt;
</description>
                <pubDate>Tue, 26 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/data-engineering-series20</link>
                <guid isPermaLink="true">http://localhost:4000/data-engineering-series20</guid>
                
                <category>Data_Engineering</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Data Engineering Series [Part19]: 로그 구조 스토리지</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;
</description>
                <pubDate>Mon, 25 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/data-engineering-series19</link>
                <guid isPermaLink="true">http://localhost:4000/data-engineering-series19</guid>
                
                <category>Data_Engineering</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Data Engineering Series [Part18]: APIs</title>
                <description>&lt;hr /&gt;

&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#event-driven-api&quot; id=&quot;markdown-toc-event-driven-api&quot;&gt;Event Driven API&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#web-api&quot; id=&quot;markdown-toc-web-api&quot;&gt;Web API&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;event-driven-api&quot;&gt;Event Driven API&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Webhooks&lt;/li&gt;
  &lt;li&gt;Websockets&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;web-api&quot;&gt;Web API&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;REST&lt;/li&gt;
  &lt;li&gt;RPC&lt;/li&gt;
  &lt;li&gt;GraphQL&lt;/li&gt;
&lt;/ul&gt;
</description>
                <pubDate>Sun, 24 Jul 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/data-engineering-series18</link>
                <guid isPermaLink="true">http://localhost:4000/data-engineering-series18</guid>
                
                <category>Data_Engineering</category>
                
                
                <category>DE</category>
                
            </item>
        
    </channel>
</rss>