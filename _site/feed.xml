<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Jay Tech</title>
        <description>Jay Tech personal blogging theme for Jekyll</description>
        <link>http://localhost:4000/</link>
        <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
        <pubDate>Sun, 27 Feb 2022 13:11:03 +0900</pubDate>
        <lastBuildDate>Sun, 27 Feb 2022 13:11:03 +0900</lastBuildDate>
        <generator>Jekyll v4.2.1</generator>
        
            <item>
                <title>Apache Spark Series [Part6]: 스파크 SQL</title>
                <description>&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;
</description>
                <pubDate>Tue, 22 Feb 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/spark-series6</link>
                <guid isPermaLink="true">http://localhost:4000/spark-series6</guid>
                
                <category>Spark</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Apache Spark Series [Part5]: 스파크 데이터프레임(DataFrame)</title>
                <description>&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;
</description>
                <pubDate>Tue, 22 Feb 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/spark-series5</link>
                <guid isPermaLink="true">http://localhost:4000/spark-series5</guid>
                
                <category>Spark</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Apache Spark Series [Part4]: 스파크의 클러스터 매니저(Cluster Manager)</title>
                <description>&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#스탠드얼론&quot; id=&quot;markdown-toc-스탠드얼론&quot;&gt;스탠드얼론&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#얀&quot; id=&quot;markdown-toc-얀&quot;&gt;얀&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#메소스&quot; id=&quot;markdown-toc-메소스&quot;&gt;메소스&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#쿠버네티스&quot; id=&quot;markdown-toc-쿠버네티스&quot;&gt;쿠버네티스&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;스탠드얼론&quot;&gt;스탠드얼론&lt;/h1&gt;

&lt;h1 id=&quot;얀&quot;&gt;얀&lt;/h1&gt;

&lt;h1 id=&quot;메소스&quot;&gt;메소스&lt;/h1&gt;

&lt;h1 id=&quot;쿠버네티스&quot;&gt;쿠버네티스&lt;/h1&gt;
</description>
                <pubDate>Tue, 22 Feb 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/spark-series4</link>
                <guid isPermaLink="true">http://localhost:4000/spark-series4</guid>
                
                <category>Spark</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>Apache Spark Series [Part3]: 스파크의 분산처리 동작원리</title>
                <description>&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#클러스터-환경&quot; id=&quot;markdown-toc-클러스터-환경&quot;&gt;클러스터 환경&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#스파크의-분산처리-아키텍처&quot; id=&quot;markdown-toc-스파크의-분산처리-아키텍처&quot;&gt;스파크의 분산처리 아키텍처&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#스파크-애플리케이션-동작-순서&quot; id=&quot;markdown-toc-스파크-애플리케이션-동작-순서&quot;&gt;스파크 애플리케이션 동작 순서&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#참고&quot; id=&quot;markdown-toc-참고&quot;&gt;참고&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h1 id=&quot;클러스터-환경&quot;&gt;클러스터 환경&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;스파크는 본질적으로 분산처리 프레임워크&lt;/strong&gt;입니다. 그래서 단순히 테스트를 위한 용도로는 단일 로컬 서버만으로도 가능하지만, 실제 배포 단계에서 스파크를 제대로 활용하기 위해서는 여러 대의 서버를 이용한 클러스터 환경을 구축할 필요가 있습니다.&lt;/p&gt;

&lt;p&gt;클러스터란 여러 대의 서버가 네트워크를 통해 연결되어 마치 하나의 서버인 것처럼 동작하는 방식을 의미합니다. 하지만 여러 서버들을 이 같은 방식으로 동작시키는 것은 쉬운 일이 아닙니다. 그래서 스파크에서는 전체 서버의 자원과 동작을 세밀하고 효율적으로 제어할 수 있는 별도 모듈이 필요한데, 이를 &lt;strong&gt;클러스터 매니저&lt;/strong&gt;라고 합니다.&lt;/p&gt;

&lt;p&gt;스파크에서는 자체 구현한 클러스터 매니저도 제공하고 외부 클러스터 매니저를 임포트해서 사용할 수도 있습니다. 이렇게 여러 종류의 클러스터 매니저를 지원하게 되면 선택의 폭이 넓어진다는 장점도 있긴 하지만 클러스터 매니저마다 동작 방식이나 용어가 다르면 혼동이 될 수 있습니다. 스파크에서는 이런 혼란을 없애고자 추상화된 클러스터 모델을 제공함으로써 사용하는 클러스터의 종류에 관계없이 일관된 방법으로 프로그램을 작성하고 클러스터를 관리할 수 있게 해줍니다.&lt;/p&gt;

&lt;p&gt;내용에 들어가기 전에 한 가지 알아둘 것은 클러스터 환경이라고 해서 로컬 환경에서 사용하던 스파크 애플리케이션 &lt;strong&gt;코드를 새로 작성해야 할 필요는 없습니다.&lt;/strong&gt; 다만 클러스터 환경에서는 여러 서버를 마치 하나의 서버인 것처럼 다뤄야 하기 때문에 하나의 작업을 여러 서버에 분산해서 실행하고 그 결과를 취합할 수 있는 &lt;strong&gt;분산 작업 관리 기능이 추가&lt;/strong&gt;되어야 할 것입니다.&lt;/p&gt;

&lt;p&gt;따라서 이번 포스트의 목적은 &lt;strong&gt;분산처리를 위한 시스템 아키텍처를 이해&lt;/strong&gt;하고, 이를 구현하기 위해 &lt;strong&gt;필요한 설정과 매개변수를 이해&lt;/strong&gt;하는 것입니다.&lt;/p&gt;

&lt;h1 id=&quot;스파크의-분산처리-아키텍처&quot;&gt;스파크의 분산처리 아키텍처&lt;/h1&gt;

&lt;p&gt;아래 그림은 분산처리를 위한 스파크의 전형적인 아키텍처입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/../../images/spark_5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;보시다시피 클러스터 매니저는 가운데에서 분산처리를 위한 매니저 역할을 하고 있습니다. 각각의 컴포넌트에 대한 설명은 &lt;a href=&quot;https://jaykim0510.github.io/spark-series1&quot;&gt;&lt;strong&gt;앞의 포스트&lt;/strong&gt;&lt;/a&gt;에서 다룬 적이 있음으로 여기서는 간단하게만 요약하도록 하겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;드라이버 프로그램&lt;/strong&gt;: 스파크 컨텍스트를 생성하고 클러스터 매니저와 연결시켜주는 프로그램&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;스파크 컨텍스트&lt;/strong&gt;: 클러스터와 연결되는 객체로 스파크 애플리케이션 코드를 작성하는데 필요한 거의 모든 기능을 제공&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;클러스터 매니저&lt;/strong&gt;: 워커 노드를 모니터링하며 최적의 자원(CPU, 메모리) 할당&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;워커 노드&lt;/strong&gt;: 분산된 데이터를 할당받고 요청된 작업을 처리하는 서버&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;익스큐터&lt;/strong&gt;: 작업을 수행하기 위해 스파크에서 실행하는 프로세스, 자원할당 단위&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;태스크&lt;/strong&gt;: 액션 연산의 수&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;스파크 클러스터는 이와 같이 드라이버, 클러스터 매니저, 워커 노드의 조합으로 구성됩니다. 여기서 실행 모드, 클러스터 매니저의 종류에 따라 약간의 다른 점이 있지만 큰 맥락에서는 같습니다.&lt;/p&gt;

&lt;p&gt;실행 모드의 경우 두 가지가 있습니다. 클러스터 모드, 클라이언트 모드입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/../../images/spark_13.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;두 모드 가운데 어떤 것을 선택하든 수행 결과는 동일합니다. 하지만 &lt;strong&gt;클러스터 모드의 경우&lt;/strong&gt; 드라이버 프로그램과 익스큐터 간의 네트워크 비용이 상대적으로 낮아져서 &lt;strong&gt;성능 향상&lt;/strong&gt;을 기대할 수 있습니다. 하지만 스파크 셸과 같은 인터랙티브 환경을 이용한 &lt;strong&gt;디버깅이 어려워&lt;/strong&gt;서 정형화된 작업에만 주로 사용하고, &lt;strong&gt;클라이언트 모드의 경우&lt;/strong&gt; 사용성이 &lt;strong&gt;편리&lt;/strong&gt;하지만 드라이버 프로그램과 워커 노드가 네트워크 상에서 너무 많이 떨어져 있으면 전체적인 성능에 영향을 줄 수 있으므로 &lt;strong&gt;가급적 동일 네트워크 상에 존재하는 서버로 선택&lt;/strong&gt;하는 것이 좋습니다.&lt;/p&gt;

&lt;p&gt;클러스터 매니저에 대해서는 다음 포스트에서 조금 더 자세히 다루도록 하겠습니다.&lt;/p&gt;

&lt;h1 id=&quot;스파크-애플리케이션-동작-순서&quot;&gt;스파크 애플리케이션 동작 순서&lt;/h1&gt;

&lt;h1 id=&quot;참고&quot;&gt;참고&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://sparkbyexamples.com/spark/spark-sparkcontext/&quot; target=&quot;_blank&quot;&gt;What is SparkContext? Explained&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
                <pubDate>Mon, 21 Feb 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/spark-series3</link>
                <guid isPermaLink="true">http://localhost:4000/spark-series3</guid>
                
                <category>Spark</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>BlockChain Series [Part2]: 블록체인의 동작 원리</title>
                <description>&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;
</description>
                <pubDate>Mon, 21 Feb 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/blockchain-series1</link>
                <guid isPermaLink="true">http://localhost:4000/blockchain-series1</guid>
                
                <category>Blockchain_basic</category>
                
                
                <category>Blockchain</category>
                
            </item>
        
            <item>
                <title>Apache Spark Series [Part2]: 스파크 개발환경 구축하기</title>
                <description>&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#스파크-설치&quot; id=&quot;markdown-toc-스파크-설치&quot;&gt;스파크 설치&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#pyspark&quot; id=&quot;markdown-toc-pyspark&quot;&gt;pyspark&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#자바-파이썬-설치&quot; id=&quot;markdown-toc-자바-파이썬-설치&quot;&gt;자바, 파이썬 설치&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#pyspark-설치&quot; id=&quot;markdown-toc-pyspark-설치&quot;&gt;pyspark 설치&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#spark&quot; id=&quot;markdown-toc-spark&quot;&gt;Spark&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#로컬-개발-환경&quot; id=&quot;markdown-toc-로컬-개발-환경&quot;&gt;로컬 개발 환경&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#클러스터-환경&quot; id=&quot;markdown-toc-클러스터-환경&quot;&gt;클러스터 환경&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#참고&quot; id=&quot;markdown-toc-참고&quot;&gt;참고&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;스파크-설치&quot;&gt;스파크 설치&lt;/h1&gt;
&lt;p&gt;스파크를 설치하는 과정 자체는 크게 복잡하지 않습니다. &lt;strong&gt;자바와 스파크만 설치&lt;/strong&gt;하면 스파크를 사용할 수 있습니다. 자바가 필요한 이유는 스파크가 JVM 위에서 실행되기 때문입니다.&lt;/p&gt;

&lt;p&gt;하지만 실무에서는 대부분의 빅데이터 소프트웨어들이 클러스터 환경에서 동작하기 때문에 제대로 활용하기 위해서는 여러 가지 준비할 것도 많고 설정해야 할 것들도 많습니다. 그래서 스파크는 &lt;strong&gt;개발/테스트를 위한 용도로 간단하게 사용할 때에는 단독 서버에서 동작하는 로컬 모드를, 배포를 위한 용도로 클라이언트, 클러스터 모드를 지원&lt;/strong&gt;합니다.&lt;/p&gt;

&lt;p&gt;스파크 애플리케이션 코드는 &lt;strong&gt;자바, 스칼라, 파이썬, R&lt;/strong&gt;언어로 작성할 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;pyspark&quot;&gt;pyspark&lt;/h2&gt;
&lt;p&gt;우선 저는 파이썬을 주언어로 사용하기 때문에 pyspark를 이용해 파이썬으로 스파크 애플리케이션 코드를 작성할 예정입니다. pyspark의 장점은 만약 개발/테스트를 위한 목적으로만 스파크를 사용할 예정이라면 스파크를 설치할 필요가 없다는 것입니다. 스파크를 사용하는데 스파크를 설치할 필요가 없다? 무슨 뜻이냐면 pyspark를 설치하기만 해도 스파크를 실행하기 위해 필요한 최소한의 파일을 함께 설치해줍니다.&lt;/p&gt;

&lt;p&gt;하지만 여전히 자바는 설치해주어야 합니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;To run Spark, you only require a Java runtime environment (JRE) but you may also download the Java development kit (JDK) which includes the JRE.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;저는 &lt;strong&gt;파이썬이 설치되어 있는 도커 이미지를 이용해 컨테이너 안에서 실습&lt;/strong&gt;을 진행해 보았습니다.&lt;/p&gt;

&lt;h3 id=&quot;자바-파이썬-설치&quot;&gt;자바, 파이썬 설치&lt;/h3&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 파이썬이 설치된 컨테이너 생성&lt;/span&gt;
docker run &lt;span class=&quot;nt&quot;&gt;-it&lt;/span&gt; python:3.8-buster
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# JDK 설치&lt;/span&gt;
apt-get update
apt-get &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;openjdk-11-jdk
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# JAVA_HOME 변수 설정, 경로 추가&lt;/span&gt;


&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/etc/openjdk-11-jdk     &lt;span class=&quot;c&quot;&gt;# 본인의 자바 설치 경로&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$JAVA_HOME&lt;/span&gt;/bin:&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; /etc/profile &lt;span class=&quot;c&quot;&gt;# bash쉘이면 source /etc/profile&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;pyspark-설치&quot;&gt;pyspark 설치&lt;/h3&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# pyspark 설치&lt;/span&gt;
pip &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;pyspark
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 잘 설치되었는지 확인
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pyspark&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pyspark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SparkContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;appName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SparkContext&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;--------------------------------&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;SparkContext&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Version&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;v3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Master&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;local&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AppName&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;SparkContext&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;spark&quot;&gt;Spark&lt;/h2&gt;
&lt;p&gt;이번에는 파이썬에 국한되지 않는 조금 더 일반적인 방법으로 스파크를 설치해보겠습니다. 이번에는 리눅스 운영체제만 가지는 컨테이너 위에서 실습을 진행하도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;처음에는 우분투 이미지를 바로 컨테이너로 띄우고 그 위에서 자바를 설치하려 했지만, 오라클에서 다운받는 방법을 제한하고 있어서 아래의 방법으로 진행했습니다. (우분투 이미지에 로컬에서 다운받은 자바를 하나의 이미지로 새로 빌드)&lt;/p&gt;

&lt;p&gt;그래서 사실 위에서 진행한 pyspark만 설치하는 방법에서도 python이미지에 로컬 자바로 한 번 이미지를 빌드한 후 사용하는 것이 좋을 것 같습니다. 저도 아직 본격적으로 사용해보지는 않아서 에러가 있는지는 확인해보지 않았지만 로컬에서 자바를 다운 받고 빌드하는 방법은 확실히 안전합니다.&lt;/p&gt;

&lt;p&gt;🦊 &lt;strong&gt;자바 설치&lt;/strong&gt;&lt;br /&gt;
자바 라이센스를 소유하고 있는 오라클에서 2019년 4월부터 자바를 외부의 허용하지 않은 방법으로 다운받는 것을 금지시켰습니다. 그래서 wget과 같은 방식으로 자바8 버전을 더이상 다운받을 수 없게 되고 무조건 오라클에 로그인을 한 후 로컬에 먼저 다운을 받아야합니다. &lt;del&gt;자바 17은 가능한데 스파크에서 자바 17로 설치하니까 오류가 난다. 구글링에서는 자바를 다운그레이드 하라고 나와있다. 자바8로 해보니까 된다. 그래서 자바8을 지금 다운 받으려고 하는 것이다.&lt;/del&gt;그래서 저같은 경우에는 왠만한 작업들은 무조건 도커 컨테이너에서 진행하는 편이라 처음에는 도커허브에서 자바8이 설치되어 있는 이미지를 찾아봤지만 뭔가 세부설정들이 마음에 들지 않게 되어 있어서 이미지를 직접 빌드하기로 결정했습니다. 제가 사용한 방법의 과정은 다음과 같습니다.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 자바를 로컬에 다운로드&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 다운로드 페이지 접속&lt;/span&gt;
https://www.oracle.com/java/technologies/javase/javase8u211-later-archive-downloads.html

&lt;span class=&quot;c&quot;&gt;# 저는 M1 칩을 사용하고 있어서 ARM64 전용 파일을 다운로드 받았습니다.&lt;/span&gt;
jdk-8u311-linux-aarch64.tar.gz

&lt;span class=&quot;c&quot;&gt;# 다운로드 받은 폴더에서 압축해제&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;tar&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-xzvf&lt;/span&gt; jdk-8u311-linux-aarch64.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;language-Dockerfile highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Dockerfile 작성&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 로컬에 설치한 자바를 컨테이너로 옮기고 스파크까지 설치해주었습니다&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; ubuntu:latest&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; jdk1.8.0_321 ./jdk1.8.0_321&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;apt-get &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; update &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;vim &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;wget &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; wget https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz &lt;span class=&quot;se&quot;&gt;\
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;tar&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-xzvf&lt;/span&gt; spark-3.2.1-bin-hadoop3.2.tgz
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vim /etc/profile

&lt;span class=&quot;c&quot;&gt;# 환경 변수설정해줍니다. 이부분은 Dockerfile에서 ENV로 설정해 줄 수도 있습니다&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/jdk1.8.0_321
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$JAVA_HOME&lt;/span&gt;/bin:&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; /etc/profile
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;spark-3.2.1-bin-hadoop3.2
&lt;span class=&quot;nb&quot;&gt;ls&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--------------------------------------------------------------------------------------------------------------&lt;/span&gt;
LICENSE  NOTICE  R  README.md  RELEASE  bin  conf  data  examples  jars  kubernetes  licenses  python  sbin  yarn
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 스파크에서 제공하는 실행 파일
cd bin
ls
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;../images/../../images/spark_9.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 스파크 셸 실행&lt;/span&gt;
./bin/spark-shell

&lt;span class=&quot;c&quot;&gt;# 셸 종료&lt;/span&gt;
:q
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;../images/../../images/spark_8.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 과정은 이미지에서 매번 스파크를 다운받는 방식이기 때문에, 스파크를 다운받은 컨테이너를 다시 한 번 이미지로 만들면 그 다음부터는 새로 만든 이미지를 이용하면 컨테이너를 띄우는 속도가 더 빨라지게 됩니다. 그래서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docker commit&lt;/code&gt; 명령어를 이용해 한번 더 이미지를 빌드하는 것을 권장드립니다.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 로컬 터미널에서 docker commit 명령어로 이미지 생성&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# dockere commit &amp;lt;원하는 컨테이너 이름&amp;gt; &amp;lt;생성할 이미지 이름&amp;gt;&lt;/span&gt;
docker commit thirsty_galois spark_container
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;로컬-개발-환경&quot;&gt;로컬 개발 환경&lt;/h1&gt;
&lt;p&gt;위의 설치과정을 완료한 후 스파크의 설정 정보를 확인해 보겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./bin/spark-shell --verbose
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;../images/../../images/spark_11.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;다른 부분은 일단 신경쓰지 말고 master 부분만 보도록 하겠습니다. 현재 master가 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;local[*]&lt;/code&gt;로 설정되어 있습니다. 이는 현재 드라이버 프로그램을 실행하는 서버를 포함해 워커 노드까지 모두 로컬 서버를 이용하고 있다는 뜻입니다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;*&lt;/code&gt;는 로컬 서버의 모든 스레드를 사용하겠다는 뜻입니다.&lt;/p&gt;

&lt;p&gt;따라서 여기까지만 설정하게 되면 로컬에서 테스트 목적으로 사용하기 위한 최소한의 준비는 끝난 것입니다. 이 외에도 여러 가지 설정들을 직접하고 싶을 때에는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;./conf&lt;/code&gt;에 설정을 위한 여러가지 파일의 템플릿을 이용할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/../../images/spark_12.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;클러스터-환경&quot;&gt;클러스터 환경&lt;/h1&gt;

&lt;h1 id=&quot;참고&quot;&gt;참고&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/61816236/does-pyspark-code-run-in-jvm-or-python-subprocess&quot; target=&quot;_blank&quot;&gt;Pyspark 코드는 어디서 실행되는가?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/51728177/can-pyspark-work-without-spark&quot; target=&quot;_blank&quot;&gt;Pyspark만으로 스파크 애플리케이션 실행할 수 있나?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/58479357/pyspark-from-spark-installation-vs-pyspark-python-package&quot; target=&quot;_blank&quot;&gt;Pyspark의 한계&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://askubuntu.com/questions/1363992/bin-sh-1-source-not-found&quot; target=&quot;_blank&quot;&gt;bin/sh: 1: source: not found&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://unit-15.tistory.com/114?category=521121#recentComments&quot; target=&quot;_blank&quot;&gt;[Linux] 우분투에 자바 설치&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://superuser.com/questions/1466580/unable-to-download-oracle-jdk-8-using-wget-command&quot; target=&quot;_blank&quot;&gt;Unable to download Oracle JDK 8 using Wget command&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nhj12311.tistory.com/37&quot; target=&quot;_blank&quot;&gt;자바(JDK, JRE) 모든 버전 다운로드( 6,7,8,9,10,11,12,13,14,15, 16, 17..)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.quobyte.com/enterprise-analytics/howto-spark-quobyte-multinode&quot; target=&quot;_blank&quot;&gt;How to Set Up a Multi Node Apache Spark Cluster with Quobyte&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.ibm.com/docs/en/zpfas/1.1.0?topic=structure-updating-apache-spark-configuration-files&quot; target=&quot;_blank&quot;&gt;Updating the Apache Spark configuration files&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://velog.io/@somnode/spark-cluster-install&quot; target=&quot;_blank&quot;&gt;[spark] Spark 3 클러스터 설치&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
                <pubDate>Sun, 20 Feb 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/spark-series2</link>
                <guid isPermaLink="true">http://localhost:4000/spark-series2</guid>
                
                <category>Spark</category>
                
                
                <category>DE</category>
                
            </item>
        
            <item>
                <title>HyperLedger Fabric Series [Part1]: What is HyperLedger Fabric?</title>
                <description>&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;
</description>
                <pubDate>Sun, 20 Feb 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/hyperledger_fabric-series0</link>
                <guid isPermaLink="true">http://localhost:4000/hyperledger_fabric-series0</guid>
                
                <category>Hyperledger_fabric</category>
                
                
                <category>Blockchain</category>
                
            </item>
        
            <item>
                <title>Development Knowledge Series(2): Java 관련 용어</title>
                <description>&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;아직 글을 작성 중입니다.&lt;/p&gt;

&lt;p&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/f0cAmTYo4tQ&quot; width=&quot;640&quot; height=&quot;360&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/p&gt;

&lt;p&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/L19wXSpv5cs&quot; width=&quot;640&quot; height=&quot;360&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/p&gt;
</description>
                <pubDate>Sun, 20 Feb 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/dev_know-series2</link>
                <guid isPermaLink="true">http://localhost:4000/dev_know-series2</guid>
                
                <category>Java</category>
                
                
                <category>Development_knowledge</category>
                
            </item>
        
            <item>
                <title>Development Knowledge Series(1): Scripting Language vs Compile Language</title>
                <description>&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;https://well-made-codestory.tistory.com/30?category=978350&lt;/p&gt;
</description>
                <pubDate>Sun, 20 Feb 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/dev_know-series1</link>
                <guid isPermaLink="true">http://localhost:4000/dev_know-series1</guid>
                
                <category>Javascript</category>
                
                <category>Python</category>
                
                <category>Java</category>
                
                
                <category>Development_knowledge</category>
                
            </item>
        
            <item>
                <title>BlockChain Series [Part1]: 블록체인을 공부하기 전에</title>
                <description>&lt;p id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#블록체인이란&quot; id=&quot;markdown-toc-블록체인이란&quot;&gt;블록체인이란&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#블록체인에-대한-오해&quot; id=&quot;markdown-toc-블록체인에-대한-오해&quot;&gt;블록체인에 대한 오해&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#블록체인-용어-바로-알기&quot; id=&quot;markdown-toc-블록체인-용어-바로-알기&quot;&gt;블록체인 용어 바로 알기&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#분산-vs-탈중앙화&quot; id=&quot;markdown-toc-분산-vs-탈중앙화&quot;&gt;분산 vs 탈중앙화&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#디지털화-vs-블록체인&quot; id=&quot;markdown-toc-디지털화-vs-블록체인&quot;&gt;디지털화 vs 블록체인&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#가상-화폐-vs-암호-화폐&quot; id=&quot;markdown-toc-가상-화폐-vs-암호-화폐&quot;&gt;가상 화폐 vs 암호 화폐&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#거래소-vs-중개소&quot; id=&quot;markdown-toc-거래소-vs-중개소&quot;&gt;거래소 vs 중개소&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#트랜잭션-vs-거래내역&quot; id=&quot;markdown-toc-트랜잭션-vs-거래내역&quot;&gt;트랜잭션 vs 거래내역&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#디지털-자산&quot; id=&quot;markdown-toc-디지털-자산&quot;&gt;디지털 자산&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#블록체인의-역사&quot; id=&quot;markdown-toc-블록체인의-역사&quot;&gt;블록체인의 역사&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#사이퍼펑크&quot; id=&quot;markdown-toc-사이퍼펑크&quot;&gt;사이퍼펑크&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#비트코인의-탄생&quot; id=&quot;markdown-toc-비트코인의-탄생&quot;&gt;비트코인의 탄생&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#블록-블록체인-비트코인&quot; id=&quot;markdown-toc-블록-블록체인-비트코인&quot;&gt;블록? 블록체인? 비트코인?&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#블록&quot; id=&quot;markdown-toc-블록&quot;&gt;블록&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#블록체인&quot; id=&quot;markdown-toc-블록체인&quot;&gt;블록체인&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#비트코인&quot; id=&quot;markdown-toc-비트코인&quot;&gt;비트코인&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#마치며&quot; id=&quot;markdown-toc-마치며&quot;&gt;마치며&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#참고&quot; id=&quot;markdown-toc-참고&quot;&gt;참고&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;블록체인이란&quot;&gt;블록체인이란&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;블록체인(blockchain)이란 다수의 거래내역을 묶어 블록을 구성하고, 해시를 이용하여 여러 블록들을 체인처럼 연결한 뒤, 다수의 사람들이 복사하여 분산 저장하는 알고리즘이다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;블록체인은 &lt;strong&gt;비트코인과 이더리움 등 암호화폐&lt;/strong&gt;에 사용된 핵심 기술이다. 은행 등 제3의 중개기관이 없더라도 블록체인 기술을 이용하면 누구나 신뢰할 수 있는 안전한 거래를 할 수 있다. 블록체인은 암호화폐뿐 아니라, 온라인 거래내역이 있고 이력관리가 필요한 모든 데이터 처리에 활용할 수 있다. 블록체인 기반의 &lt;strong&gt;스마트 계약, 물류관리 시스템, 문서관리 시스템, 의료정보관리 시스템, 저작권관리 시스템&lt;/strong&gt; 등 다양한 활용이 가능하다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/blockchain_basic_0.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;블록체인은 간략히 &lt;strong&gt;‘분산원장’(分散元帳, distributed ledger) 기술&lt;/strong&gt;이라고 한다. 즉, 거래내역을 기록한 원장을 다수의 사람들에게 분산하여 저장·관리하는 기술이다. 자세히 설명하면, 블록체인이란 다수의 온라인 거래 기록을 묶어 하나의 데이터 블록(block)을 구성하고, 해시(hash) 값을 이용하여 이전 블록과 이후 블록을 마치 체인(chain)처럼 연결한 뒤, 이 정보의 전부 또는 일부를 피투피(P2P) 방식으로 전 세계 여러 컴퓨터에 복사하여 분산 저장·관리하는 기술이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/blockchain_basic_1.png&quot; alt=&quot;&quot; width=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;블록체인에-대한-오해&quot;&gt;블록체인에 대한 오해&lt;/h1&gt;
&lt;p&gt;위의 내용은 &lt;a href=&quot;http://wiki.hash.kr/index.php/블록체인&quot; target=&quot;_blank&quot;&gt;(해시넷: 블록체인)&lt;/a&gt;에서 작성한 글의 일부를 가져온 것입니다.&lt;/p&gt;

&lt;p&gt;‘제 3자가 필요 없어지고, 이에 따라 수수료도 사라지는 이상적인 플랫폼’. 많은 사람들은 블록체인을 이용하면 그동안의 거래 시스템 전반에 많은 혁신을 가져다 줄 것으로 기대했습니다. &lt;strong&gt;하지만 현실은 그렇지 않았습니다. 블록체인의 등장은 그동안 불필요했던 새로운 형태의 중개인을 양산했고, 암호화폐 재단, 채굴업자, 중개소에 종속되며 빠르게 중앙화되어갔습니다&lt;/strong&gt;. 또한 독립적인 화폐를 내세웠던 암호 화폐는 선채굴을 악용한 채굴업자들이 암호화폐 대부분을 장악한 후 전 세계 중개소를 통해 일반인들을 선동, 호도하며 내다팔아 막대한 수익을 얻었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/blockchain_basic_2.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;저는 이번 BlockChain Series를 준비하며 앞으로 블록체인의 미래가 어떻게 될지 한 번 알아보려고 합니다.&lt;/p&gt;

&lt;h1 id=&quot;블록체인-용어-바로-알기&quot;&gt;블록체인 용어 바로 알기&lt;/h1&gt;

&lt;h2 id=&quot;분산-vs-탈중앙화&quot;&gt;분산 vs 탈중앙화&lt;/h2&gt;
&lt;p&gt;블록체인을 공부하다 보면 분산, 탈중앙화라는 단어가 많이 사용되는 것을 보게 됩니다. 하지만 블록체인과 일반적인 분산 시스템과는 약간 다른 점이 있습니다. &lt;strong&gt;분산 시스템은 데이터를 여러 노드에 분산해 나누어 처리하기 때문에 효율적입니다.&lt;/strong&gt; 하지만 &lt;strong&gt;블록체인은 같은 데이터(거래 내역 등)를 모든 노드가 중복 처리합니다. 이 방법은 데이터의 신뢰도를 높일 수는 있지만 비효율적입니다.&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;특징&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;분산&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;탈중앙화&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;저장&lt;/td&gt;
      &lt;td&gt;여러 노드에 분산 저장&lt;/td&gt;
      &lt;td&gt;여러 노드에 중복 저장&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;처리&lt;/td&gt;
      &lt;td&gt;여러 노드가 분산 처리&lt;/td&gt;
      &lt;td&gt;여러 노드가 중복 처리&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;장점&lt;/td&gt;
      &lt;td&gt;높은 효율성&lt;/td&gt;
      &lt;td&gt;높은 신뢰성&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;디지털화-vs-블록체인&quot;&gt;디지털화 vs 블록체인&lt;/h2&gt;
&lt;p&gt;블록체인을 공부하면서 블록체인의 장점으로 시스템의 효율성과 안전한 데이터 저장이라는 글을 본 적이 있습니다. 하지만 이는 디지털화(digitalization)의 장점이며 블록체인은 정확히 이것과 반대입니다. &lt;strong&gt;블록체인은 효율성을 포기하고 데이터의 신뢰성을 높인 것이며, 데이터는 보안되지 않고 모든 사용자에게 공개되어 저장됩니다.&lt;/strong&gt; 따라서 블록체인은 보안과 효율을 위한 도구가 아니고 신뢰받는 제 3자 없이 거래가 가능한 플랫폼을 만들기 위한 실험적 과정에 있는 개념이라고 생각하면 됩니다.&lt;/p&gt;

&lt;h2 id=&quot;가상-화폐-vs-암호-화폐&quot;&gt;가상 화폐 vs 암호 화폐&lt;/h2&gt;
&lt;p&gt;가상 화폐는 어떤 실물의 가치를 디지털화한 것을 의미하며, &lt;strong&gt;암호 화폐는 가상 화폐의 일부로 블록 체인을 기반으로 만들어진 화폐&lt;/strong&gt;를 의미합니다. 암호화 되었다는 뜻은 암호 화폐를 보내는 송신인과 수신인이 암호화된 공개키를 통해서만 거래를 하기 때문으로 이는 금융 시스템의 투명성을 해치고 악용될 여지가 많습니다.&lt;/p&gt;

&lt;h2 id=&quot;거래소-vs-중개소&quot;&gt;거래소 vs 중개소&lt;/h2&gt;
&lt;p&gt;거래소는 금융 거래소에서 가져온 단어로 금융 거래소는 거래 시스템에 필요한 환경과 제도가 잘 갖춰져 있습니다. 하지만 암호 화폐 거래소의 경우 암호 화폐의 가격이 단일화 되어 있지도 않고, 거래소 안에 엄격한 규정이 적용되어 있지도 않습니다. 그래서 정확한 명칭은 &lt;strong&gt;암호 화폐 중개소 정도가 적합합니다.&lt;/strong&gt; 그리고 온라인 상에 있는 많은 중개소들은 블록체인과는 별 관련이 없습니다. 중개소는 그저 암호 화폐를 이용하는 지갑이라는 소프트웨어와 온라인 주식 매매에 이용되는 HTS 기능 중 일부를 사용해 거래를 중개하는 브로커일 뿐입니다.&lt;/p&gt;

&lt;h2 id=&quot;트랜잭션-vs-거래내역&quot;&gt;트랜잭션 vs 거래내역&lt;/h2&gt;
&lt;p&gt;IT 분야에서는 트랜잭션을 보통 업무 처리의 단위로 얘기 하고 특히 데이터베이스 분야에서는 더 이상 쪼갤 수 없는(또는 더 쪼개면 심각한 오류가 발생할 수 있는)최소한의 업무 처리 단위를 의미합니다. &lt;strong&gt;블록체인에 있어서 트랜잭션은 ‘정의된 이벤트가 발생하는 것’을 의미하며 거래 내역을 포함한 더 포괄적인 의미입니다.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;디지털-자산&quot;&gt;디지털 자산&lt;/h2&gt;
&lt;p&gt;암호 화폐는 디지털 자산이 아닙니다. 디지털 자산은 저작권, 소유권 등의 권리를 디지털화 한 것으로 이는 실질적인 가치를 내재하고 있습니다. 하지만 &lt;strong&gt;암호 화폐는 내재 가치가 0인 디지털 숫자에 불과합니다.&lt;/strong&gt; 하지만 내재 가치가 0인 경우에도 가치를 가질 수 있습니다. 그러기 위해 필요한 것이 바로 ‘신뢰’입니다. 따라서 &lt;strong&gt;암호 화폐가 실제로 가치를 가지기 위해서는 사람들로부터의 신뢰가 필요합니다.&lt;/strong&gt; 예를 들어 지폐가 있습니다. 지폐는 종이에 불과하지만 그 뒤에 그 지폐를 발행한 국가의 법령과 신뢰가 뒷받침하기 때문에 실질적인 가치를 가질 수 있는 것입니다. 주식도 온라인 증명서에 불과하지만 주식을 발행한 기관의 신뢰 덕분에 가치를 가지게 됩니다.&lt;/p&gt;

&lt;h1 id=&quot;블록체인의-역사&quot;&gt;블록체인의 역사&lt;/h1&gt;

&lt;h2 id=&quot;사이퍼펑크&quot;&gt;사이퍼펑크&lt;/h2&gt;
&lt;p&gt;블록체인은 사이퍼펑크(cypherpunk) 운동에 뿌리를 두고 있습니다. 사이퍼펑크란 중앙집권화된 국가와 거대 기업들에 대항하여 개인의 프라이버시를 보호하기 위해 암호기술을 이용하여 익명성을 보장하는 탈중앙화 시스템을 만드려는 행동주의자들을 말합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/block_chain_basic_4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/blockchain_basic_5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;비트코인의-탄생&quot;&gt;비트코인의 탄생&lt;/h2&gt;
&lt;p&gt;2008년 사토시 나카모토란 가명으로 암호화 커뮤니티에 논문이 하나 올라왔습니다. 제목은 &lt;strong&gt;비트코인: P2P 전자 캐시 시스템&lt;/strong&gt;으로 사토시는 이 논문에서 코인을 그 누구의 간섭도 받지 않는 결제 수단이라고 설명했습니다. 그리고 2009년 1월 비트코인의 개념을 실제로 소프트웨어로 구현되어 최초의 블록(제네시스 블록 또는 0번 블록)이 생성되었습니다. 비트코인은 현재까지 10분에 하나꼴로 블록이 만들어지고 있으며 2019년 10월 기준 70만개의 블록이 만들어졌습니다. (참고로 사토시의 정체는 아직까지 밝혀지지 않았다고 합니다)&lt;/p&gt;

&lt;h1 id=&quot;블록-블록체인-비트코인&quot;&gt;블록? 블록체인? 비트코인?&lt;/h1&gt;
&lt;p&gt;블록체인을 공부하다 보면 블록의 정체가 무엇인지 또 나는 블록체인을 공부하는데 왜 자꾸 나도 모르는 사이에 비트코인이라는 단어가 등장하는 건지 의아했었습니다. (참고로 사토시가 공개한 비트코인에 관한 논문에는 ‘블록’과 ‘체인’이라는 명사가 독립적으로 사용되기는 했지만 ‘블록체인’이라는 단어는 한 번도 등장하지 않았습니다.)&lt;/p&gt;

&lt;h2 id=&quot;블록&quot;&gt;블록&lt;/h2&gt;
&lt;p&gt;블록은 전산학에서 보통 &lt;strong&gt;한꺼번에 처리되는 논리적 데이터 단위&lt;/strong&gt;를 일컫습니다. 비트코인에서는 트랜잭션들을 1메가바이트를 넘지 않는 선에서 계속 묶었다가 &lt;strong&gt;1메가바이트 직전이 되면 블록&lt;/strong&gt;으로 만듭니다. 보통 이렇게 하나의 블록이 만들어지는데 &lt;strong&gt;10분 정도&lt;/strong&gt;가 걸립니다.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;블록&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;설명&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;정의&lt;/td&gt;
      &lt;td&gt;한꺼번에 처리되는 데이터 단위&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;크기&lt;/td&gt;
      &lt;td&gt;최대 1MB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;트랜잭션 수&lt;/td&gt;
      &lt;td&gt;2000~3000개&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;생성 시간&lt;/td&gt;
      &lt;td&gt;평균 10분&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;블록체인&quot;&gt;블록체인&lt;/h2&gt;
&lt;p&gt;트랜잭션 데이터를 포함하는 &lt;strong&gt;블록을 앞의 블록의 해시값을 이용해 연결한 것을 블록체인&lt;/strong&gt;이라고 합니다. 블록은 각각의 노드에서 자신이 가지고 있는 트랜잭션들을 묶다가 블록을 만들 수 있는 시점이 되면 &lt;strong&gt;비동기적으로 블록을 만들기 위해 경쟁&lt;/strong&gt;합니다. &lt;strong&gt;이 때의 경쟁을 채굴(mining)이라고 하며 가장 먼저 블록을 만든 노드의 블록만을 모든 노드의 블록체인에 추가합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;비트코인&quot;&gt;비트코인&lt;/h2&gt;
&lt;p&gt;비트코인 생태계(네트워크)에서 &lt;strong&gt;채굴로 얻게되는 보상을 ‘비트코인’&lt;/strong&gt;이라고 합니다. 이 보상을 얻기 위해 채굴자들이 그렇게 앞다투어 채굴을 했던 것입니다. 여기서 채굴은 블록을 만들 때 블록에 필요한 해시값을 찾는 과정을 일컫습니다. 채굴에 대한 보상으로 얻게되는 비트코인의 수량은 어떻게 책정될까요? &lt;strong&gt;보상금은 보조금과 수수료의 합&lt;/strong&gt;으로 이루어지는데, 보조금은 채굴로 얻게되는 고정 수익을 말하고, 수수료는 비트코인 거래 시 송신자로부터 얻게 되는 것으로 수수료는 송신자가 스스로 정하게 됩니다. 그래서 보통 더 높은 수수료를 지불한 트랜잭션이 먼저 블록에 포함되게 됩니다. 보조금의 경우 제네시스 블록이 생성됐을 때에는 50BTC 였으나, 보조금은 블록이 21만개 생성될 때마다 반감되도록 설정되어 현재는 블록을 하나 생성할 때마다 6.25BTC를 얻게 됩니다.&lt;/p&gt;

&lt;p&gt;블록은 평균 10분 마다 한 개씩 생성되고 보조금은 21만개 마다 계속 반감되기 때문에 시간이 지나면 블록을 생성해도 더 이상 비트코인이 (거의) 발행되지 않게 될 것입니다. 이론적으로 &lt;strong&gt;2033년에 거의 포화되는 시점에 다다를 것으로 보며 그 때까지 누적된 비트코인의 양은 2100만BTC&lt;/strong&gt;라고 합니다. 이렇게 채굴에 대한 보상이 극도로 낮아질 경우, 채굴자가 급격히 줄어들게 될 것이고, 이는 비트코인 시스템의 안전성을 급격하게 저하시키게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/blockchain_basic_6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;마치며&quot;&gt;마치며&lt;/h1&gt;
&lt;p&gt;지금까지 블록체인에 대해 공부하기 전에 알고가면 좋은 지식들에 대해 살펴보았습니다. 다음 포스트에서는 블록체인의 동작원리에 대해 알아보겠습니다.&lt;/p&gt;

&lt;h1 id=&quot;참고&quot;&gt;참고&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&amp;amp;mallGb=KOR&amp;amp;barcode=9791161752709&amp;amp;orderClick=LAG&amp;amp;Kc=&quot; target=&quot;_blank&quot;&gt;블록체인 해설서 책&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://wiki.hash.kr/index.php/블록체인&quot; target=&quot;_blank&quot;&gt;해시넷: 블록체인&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
                <pubDate>Sun, 20 Feb 2022 21:01:35 +0900</pubDate>
                <link>http://localhost:4000/blockchain-series0</link>
                <guid isPermaLink="true">http://localhost:4000/blockchain-series0</guid>
                
                <category>Blockchain_basic</category>
                
                
                <category>Blockchain</category>
                
            </item>
        
    </channel>
</rss>