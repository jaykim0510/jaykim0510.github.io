---
layout: post
title: 'Hadoop Series [Part1]: Hadoop Intro'
description: 
date: 2022-02-05 15:01:35 +0300
image: '/images/hadoop_logo.png'
logo_image: '/images/hadoop_logo.png'
categories: DE
tags: Hadoop
---
---

**Table of Contents**
{: #toc }
*  TOC
{:toc}

---

# 대용량 데이터 처리

- 우리는 데이터 시대에 살고 있다
- 매년 모든 분야에서 데이터가 발생하고 있고, 모든 기기에서 데이터가 발생하고 있으며, 모든 생명체에서 데이터가 발생하고 있다


- 이러한 대용량 데이터를 처리하는데 있어 어떤 점이 어려울까
- 모든 문제는 **단일 시스템의 한계점**에서 비롯된다
- 단일 서버에 저장 -> 기존 디스크의 용량이 다 차게되면 더 큰 용량을 갖는 새로운 디스크로 데이터를 옮겨야 한다
- 단일 서버에 쓰기/읽기 -> 데이터량이 많아지고, 유저가 많아지면 그에 맞는 컴퓨팅 자원(CPU, 메모리)이 필요 -> 한계가 있음
- 단일 서버에 장애가 난 경우 -> 일시적으로 데이터에 접근 불가, 최악의 경우 데이터 자체를 모두 잃을 수도 있다
- 갑자기 트래픽량이 증가하는 경우 -> 아주 일시적으로 폭발하는 트래픽량을 수용하기 위해 비싼 리소스 소모 -> 자원 낭비

- 이를 위해 **분산 시스템**으로 넘어가야 한다
- 하지만 분산 시스템에는 아무런 문제가 없는 것은 아니다
- 분산 시스템은 위의 문제점을 해결해주지만 분산 시스템으로 인해 생기는 어려운 점도 있다

# 분산 시스템

- **분산 시스템의 핵심은 복제 저장, 분산 저장/처리이다**
- 위의 모든 문제를 해결하고 결과적으로 **Scale-Out, 분산 저장/처리, 높은 가용성**과 같은 특성들을 제공해준다


- 분산 시스템에서 **어려운 점은 시스템 일부에 생기는 하드웨어, 네트워크의 장애**에서 비롯된다
- 우선 분산 처리/저장을 할 때 최대한 네트워크 비용 자체를 줄여야 한다 (네트워크 비용은 디스크 I/O보다도 훨씬 더 큰 작업이다)
- 일부 시스템에 장애가 발생했을 때에 대한 대비책을 만들어야 한다
- 분산 시스템에는 높은 가용성을 위한 Replication도 있고, 분산 처리를 위한 Partition도 있다
  - Replication 간에는 동기화가 잘 되어야 한다 -> **합의 알고리즘**(리더 선출, 데이터 동기화)을 알아야 한다
  - Partition 간에는 최소한의 네트워크 비용이 발생하도록 해야 한다 -> **파티셔닝**, **Lazy Operation**을 알아야 한다

# Hadoop

- 빅데이터 처리를 위한 다양한 소프트웨어 제공
- 하둡은 개발자 더크 커팅이 처음으로 시작
- 구글이 발표한 분산 파일 저장을 위한 논문 GFS, 분산 데이터 처리를 위한 MapReduce 논문을 발표
- 더그 커팅이 구글에서 발표한 논문을 구현해 하둡 프로젝트가 시작됨 -> HDFS와 MapReduce가 하둡 프로젝트에 포함
- 이 후 빅데이터 처리를 위한 다양한 소프트웨어 Hive, HBase, Cassandra, Yarn 등이 등장하여 하둡 생태계 구성

![](/images/hadoop_1.png)



