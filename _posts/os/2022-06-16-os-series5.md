---
layout: post
title:  'OS Series [Part5]: Sync vs Async vs Concurrent vs Parallel'
description: 
date:   2022-06-16 15:01:35 +0300
image:  '/images/os_35.png'
logo_image:  '/images/os_logo.png'
categories: CS
tags: OS
---

---
**Table of Contents**
{: #toc }
*  TOC
{:toc}
---

![](/images/os_35.png)


- 동기성은 각각의 작업을 시작하고 끝내는 것을 순차적으로 하는 것을 의미한다. 동기적으로 프로그래밍했다면, 여러 개의 프로그램을
- 비동기성은 각각의 작업이 다른 작업의 시작과 끝에 종속되지 않는 것을 의미한다.
- 동시성은 프로세스내 작업들을 순차적으로 시작하고 마치는 것이 아니라 동시다발적으로 실행하는 것을 의미한다.  
- 병렬성은 여러 개의 코어를 사용하는 것을 의미한다.

상황에 맞게 적절히 비동기 프로그래밍을 할 수 있는 것은 중요하다. 


# Sync vs. Async
Sync and async are two different programming models, which refer to styles of programming - how you should write code and how your code will run.  

동기 프로그래밍에서 작업은 순차적으로 처리된다. 비동기 프로그래밍에서 작업은 어떤 순서로도 처리될 수 있다. 심지어 동시에 처리될 수도 있다.  

이 두 모델은 API, 또는 이벤트 기반 아키텍처, long-running 작업을 핸들링하기 위해 반드시 이해해야 한다.  

동기와 비동기의 차이는 다음을 포함한다.  

- Async is multi-thread, which means operations or programs can run in parallel. Sync is single-thread, so only one operation or program will run at a time.  
- Async is non-blocking, which means it will send multiple requests to a server. Sync is blocking — it will only send the server one request at a time and will wait for that request to be answered by the server.  
- Async increases throughput because multiple operations can run at the same time. Sync is slower and more methodical.
- Differences aside, asynchronous and synchronous methods both offer advantages, but for different stakeholders: async for users, sync for developers.  

비동기 프로그래밍은 대개 유저 경험을 향상시킨다. 작업을 순차적으로 처리하지 않고, 동시다발적으로 처리하기 때문에 요청에서 응답까지의 시간을 줄일 수 있다.  

동기 프로그래밍은 개발자에게 이점을 준다. 쉽게 말해 코드를 작성하기가 훨씬 수월하다.  

언제 비동기 프로그래밍을 사용해야 할까?  

비동기 작업은 독립적인 태스크들에 사용돼야 한다. 반응형 UI와 같은 작업을 예로 들어보자. 사용자가 주문을 할 때 폰트가 커져야 한다고 할 때, 이전 주문 내역을 불러오는 일과 폰트가 커지는 작업을 굳이 순서대로 할 필요가 없다. 이러한 작업은 함께 처리되도록 하는 것이 낫다.  

동기 작업은 우선 코드를 작성하고 읽는데 부담이 줄어든다. 또한 만약 사용자가 상품들을 구매한다고 할 때, 상품 선택과 구매는 동기 작업으로 이루어져야 한다. 이렇게 의존적인 관계에 있는 태스크들은 동기 프로그래밍해야 한다.  


# Sync

동기 프로그래밍은 blocking 아키텍처이다. 이는 작업의 실행이 시간마다 하나씩만 실행될 수 있으며 하나의 작업이 실행되는 동안 다른 작업은 blocked된다. 하나의 작업의 종료가 다른 작업의 시작을 트리거한다.  

동기 프로그래밍으로 작성된 코드는 내가 작성한 순서대로 실행된다.  

```js
func step1() { print("1") }
func step2() { print("2") }

func main() {
    step1()
    step2()
}

// result -> 12
```

동기 프로그래밍은 우리가 결과를 예측할 수 있기 때문에 predictable programming model이라고도 한다. 대부분의 프로그래밍 언어가 동기 프로그래밍을 디폴트로 한다.  

# Async


비동기 프로그래밍은 반대로 non-blocking 아키텍처다. 이 말은 하나의 작업이 다른 작업의 실행을 방해하지 않는다는 뜻이다. 그래서 여러 개의 작업이 concurrent하게 실행될 수 있고, 서로가 다른 작업의 시작과 끝을 기다리지 않는다.  

채팅 프로그램이 비동기 프로그래밍의 좋은 예가 된다. 한 사람이 텍스트를 보내는 작업이 다른 사람의 텍스트 전송 작업을 막지 못한다.  

비동기 프로그래밍으로 작성된 코드는 내부에 작성된 작업들이 동시다발적으로 실행된다.  


```js
func task1() { print("1") }
func task2() { print("2") }

func main() {
    task1()
    task2()
}

// result -> 12 or 21
```

위의 결과를 보면 결과가 undeterministic하다. 이러한 특성 때문에 비동기 프로그래밍을 unpredictable programming model이라고도 한다. 비동기 프로그래밍은 각각의 작업이 서로 의존적이지 않은 경우, 그리고 순서가 중요하지 않은 경우에 사용할 수 있다.  

비동기 프로그래밍은 멀티 코어 환경일 경우 동시성과 병렬성, 싱글 코어 환경일 경우 동시성을 제공한다.  

# 동시성(Concurrency)

![](/images/os_33.png)

동시성(Concurrency)를 얻으려면 무조건 비동기 프로그래밍으로 코드를 작성해야 한다. 

동시성과 병렬성은 얼핏 헷갈린다. 왜냐하면 둘 다 여러 작업을 처리하기 때문이다. 하지만 동시성은 **여러 작업이 스레드 또는 코어를 공유한다는 개념**에 더 가깝다. 정말로 우리가 생각하는 여러 작업이 동시에 실행되는 것을 병렬성이라고 얘기한다.  

동시성은 작업을 하나씩 순차적으로 실행하는 것이 아니라, 여러 작업을 번갈아가며 실행하는 것을 의미한다. 만약 싱글 코어 환경이라면, 동시성은 컨텍스트 스위칭을 통해 얻어진다.  
 

# 병렬성(Parallel)

병렬성은 여러 작업이 정말로 동시에 처리되는 것을 의미한다. 병렬성은 반드시 멀티 코어 환경에서만 얻을 수 있다. 

![](/images/os_34.png)

# 멀티 프로세싱

멀티 프로세싱은 다수의 프로세서가 서로 협력적으로 일을 처리하는 것을 의미한다. 프로세스 간 통신을 하기 위해서는 IPC를 통해야 한다.   

![](/images/os_31.png)

- 장점
  - 독립된 구조로 안전성이 높은 장점이 있다.
  - 프로세스 중 하나에 문제가 생겨도 다른 프로세스에 영향을 주지 않아, 작업속도가 느려지는 손해정도는 생기지만 정지되거나 하는 문제는 발생하지 않는다.

- 단점
  - 메모리 사용량이 많다
  - 독립된 메모리 영역이기 때문에 작업량이 많을수록(Context Switching이 자주 일어나서 주소 공간의 공유가 잦을 경우) 오버헤드가 발생하여 성능저하가 발생 할 수 있다.
  - Context Switching 과정에서 캐시 메모리 초기화 등 무거운 작업이 진행되고 시간이 소모되는 등 오버헤드가 발생한다.

# 멀티 스레딩

멀티 스레딩은 하나의 프로세스를 스레드 단위로 프로세서에게 할당해 병렬 처리하는 것을 의미하며, 여러 개의 스레드는 서로 자원을 공유할 수 있다.  

![](/images/os_32.png)


- 장점
  - 응답성 향상: 한 스레드가 입출력으로 인해 작업이 진행되지 않더라도 다른 스레드가 작업을 계속하여 사용자의 작업 요구에 빨리 응답할 수 있다
  - 자원 공유: 한 프로세스 내에서 독립적인 스레드를 생성하면 프로세스가 가진 자원을 모든 스레드가 공유하게 되어 작업을 원활하게 진행할 수 있다
  - 효율성 향상: 불필요한 자원의 중복을 막음으로써 시스템의 효율이 향상된다
  - 다중 CPU 지원: 2개 이상의 CPU를 가진 컴퓨터에서 멀티스레드를 사용하면 다중 CPU가 멀티스레드를 동시에 처리하여 CPU 사용량이 증가하고 프로세스의 처리 시간이 단축된다
  - 시스템 자원소모 감소 (자원의 효율성 증대)
    - 프로세스를 생성하여 자원을 할당하는 시스템 콜이 줄어 자원을 효율적으로 관리할 수 있다.
  - 시스템 처리율 향상 (처리비용 감소)
    - 스레드 간 데이터를 주고 받는 것이 간단해지고 시스템 자원 소모가 줄어든다.
    - 스레드 사이 작업량이 작아 Context Switching이 빠르다. (캐시 메모리를 비울 필요가 없다.)
  - 간단한 통신 방법으로 프로그램 응답시간 단축
    - 스레드는 프로세스 내 스택영역을 제외한 메모리 영역을 공유하기에 통신 비용이 적다.
    - 힙 영역을 공유하므로 데이터를 주고 받을 수 있다.

  - 운영체제가 시스템 자원을 효율적으로 관리하기 위해 스레드를 사용한다.
  - 멀티 프로세스로 실행되는 작업을 멀티 스레드로 실행할 경우, 프로세스를 생성하여 자원을 할당하는 시스템 콜이 줄어들어 자원을 효율적으로 관리할 수 있다.
  - 또한, 프로세스 간의 통신보다 스레드 간의 통신 비용이 적으므로 작업들 간 통신의 부담이 줄어든다. (처리비용 감소. 프로세스는 독립구조이기 때문)

- 단점
  - 모든 스레드가 자원을 공유하기 때문에 한 스레드에 문제가 생기면 전체 프로세스에 영향을 미친다.  
  - 자원을 공유하기에 동기화 문제가 발생할 수 있다. (병목현상, 데드락 등)
  - 주의 깊은 설계가 필요하고 디버깅이 어렵다. (불필요 부분까지 동기화하면, 대기시간으로 인해 성능저하 발생)
  - 하나의 스레드에 문제가 생기면 전체 프로세스가 영향을 받는다.
  - 단일 프로세스 시스템의 경우 효과를 기대하기 어렵다.
  - 스레드를 활용하면 자원의 효율성이 증가하기도 하지만, 스레드 간의 자원 공유는 전역 변수를 이용하므로 동기화 문제가 발생 할 수 있으므로 프로그래머의 주의가 필요하다.
  - 스레드 하나가 프로세스 내 자원을 망쳐버린다면 모든 프로세스가 종료될 수 있다.
  - 자원을 공유하기 때문에 필연적으로 동기화 문제가 발생할 수밖에 없다.
  - 동기화 그리고 교착상태가 발생하지 않도록 주의해야 한다.
  - 자식 스레드 중 하나에 문제가 생긴경우 전체 프로세스에 영향을 줄 수 있다.
  - race condition, deadlocks, shared resources, and callbacks events 같은 문제들을 처리해야한다.

자원의 효율성증대  
멀티 프로세스로 실행되는 작업을 멀티 스레드로 실행할 경우 프로세스를 생성하여 자원을 할당하는 비용이 적고, 스레드는 프로세스 내의 메모리를 공유하기 때문에 독립적인 프로세스와 달리 스레드 간 데이터를 주고 받는 것이 간단해지고 시스템 자원 소모가 줄어든다.  

 

응답 시간 단축 및 처리 비용 감소  
프로세스간 IPC를 사용하여 통신하는 것은 상대적으로 비용이 크다.  

하지만 스레드는 프로세스의 메모리 영역을 공유하여 스레드 간의 통신 비용이 적게 든다.  

또한 프로세스간의 Context Switching은 느린 반면 쓰레드간의 Context Switching 은 빠른데, 그 이유는 Context Switching 시 스레드는 Stack 영역만 처리하면 되기 때문이다.  

 

멀티 스레드의 안정성 문제  
여러 개의 스레드가 동일한 데이터 공간(Critical Section)을 공유하면서 이들을 수정한다는 점에 필연적으로 생기는 문제이다.  

Tip  
Critical Section:   
임계 구역(critical section) 또는 공유변수 영역은 둘 이상의 스레드가 동시에 접근해서는 안되는 공유 자원(자료 구조 또는 장치)을 접근하는 코드의 일부를 말한다.  

멀티 프로세스의 프로그램은 문제가 생기면 해당 프로세스가 중단되거나 중단 시키고 다시 시작 하면된다.  

하지만 멀티 스레드 방식의 프로그램에서는 하나의 스레드가 자신이 사용하던 데이터 공간을 망가뜨린다면, 해당 데이터 공간을 공유하는 모든 스레드를 망가뜨릴 수 있다.  

# Global Interpreter Lock

- GIL은 파이썬에서 멀티스레드에 관해 얘기할 때 자주 등장하는 용어다
- 파이썬은 C언어 같은 언어와 다르게 메모리 관리를 자동 지원한다. 이를 돕는 것을 가비지 컬렉터(GC, Garbage Collector)라고 한다
- 가비지 컬렉터는 객체가 가지고 있는 참조 횟수 카운트를 보고 카운트가 0인 객체는 더 이상 사용되지 않는다고 판단하고 메모리를 회수한다
- 근데 여기서 멀티스레드를 사용한다고 하면, 여러 스레드에서 하나의 객체의 참조 횟수 카운트(refcount)를 수정하려고 접근할 수 있다
- 이 때 파이썬은 문제가 될 것이라고 판단하고, 이로 인해 GC가 제대로 된 기능을 못하게 되는 것을 방지하고자 GIL이라는 개념을 도입했다
- GIL은 임계 구역 문제를 해결하고자 사용하는 뮤텍스와 같은 것이다
- 뮤텍스는 하나의 공간을 여러 사용자가 접근하고자 할 때 한 명만 접근하도록 허용하고 나머지는 기다리도록 하기 위해 접근 가능한 사용자에게만 주는 일종의 열쇠이다
- 이 열쇠를 건네받는 사용자만 이 공간을 사용할 수 있다
- GIL이 파이썬에서 이 뮤텍스(열쇠)다
- GIL로 다른 스레드의 접근을 막고 본인 스레드만 객체의 참조 횟수 카운트를 바꿀 수 있도록 하는 것이다
- 그래야 가비지 컬렉터에게 생기는 혼란을 방지할 수 있고 메모리 관리를 차질없이 할 수 있게 된다
- [**피그브라더, [Python] GIL (Global Interpreter Lock) 이해하기 참고**](https://it-eldorado.tistory.com/160){:target="_blank"}
- [**스터디룸, Python GIL(Global Interpreter Lock) 참고**](https://8iggy.tistory.com/241){:target="_blank"}

# 콜백 함수

- 함수 안에 인자로 전달되는 함수
- fun1(fun2) -> fun1 함수를 실행하는 도중에 fun2 함수가 실행되고 fun2 함수가 종료된 후 fun1 함수가 마저 실행됨
- fun2와 같은 함수를 콜백 함수라고 함

# Thread Safe(스레드 동기화)
멀티 쓰레드 프로그래밍에서, 어떤 공유 자원에 여러 쓰레드가 동시에 접근해도, 프로그램 실행에 문제가 없는 상태를 의미합니다.  

멀티 스레드 프로그래밍에서 일반적으로 어떤 함수나 변수, 혹은 객체가 여러 스레드로부터 동시에 접근이 이루어져도 프로그램의 실행에 문제가 없음을 뜻한다. 보다 엄밀하게는 하나의 함수가 한 스레드로부터 호출되어 실행 중일 때, 다른 스레드가 그 함수를 호출하여 동시에 함께 실행되더라도 각 스레드에서의 함수의 수행 결과가 올바로 나오는 것으로 정의한다.  

Thread Safe 를 지키기 위한 방법은 네 가지로 이루어져 있습니다.  
- Mutual exclusion (상호 배제)
- Atomic operation (원자 연산)
- Thread-local storage (쓰레드 지역 저장소)
- Re-entrancy (재진입성)

## Mutual exclusion (상호 배제)
- 공유자원에 하나의 Thread 만 접근할 수 있도록, 세마포어/뮤텍스로 락을 통제하는 방법입니다.
- 일반적으로 많이 사용되는 방식입니다.
- 적용 예제
  - Python 은 Thread Safe 하게 메모리 관리 하지 않으므로,
  - GlL(Global Interpreter Lock)을 사용해 Thread Safe 를 보장합니다.

## Atomic operation (원자 연산)
- 공유자원에 원자적으로 접근하는 방법입니다.
- Atomic
  - 공유 자원 변경에 필요한 연산을 원자적으로 분리한 뒤,
  - 실제로 데이터의 변경이 이루어지는 시점에 Lock 을 걸고,
  - 데이터를 변경하는 시간 동안, 다른 쓰레드의 접근이 불가능하도록 하는 방법입니다.

## Thread-local storage (쓰레드 지역 저장소)

- 공유 자원의 사용을 최대한 줄이고, 각각의 쓰레드에서만 접근 가능한 저장소들을 사용함으로써 동시 접근을 막는 방법입니다.
- 일반적으로 공유상태를 피할 수 없을 때 사용하는 방식입니다.

## Re-entrancy (재진입성)
- 쓰레드 호출과 상관 없이 프로그램에 문제가 없도록 작성하는 방법입니다.

# 궁금한 것 

- 스레드로 나눌 수 있는 기준
- 멀티 프로세싱을 위해 프로세스를 나눌 수 있는 기준


- [Minh-Phuc Tran, Sync vs. Async vs. Concurrent vs. Parallel](https://phuctm97.com/blog/sync-async-concurrent-parallel){:target="_blank"}
- [Concurrency, Multi-threading, Multi-processing, Asynchronous Programming and Event Loop](https://blog.devgenius.io/concurrency-multi-threading-multi-processing-asynchronous-programming-and-event-loop-1b8df9fa6c20){:target="_blank"}
- [oxylabs, Concurrency vs Parallelism: The Main Differences](https://oxylabs.io/blog/concurrency-vs-parallelism){:target="_blank"}
- [David Bevans, Asynchronous vs. Synchronous Programming: Key Similarities and Differences](https://www.mendix.com/blog/asynchronous-vs-synchronous-programming/){:target="_blank"}
- [stackoverflow, What is the difference between concurrency, parallelism and asynchronous methods?](https://stackoverflow.com/questions/4844637/what-is-the-difference-between-concurrency-parallelism-and-asynchronous-methods){:target="_blank"}
- [비동기와 멀티스레딩](https://jayhyun-hwang.github.io/2021/09/02/The-Difference-Between-Asynchronous-And-Multi-Threading/){:target="_blank"}
- [피그브라더, [Python] GIL (Global Interpreter Lock) 이해하기](https://it-eldorado.tistory.com/160){:target="_blank"}
- [스터디룸, Python GIL(Global Interpreter Lock)](https://8iggy.tistory.com/241){:target="_blank"}
- [우노, [OS] 쓰레드 세이프(Tread Safe)란?](https://wooono.tistory.com/523){:target="_blank"}