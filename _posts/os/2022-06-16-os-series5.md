---
layout: post
title:  'OS Series [Part5]: Sync vs Async vs Concurrent vs Parallel'
description: 
date:   2022-06-16 15:01:35 +0300
image:  '/images/os_3.png'
logo_image:  '/images/os_logo.png'
categories: CS
tags: OS
---

---
**Table of Contents**
{: #toc }
*  TOC
{:toc}
---

![](/images/os_35.png)


- 동기성은 각각의 작업을 시작하고 끝내는 것을 순차적으로 하는 것을 의미한다. 동기적으로 프로그래밍했다면, 여러 개의 프로그램을
- 비동기성은 각각의 작업이 다른 작업의 시작과 끝에 종속되지 않는 것을 의미한다.
- 동시성은 프로세스내 작업들을 순차적으로 시작하고 마치는 것이 아니라 동시다발적으로 실행하는 것을 의미한다.  
- 병렬성은 여러 개의 코어를 사용하는 것을 의미한다.

상황에 맞게 적절히 비동기 프로그래밍을 할 수 있는 것은 중요하다. 


# Sync vs. Async
Sync and async are two different programming models, which refer to styles of programming - how you should write code and how your code will run.  

Synchronous tasks happen in order — you must finish task one before moving on to the next. Asynchronous tasks can be executed in any order, or even simultaneously. How can this be understood in terms of programming?  

Understanding how these two models differ is critical in building application programming interfaces (APIs), creating event-based architectures, and deciding how to handle long-running tasks. In choosing which method to use and when, it’s important to know a few key things about synchronous programming and asynchronous programming.  

The differences between asynchronous and synchronous include:  

Async is multi-thread, which means operations or programs can run in parallel. Sync is single-thread, so only one operation or program will run at a time.  
Async is non-blocking, which means it will send multiple requests to a server. Sync is blocking — it will only send the server one request at a time and will wait for that request to be answered by the server.  
Async increases throughput because multiple operations can run at the same time. Sync is slower and more methodical.
Differences aside, asynchronous and synchronous methods both offer advantages, but for different stakeholders: async for users, sync for developers.  


Asynchronous programming enhances a user’s experience by decreasing the lag time between when a function is called and when the value of that function is returned. In the real world, this translates to a faster, more seamless flow. For example, users want their apps to run fast, but it takes time to fetch data from an application programming interface (API). In these cases, asynchronous programming helps the app screens load faster, improving the user experience.  

Synchronous programming, on the other hand, is advantageous for developers. Quite simply, synchronous programming is much easier to code. It’s well supported among all programming languages, and as the default programming method, developers don’t have to spend time learning something new that could open the door to bugs.  


When to use async  
Asynchronous programming should only be used in programming independent tasks, where it plays a critical role. For instance, asynchronous programs are ideal for development projects with a large number of iterations. Because steps don’t have to follow a fixed sequence, asynchronous programming keeps development moving forward.  

Responsive UI is a great use case for asynchronous planning. Take, for example, a shopping app. When a user pulls up their order, the font size should increase. Instead of first waiting to load the history and update the font size, asynchronous programming can make both actions happen simultaneously.  

When to use sync  
Asynchronous programming is relatively complex. It can overcomplicate things and make code difficult to read. Synchronous programming, on the other hand, is fairly straightforward; its code is easier to write and doesn’t require tracking and measuring process flows (as async does). Because tasks are dependent on each other, there’s a need to know if they could run independently without interrupting each other.   

Synchronous programming could be appropriate for a shopping app, for example. When checking out online, a user wants to buy all of their items together, not individually. Instead of completing an order every time the user adds something to their cart, synchronous programming ensures that the payment method and shipping destination for all items are selected at the same time.  


# Sync

Synchronous is known as a blocking architecture and is ideal for programming reactive systems. As a single-thread model, it follows a strict set of sequences, which means that operations are performed one at a time, in perfect order. While one operation is being performed, other operations’ instructions are blocked. The completion of the first task triggers the next, and so on.  

To illustrate how synchronous programming works, think of a telephone. During a phone call, while one person speaks, the other listens. When the first person finishes, the second tends to respond immediately.  

동기 프로그래밍으로 작성된 코드는 내가 작성한 순서대로 실행될 것이다. 

```js
func step1() { print("1") }
func step2() { print("2") }

func main() {
    step1()
    step2()
}

// result -> 12
```

동기 프로그래밍은 우리가 결과를 예측할 수 있기 때문에 predictable programming model이라고도 한다. 대부분의 프로그래밍 언어가 동기 프로그래밍을 디폴트로 한다.  

# Async

Asynchronous programming, conversely, is a multithreaded model that’s most applicable to networking and communications. Asynchronous is a non-blocking architecture, which means it doesn’t block further execution while one or more operations are in progress.  

With asynchronous programming, multiple related operations can run concurrently without waiting for other tasks to complete. During asynchronous communication, parties receive and process messages when it’s convenient or possible to do so, rather than responding immediately upon receipt.  

Texting is an asynchronous communication method. One person can send a text message and the recipient can respond at their leisure. In the meantime, the sender may do other things while waiting for a response.  
비동기 프로그래밍으로 작성된 코드는 내부에 작성된 작업들이 동시다발적으로 실행된다.  


```js
func task1() { print("1") }
func task2() { print("2") }

func main() {
    task1()
    task2()
}

// result -> 12 or 21
```

위의 결과를 보면 결과가 undeterministic하다. 이러한 특성 때문에 비동기 프로그래밍을 unpredictable programming model이라고도 한다. 비동기 프로그래밍은 각각의 작업이 서로 의존적이지 않은 경우, 그리고 순서가 중요하지 않은 경우에 사용할 수 있다.  



# con

![](/images/os_33.png)

동시성(Concurrency)를 얻으려면 무조건 비동기 프로그래밍으로 코드를 작성해야 한다. 

Concurrent and parallel are effectively the same principle as you correctly surmise, both are related to tasks being executed simultaneously although I would say that parallel tasks should be truly multitasking, executed "at the same time" whereas concurrent could mean that the tasks are sharing the execution thread while still appearing to be executing in parallel.  

Asynchronous methods aren't directly related to the previous two concepts, asynchrony is used to present the impression of concurrent or parallel tasking but effectively an asynchronous method call is normally used for a process that needs to do work away from the current application and we don't want to wait and block our application awaiting the response.  

For example, getting data from a database could take time but we don't want to block our UI waiting for the data. The async call takes a call-back reference and returns execution back to your code as soon as the request has been placed with the remote system. Your UI can continue to respond to the user while the remote system does whatever processing is required, once it returns the data to your call-back method then that method can update the UI (or handoff that update) as appropriate.  

Concurrency means executing multiple tasks at the same time but not necessarily simultaneously. When you have to perform more than one task but you have a single resource then we go for concurrency. In a single-core environment, concurrency is achieved by context switching.  

Parallelism is like performing more than one task simultaneously like you can sing and bath together. Now you are doing the tasks in parallel.  

The term asynchronous is related to thread execution. In an asynchronous model, when one task gets executed, you can switch to a different task without waiting for the previous task to get completed.  

Asynchronous programming helps us to achieve concurrency. Asynchronous programming in a multi-threaded environment is a way to achieve parallelism.  

# parallel

![](/images/os_34.png)
## 멀티 프로세싱

멀티 프로세싱은 다수의 프로세서가 서로 협력적으로 일을 처리하는 것을 의미한다. 프로세스 간 통신을 하기 위해서는 IPC를 통해야 한다.   

![](/images/os_31.png)

- 장점
  - 독립된 구조로 안전성이 높은 장점이 있다.
  - 프로세스 중 하나에 문제가 생겨도 다른 프로세스에 영향을 주지 않아, 작업속도가 느려지는 손해정도는 생기지만 정지되거나 하는 문제는 발생하지 않는다.

- 단점
  - 메모리 사용량이 많다
  - 독립된 메모리 영역이기 때문에 작업량이 많을수록( Context Switching이 자주 일어나서 주소 공간의 공유가 잦을 경우) 오버헤드가 발생하여 성능저하가 발생 할 수 있다.
  - Context Switching 과정에서 캐시 메모리 초기화 등 무거운 작업이 진행되고 시간이 소모되는 등 오버헤드가 발생한다.

## 멀티 스레딩

멀티 스레딩은 하나의 프로세스를 스레드 단위로 프로세서에게 할당해 병렬 처리하는 것을 의미하며, 여러 개의 스레드는 서로 자원을 공유할 수 있다.  

![](/images/os_32.png)


- 장점

  - 응답성 향상: 한 스레드가 입출력으로 인해 작업이 진행되지 않더라도 다른 스레드가 작업을 계속하여 사용자의 작업 요구에 빨리 응답할 수 있다
  - 자원 공유: 한 프로세스 내에서 독립적인 스레드를 생성하면 프로세스가 가진 자원을 모든 스레드가 공유하게 되어 작업을 원활하게 진행할 수 있다
  - 효율성 향상: 불필요한 자원의 중복을 막음으로써 시스템의 효율이 향상된다
  - 다중 CPU 지원: 2개 이상의 CPU를 가진 컴퓨터에서 멀티스레드를 사용하면 다중 CPU가 멀티스레드를 동시에 처리하여 CPU 사용량이 증가하고 프로세스의 처리 시간이 단축된다
  - 시스템 자원소모 감소 (자원의 효율성 증대)
    - 프로세스를 생성하여 자원을 할당하는 시스템 콜이 줄어 자원을 효율적으로 관리할 수 있다.
  - 시스템 처리율 향상 (처리비용 감소)
    - 스레드 간 데이터를 주고 받는 것이 간단해지고 시스템 자원 소모가 줄어든다.
    - 스레드 사이 작업량이 작아 Context Switching이 빠르다. (캐시 메모리를 비울 필요가 없다.)
  - 간단한 통신 방법으로 프로그램 응답시간 단축
    - 스레드는 프로세스 내 스택영역을 제외한 메모리 영역을 공유하기에 통신 비용이 적다.
    - 힙 영역을 공유하므로 데이터를 주고 받을 수 있다.

  - 운영체제가 시스템 자원을 효율적으로 관리하기 위해 스레드를 사용한다.
  - 멀티 프로세스로 실행되는 작업을 멀티 스레드로 실행할 경우, 프로세스를 생성하여 자원을 할당하는 시스템 콜이 줄어들어 자원을 효율적으로 관리할 수 있다.
  - 또한, 프로세스 간의 통신보다 스레드 간의 통신 비용이 적으므로 작업들 간 통신의 부담이 줄어든다. (처리비용 감소. 프로세스는 독립구조이기 때문)

- 단점
  - 모든 스레드가 자원을 공유하기 때문에 한 스레드에 문제가 생기면 전체 프로세스에 영향을 미친다.  
  - 자원을 공유하기에 동기화 문제가 발생할 수 있다. (병목현상, 데드락 등)
  - 주의 깊은 설계가 필요하고 디버깅이 어렵다. (불필요 부분까지 동기화하면, 대기시간으로 인해 성능저하 발생)
  - 하나의 스레드에 문제가 생기면 전체 프로세스가 영향을 받는다.
  - 단일 프로세스 시스템의 경우 효과를 기대하기 어렵다.
  - 스레드를 활용하면 자원의 효율성이 증가하기도 하지만, 스레드 간의 자원 공유는 전역 변수를 이용하므로 동기화 문제가 발생 할 수 있으므로 프로그래머의 주의가 필요하다.
  - 스레드 하나가 프로세스 내 자원을 망쳐버린다면 모든 프로세스가 종료될 수 있다.
  - 자원을 공유하기 때문에 필연적으로 동기화 문제가 발생할 수밖에 없다.
  - 동기화 그리고 교착상태가 발생하지 않도록 주의해야 한다.
  - 자식 스레드 중 하나에 문제가 생긴경우 전체 프로세스에 영향을 줄 수 있다.
  - race condition, deadlocks, shared resources, and callbacks events 같은 문제들을 처리해야한다.

자원의 효율성증대  
멀티 프로세스로 실행되는 작업을 멀티 스레드로 실행할 경우 프로세스를 생성하여 자원을 할당하는 비용이 적고, 스레드는 프로세스 내의 메모리를 공유하기 때문에 독립적인 프로세스와 달리 스레드 간 데이터를 주고 받는 것이 간단해지고 시스템 자원 소모가 줄어든다.  

 

응답 시간 단축 및 처리 비용 감소  
프로세스간 IPC를 사용하여 통신하는 것은 상대적으로 비용이 크다.  

하지만 스레드는 프로세스의 메모리 영역을 공유하여 스레드 간의 통신 비용이 적게 든다.  

또한 프로세스간의 Context Switching은 느린 반면 쓰레드간의 Context Switching 은 빠른데, 그 이유는 Context Switching 시 스레드는 Stack 영역만 처리하면 되기 때문이다.  

 

멀티 스레드의 안정성 문제  
여러 개의 스레드가 동일한 데이터 공간(Critical Section)을 공유하면서 이들을 수정한다는 점에 필연적으로 생기는 문제이다.  

Tip  
Critical Section:   
임계 구역(critical section) 또는 공유변수 영역은 둘 이상의 스레드가 동시에 접근해서는 안되는 공유 자원(자료 구조 또는 장치)을 접근하는 코드의 일부를 말한다.  

멀티 프로세스의 프로그램은 문제가 생기면 해당 프로세스가 중단되거나 중단 시키고 다시 시작 하면된다.  

하지만 멀티 스레드 방식의 프로그램에서는 하나의 스레드가 자신이 사용하던 데이터 공간을 망가뜨린다면, 해당 데이터 공간을 공유하는 모든 스레드를 망가뜨릴 수 있다.  


# There are several scenarios in which concurrency can occur:

Asynchrony— This means that your program performs non-blocking operations. For example, it can initiate a request for a remote resource via HTTP and then go on to do some other task while it waits for the response to be received. It’s a bit like when you send an email and then go on with your life without waiting for a response.  

Parallelism— This means that your program leverages the hardware of multi-core machines to execute tasks at the same time by breaking up work into tasks, each of which is executed on a separate core. It’s a bit like singing in the shower: you’re actually doing two things at exactly the same time.  

Multithreading— This is a software implementation allowing different threads to be executed concurrently. A multithreaded program appears to be doing several things at the same time even when it’s running on a single-core machine. This is a bit like chatting with different people through various IM windows; although you’re actually switching back and forth, the net result is that you’re having multiple conversations at the same time.  


# Global Interpreter Lock

# 콜백 함수

- 함수 안에 인자로 전달되는 함수
- fun1(fun2) -> fun1 함수를 실행하는 도중에 fun2 함수가 실행되고 fun2 함수가 종료된 후 fun1 함수가 마저 실행됨
- fun2와 같은 함수를 콜백 함수라고 함

# Thread Safe
멀티 쓰레드 프로그래밍에서, 어떤 공유 자원에 여러 쓰레드가 동시에 접근해도, 프로그램 실행에 문제가 없는 상태를 의미합니다.  

멀티 스레드 프로그래밍에서 일반적으로 어떤 함수나 변수, 혹은 객체가 여러 스레드로부터 동시에 접근이 이루어져도 프로그램의 실행에 문제가 없음을 뜻한다. 보다 엄밀하게는 하나의 함수가 한 스레드로부터 호출되어 실행 중일 때, 다른 스레드가 그 함수를 호출하여 동시에 함께 실행되더라도 각 스레드에서의 함수의 수행 결과가 올바로 나오는 것으로 정의한다.  

Thread Safe 를 지키기 위한 방법은 네 가지로 이루어져 있습니다.  
- Mutual exclusion (상호 배제)
- Atomic operation (원자 연산)
- Thread-local storage (쓰레드 지역 저장소)
- Re-entrancy (재진입성)

## Mutual exclusion (상호 배제)
- 공유자원에 하나의 Thread 만 접근할 수 있도록, 세마포어/뮤텍스로 락을 통제하는 방법입니다.
- 일반적으로 많이 사용되는 방식입니다.
- 적용 예제
  - Python 은 Thread Safe 하게 메모리 관리 하지 않으므로,
  - GlL(Global Interpreter Lock)을 사용해 Thread Safe 를 보장합니다.

## Atomic operation (원자 연산)
- 공유자원에 원자적으로 접근하는 방법입니다.
- Atomic
  - 공유 자원 변경에 필요한 연산을 원자적으로 분리한 뒤,
  - 실제로 데이터의 변경이 이루어지는 시점에 Lock 을 걸고,
  - 데이터를 변경하는 시간 동안, 다른 쓰레드의 접근이 불가능하도록 하는 방법입니다.

## Thread-local storage (쓰레드 지역 저장소)

- 공유 자원의 사용을 최대한 줄이고, 각각의 쓰레드에서만 접근 가능한 저장소들을 사용함으로써 동시 접근을 막는 방법입니다.
- 일반적으로 공유상태를 피할 수 없을 때 사용하는 방식입니다.

## Re-entrancy (재진입성)
- 쓰레드 호출과 상관 없이 프로그램에 문제가 없도록 작성하는 방법입니다.

# 궁금한 것 

- 스레드로 나눌 수 있는 기준
- 멀티 프로세싱을 위해 프로세스를 나눌 수 있는 기준


- [Minh-Phuc Tran, Sync vs. Async vs. Concurrent vs. Parallel](https://phuctm97.com/blog/sync-async-concurrent-parallel){:target="_blank"}
- [Concurrency, Multi-threading, Multi-processing, Asynchronous Programming and Event Loop](https://blog.devgenius.io/concurrency-multi-threading-multi-processing-asynchronous-programming-and-event-loop-1b8df9fa6c20){:target="_blank"}
- [oxylabs, Concurrency vs Parallelism: The Main Differences](https://oxylabs.io/blog/concurrency-vs-parallelism){:target="_blank"}
- [David Bevans, Asynchronous vs. Synchronous Programming: Key Similarities and Differences](https://www.mendix.com/blog/asynchronous-vs-synchronous-programming/){:target="_blank"}
- [stackoverflow, What is the difference between concurrency, parallelism and asynchronous methods?](https://stackoverflow.com/questions/4844637/what-is-the-difference-between-concurrency-parallelism-and-asynchronous-methods){:target="_blank"}
- [비동기와 멀티스레딩](https://jayhyun-hwang.github.io/2021/09/02/The-Difference-Between-Asynchronous-And-Multi-Threading/){:target="_blank"}
- [피그브라더, [Python] GIL (Global Interpreter Lock) 이해하기](https://it-eldorado.tistory.com/160){:target="_blank"}
- [스터디룸, Python GIL(Global Interpreter Lock)](https://8iggy.tistory.com/241){:target="_blank"}
- [우노, [OS] 쓰레드 세이프(Tread Safe)란?](https://wooono.tistory.com/523){:target="_blank"}