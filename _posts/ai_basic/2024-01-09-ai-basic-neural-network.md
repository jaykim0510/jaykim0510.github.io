---
layout: post
title:  '[AI Basic] 인공신경망이란'
description: 인공신경망은 합과 곱으로 이루어진 일종의 함수이며, 인공신경망을 깊이 쌓으면 더 복잡한 문제를 풀 수 있게 된다
date:   2024-01-09 15:01:35 +0300
image:  '/images/ai_basic_logo.png'
logo_image:  '/images/ai_basic_logo.png'
category: AI
tag: AI_basic
---
---

**Table of Contents**
{: #toc }
*  TOC
{:toc}

---

# 인공신경망

- Artificial Neural Network
- 인공신경망은 딥러닝을 이루는 핵심 개념이다
- 딥러닝은 결국 인공신경망 레이어를 깊이(deep) 쌓아서 딥러닝인 것이다


## 퍼셉트론

- **퍼셉트론은 가장 간단한 인공 신경망 구조 중 하나**로 1957년 프랑크 로젠블라트가 제안했다
- 퍼셉트론은 현대의 인공 신경망과 비교하면 상당히 원시적인 신경망이지만, 노드, 가중치, 레이어와 같은 인공 신경망의 중요한 구성요소들을 공부하는데에 큰 의미가 있다

![](/images/ai_basic_5.png)
*Photo by [Daeki Yoon](https://compmath.korea.ac.kr/deeplearning/Perceptron.html)*

- 퍼셉트론 (혹은 인공신경망)은 위 그림과 같이, <span class='very__important'>입력을 받아 각각의 가중치를 곱해 더한 후 활성 함수를 통과시켜 값을 출력하는 일종의 함수</span>다

![](/images/ai_basic_10.png)

- 하지만 퍼셉트론은 비선형 분류 문제를 풀 수 없다는 치명적인 약점이 있다
- 이 문제는 1970년대 민스키의 『Perceptrons』에서 지적되었고, 이 후 한동안 신경망 연구가 정체기를 겪었다

![](/images/ai_basic_6.png){: width="50%"}

- 이 문제를 해결하기 위해 <span class='very__important'>은닉층</span> 이라는 개념이 도입되었다
- 다시 XOR 문제로 돌아와 보면, XOR 문제는 주어진 `x1`, `x2` 공간에서는 데이터를 분류하는 모델을 만들 수 없다. 따라서 분류가 가능하도록 해주는 특징공간으로 옮겨야 하는데, 이를 가능하게 해주는 것이 바로 은닉층의 역할이다.  
  ![](/images/ai_basic_7.png){: width="80%"}
- 밑에 그림과 같이 두 개의 퍼셉트론을 이용해 새로운 특징공간 `z1`, `z2`로 옮기면 우리의 데이터를 분류할 수 있게 된다(`z1`, `z2`층이 바로 은닉층)  
  ![](/images/ai_basic_8.png){: width="80%"}

![](/images/ai_basic_11.png)

## DNN

- Deep Neural Network
- 인공신경망은 일종의 함수인데, 이러한 인공신경망을 깊이 쌓으면 그것이 바로 **깊은 인공 신경망(DNN)**이 된다
- 이것은 여러 개의 함수가 적용된 합성 함수와 같다

![](/images/ai_basic_12.png)

![](/images/ai_basic_9.png){: width="60%"}


- 깊은 층을 통해 비선형 분류 문제를 해결하게 되며 이를 계기로 다양한 문제에 층을 깊이 쌓은 신경망 구조가 주목을 받기 시작했다
- 신경망을 깊게 쌓음으로써 기계가 여러 가지 특징 공간에서 데이터를 볼 수 있게 되었고 이 방법은 실제로 비정형 데이터(음성, 사진 등)를 다루는 데에 굉장한 성능을 보여주었다

## 비선형 활성 함수

- <span class='very__important'>깊은 인공신경망</span>. 이것이 바로 딥러닝의 핵심이다
- 은닉층을 깊게 쌓으면 모델이 데이터를 더 다양한 특징 공간에서 볼 수 있고 이것은 마치 사람의 생각이 더 깊어지고 더 다양한 관점에서 사물을 바라보는 것과 비슷하다
- 하지만 은닉층을 깊이 쌓으려면 은닉층에 반드시 포함되어야 하는 요소가 있는데 바로 비선형 활성 함수(Non linear activation function)이다
- 깊은 인공 신경망은 여러 개의 함수가 적용된 합성 함수와 같은데, 합성 함수가 linear한 관계라면, 결국은 하나의 linear function과 다를게 없고, 이는 신경망을 깊어지는 효과를 만들어내지 못한다
- 그래서 <span class='very__important'>인공신경망을 깊게 만들려면 하나로 합쳐지지 않는 비선형 활성 함수가 필요</span>한 것이다


# 결론

- 인공신경망은 일종의 함수다
- 인공신경망을 깊게 쌓으면 비선형 문제를 비롯한 복잡한 문제를 풀 수 있게 된다
- 인공신경망을 깊게 쌓기 위해서는 각 은닉층마다 비선형 활성 함수가 있어야 한다