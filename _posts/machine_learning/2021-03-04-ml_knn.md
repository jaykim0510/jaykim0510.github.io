---
layout: post
title:  'Machine Learning Series [Part4]: K-nearest Neighbors'
description: 
date:   2021-03-04 15:01:35 +0300
image:  '/images/ai_logo.jpeg'
logo_image:  '/images/ai_logo.jpeg'
categories: AI
tags: Machine_Learning
---
---

**Table of Contents**
{: #toc }
*  TOC
{:toc}

---

- 모델이 따로 없다
- 데이터셋 자체가 모델이라고 할 수 있다

- 추론할 새로운 데이터 x가 들어오면 
- 데이터셋에 있는 모든 데이터와 거리를 계산하고, 가장 가까운 데이터 k개를 고른다
- 그래서 학습시간은 따로 없지만, 추론하는데 시간이 오래 걸린다 -> 그래서 실무에서는 잘 안쓴다


- 분류문제는 k개의 데이터의 타겟값을  voting 한다
- 회귀문제는 k개의 데이터의 타겟값을  평균 한다

- k는 작을수록 overfitting, 클수록 underfitting 된다

- k값과 데이터간 거리를 측정하는 지표를 성능을 비교하며 선택해야 한다
- (유클리디안 거리, 맨하탄 거리, 마할라노비스 거리)

# 장단점

- 장점: 
  - 이해하기 쉬운 모델
  - 복잡한 알고리즘을 적용하기 전에 시도해 볼만한 좋은 시작점
  - 데이터에 있는 노이즈에 크게 영향을 받지 않는다. 데이터가 많으면 정확도가 올라간다
- 단점: 
  - 훈련 데이터가 많아지면 추론이 느려짐
  - 고차원 데이터셋에 대해 약함
  - 특성 값 대부분이 0인 데이터셋에 대해 약함